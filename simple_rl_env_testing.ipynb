{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "prices_df = pd.read_hdf('data/binance_BTC_USDT.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "env = SimulationEnv(prices=prices_df['price'].to_numpy()[:1_000], initial_balance=10_000, fee=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "state, done = env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "((0, 4280.5599999999995, 2.3442559861832044, 4261.48, 4261.48), 0, False)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "((10024.69367581216, 4261.48, 0, 4271.0199999999995, 4261.857821782178),\n 0.0,\n False)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Network:\n",
    "    def __init__(self) -> None:\n",
    "        # Use GPU if available.\n",
    "        self._device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        ).to(self._device)\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=1e-3)\n",
    "        self._loss = nn.MSELoss()\n",
    "\n",
    "    def train(self, states: np.ndarray, actions: np.ndarray, q_values: np.ndarray) -> None:\n",
    "        states = torch.from_numpy(states).float().to(self._device)\n",
    "        q_values = torch.from_numpy(q_values).float().to(self._device)\n",
    "        actions = torch.from_numpy(actions).long().to(self._device)\n",
    "\n",
    "        self._model.train()\n",
    "        self._optimizer.zero_grad()\n",
    "        predictions = self._model(states)\n",
    "        predictions = torch.gather(predictions, dim=1, index=actions)\n",
    "        loss = self._loss(predictions, q_values)\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self._model.parameters(), 10)\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def predict(self, states: np.ndarray) -> np.ndarray:\n",
    "        states = torch.from_numpy(states).float().to(self._device)\n",
    "        self._model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self._model(states).cpu().numpy()\n",
    "\n",
    "    def copy_weights_from(self, other) -> None:\n",
    "        params = dict(self._model.named_parameters())\n",
    "        params_other = dict(other._model.named_parameters())\n",
    "        with torch.no_grad():\n",
    "            for name, value in params_other.items():\n",
    "                params[name].data.copy_(value.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 return: 224.99744838047303\n",
      "Episode: 1 return: 264.531597508022\n",
      "Episode: 2 return: 10.526600750194191\n",
      "Episode: 3 return: 463.344433536383\n",
      "Episode: 4 return: 107.36902379122189\n",
      "Episode: 5 return: 659.0909868725554\n",
      "Episode: 6 return: 93.25250433980881\n",
      "Episode: 7 return: -754.3228877029144\n",
      "Episode: 8 return: -12.09655519360639\n",
      "Episode: 9 return: -4.448079854905141\n",
      "Episode: 10 return: 404.5836446362279\n",
      "Episode: 11 return: 202.75678159449467\n",
      "Episode: 12 return: -403.27718192251444\n",
      "Episode: 13 return: -319.655870002426\n",
      "Episode: 14 return: -126.48002786972344\n",
      "Episode: 15 return: -267.77574004643776\n",
      "Episode: 16 return: 175.35113259349407\n",
      "Episode: 17 return: 712.920821829259\n",
      "Episode: 18 return: 370.2768818837727\n",
      "Episode: 19 return: -240.6320419818552\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "network = Network()\n",
    "\n",
    "epsilon = 0.5\n",
    "gamma = 0.99\n",
    "\n",
    "replay_buffer = collections.deque()\n",
    "\n",
    "Transition = collections.namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"done\", \"next_state\"])\n",
    "\n",
    "for episode in range(20):\n",
    "    state, done = env.reset()\n",
    "    episode_return = 0\n",
    "\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            q_values = network.predict(np.array([state], dtype=np.float32))[0]\n",
    "        if np.random.uniform() >= epsilon:\n",
    "            action = np.argmax(q_values)\n",
    "        else:\n",
    "            action = np.random.randint(0, 3)\n",
    "\n",
    "        next_state, reward, done = env.step(action)\n",
    "        episode_return += reward\n",
    "        replay_buffer.append(Transition(state, action, reward, done, next_state))\n",
    "\n",
    "\n",
    "        if len(replay_buffer) > 512:\n",
    "            minibatch = random.sample(replay_buffer, 512)\n",
    "            states = np.vstack([t.state for t in minibatch])\n",
    "            actions = np.vstack([t.action for t in minibatch])\n",
    "            rewards = np.vstack([t.reward for t in minibatch])\n",
    "            next_states = np.vstack([t.next_state for t in minibatch])\n",
    "            dones = np.vstack([t.done for t in minibatch]).astype(np.uint8)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_values_next = network.predict(next_states)\n",
    "                q_values_next = q_values_next.max(axis=1).reshape(-1, 1)\n",
    "                target_q_values = rewards + (1 - dones) * gamma * q_values_next\n",
    "            network.train(states, actions, target_q_values)\n",
    "\n",
    "        state = next_state\n",
    "    print(f'Episode: {episode} return: {episode_return}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "-19.080000000000837"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4261.48 - 4280.56"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 3829.47615283,   872.362006  ,  3829.47615283,  3829.47615283,\n            0.        ,    50.        ,  3829.47615283, 10000.        ,\n            0.        ]),\n {})"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 3.80494806e+03,  3.85813469e+02,  3.80876260e+03,  3.81634181e+03,\n        -6.61621262e-01,  4.21757695e+01,  3.81111808e+03,  0.00000000e+00,\n         2.62047935e+00]),\n -13.047519166573693,\n False,\n False,\n {})"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "                amount         price\ntimestamp                           \n1502942460    1.775183   4261.480000\n1502942580    0.261074   4280.560000\n1502942640    0.012008   4261.480000\n1502942700    0.140796   4261.480000\n1502943480    0.075455   4262.187216\n...                ...           ...\n1670479020  140.372990  16822.509019\n1670479080  135.652550  16823.593779\n1670479140  106.761210  16823.667239\n1670479200  160.929330  16820.593849\n1670479260  311.577950  16812.328981\n\n[2760153 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1502942460</th>\n      <td>1.775183</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502942580</th>\n      <td>0.261074</td>\n      <td>4280.560000</td>\n    </tr>\n    <tr>\n      <th>1502942640</th>\n      <td>0.012008</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502942700</th>\n      <td>0.140796</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502943480</th>\n      <td>0.075455</td>\n      <td>4262.187216</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1670479020</th>\n      <td>140.372990</td>\n      <td>16822.509019</td>\n    </tr>\n    <tr>\n      <th>1670479080</th>\n      <td>135.652550</td>\n      <td>16823.593779</td>\n    </tr>\n    <tr>\n      <th>1670479140</th>\n      <td>106.761210</td>\n      <td>16823.667239</td>\n    </tr>\n    <tr>\n      <th>1670479200</th>\n      <td>160.929330</td>\n      <td>16820.593849</td>\n    </tr>\n    <tr>\n      <th>1670479260</th>\n      <td>311.577950</td>\n      <td>16812.328981</td>\n    </tr>\n  </tbody>\n</table>\n<p>2760153 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prices_df = pd.read_hdf('data/binance_BTC_USDT.h5')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                         amount         price\ntimestamp                                    \n2017-08-17 04:01:00    1.775183   4261.480000\n2017-08-17 04:03:00    0.261074   4280.560000\n2017-08-17 04:04:00    0.012008   4261.480000\n2017-08-17 04:05:00    0.140796   4261.480000\n2017-08-17 04:18:00    0.075455   4262.187216\n...                         ...           ...\n2022-12-08 05:57:00  140.372990  16822.509019\n2022-12-08 05:58:00  135.652550  16823.593779\n2022-12-08 05:59:00  106.761210  16823.667239\n2022-12-08 06:00:00  160.929330  16820.593849\n2022-12-08 06:01:00  311.577950  16812.328981\n\n[2760153 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-17 04:01:00</th>\n      <td>1.775183</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:03:00</th>\n      <td>0.261074</td>\n      <td>4280.560000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:04:00</th>\n      <td>0.012008</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:05:00</th>\n      <td>0.140796</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:18:00</th>\n      <td>0.075455</td>\n      <td>4262.187216</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:57:00</th>\n      <td>140.372990</td>\n      <td>16822.509019</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:58:00</th>\n      <td>135.652550</td>\n      <td>16823.593779</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:59:00</th>\n      <td>106.761210</td>\n      <td>16823.667239</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:00:00</th>\n      <td>160.929330</td>\n      <td>16820.593849</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:01:00</th>\n      <td>311.577950</td>\n      <td>16812.328981</td>\n    </tr>\n  </tbody>\n</table>\n<p>2760153 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_df.index = pd.to_datetime(prices_df.index * 1e9)\n",
    "prices_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "hourly_prices = prices_df.groupby(pd.Grouper(freq='H')).agg({'amount': 'sum', 'price': 'last'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "hourly_prices['price'] = hourly_prices['price'].ffill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import talib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "%matplotlib\n",
    "\n",
    "class StockExchangeEnv(gym.Env):\n",
    "    def __init__(self, price_data: np.ndarray, volume_data: np.ndarray, initial_cash: int, max_steps: int = 720, trading_fee: float = 0.0):\n",
    "        super(StockExchangeEnv, self).__init__()\n",
    "\n",
    "        self.price_data = price_data\n",
    "        self.volume_data = volume_data\n",
    "        self.initial_cash = initial_cash\n",
    "        self.trading_fee = trading_fee\n",
    "        self.max_steps = max_steps\n",
    "        self.balance_history = []\n",
    "        self.action_history = []\n",
    "        self.reward_history = []\n",
    "        self.net_worth_changes = []\n",
    "        self.price_line = None\n",
    "        self.start_step = 0\n",
    "\n",
    "        # Define action space: 0 - hold, 1 - buy, 2 - sell\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Define observation space: normalized price, volume, cash balance, asset holdings\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(9,), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            rng = np.random.default_rng(seed=seed)\n",
    "            self.current_step = rng.integers(0, len(self.price_data) - self.max_steps)\n",
    "            self.start_step = self.current_step\n",
    "        else:\n",
    "            self.current_step = np.random.randint(len(self.price_data) - self.max_steps)\n",
    "            self.start_step = self.current_step\n",
    "        self.cash_balance = self.initial_cash\n",
    "        self.asset_holdings = 0\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        current_price = self.price_data[self.current_step]\n",
    "        current_volume = self.volume_data[self.current_step]\n",
    "\n",
    "        self.balance_history.append(self.cash_balance + self.asset_holdings * current_price)\n",
    "\n",
    "        if action == 1:  # Buy\n",
    "            amount_to_buy = (1 * self.cash_balance) / current_price\n",
    "            cost = amount_to_buy * current_price\n",
    "            self.cash_balance -= cost\n",
    "            self.asset_holdings += amount_to_buy * (1 - self.trading_fee)\n",
    "            self.action_history.append(1)\n",
    "        elif action == 2:  # Sell\n",
    "            amount_to_sell = self.asset_holdings\n",
    "            revenue = amount_to_sell * current_price * (1 - self.trading_fee)\n",
    "            self.cash_balance += revenue\n",
    "            self.asset_holdings = 0\n",
    "            self.action_history.append(-1)\n",
    "        else:\n",
    "            self.action_history.append(0)\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step == self.start_step + self.max_steps\n",
    "        reward = self._get_reward()\n",
    "        self.reward_history.append(reward)\n",
    "\n",
    "        return self._get_observation(), reward, done, False, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        current_price = self.price_data[self.current_step]\n",
    "        current_volume = self.volume_data[self.current_step]\n",
    "\n",
    "        short_mavg = talib.SMA(self.price_data[self.start_step:self.current_step + 1], timeperiod=5)[-1] if self.current_step - self.start_step >= 4 else current_price\n",
    "        long_mavg = talib.SMA(self.price_data[self.start_step:self.current_step + 1], timeperiod=20)[-1] if self.current_step - self.start_step >= 19 else current_price\n",
    "\n",
    "        if self.current_step - self.start_step >= 26:\n",
    "            macd, macd_signal, _ = talib.MACD(self.price_data[self.start_step:self.current_step + 1], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            macd_diff = macd[-1] - macd_signal[-1]\n",
    "            if np.isnan(macd_diff):\n",
    "                macd_diff = 0\n",
    "        else:\n",
    "            macd_diff = 0\n",
    "\n",
    "        rsi = talib.RSI(self.price_data[self.start_step:self.current_step + 1], timeperiod=14)[-1] if self.current_step - self.start_step >= 14 else 50\n",
    "\n",
    "        ema = talib.EMA(self.price_data[self.start_step:self.current_step + 1], timeperiod=12)[-1] if self.current_step - self.start_step >= 11 else current_price\n",
    "\n",
    "        observation = np.array([current_price, current_volume, short_mavg, long_mavg, macd_diff, rsi, ema, self.cash_balance, self.asset_holdings])\n",
    "        if any(np.isnan(observation)):\n",
    "            print(observation)\n",
    "        return observation\n",
    "\n",
    "    def _get_reward(self):\n",
    "        current_net_worth_change = self.cash_balance + self.asset_holdings * self.price_data[self.current_step] - self.initial_cash\n",
    "        if len(self.net_worth_changes) > 0:\n",
    "            previous_net_worth_change = self.net_worth_changes[-1]\n",
    "        else:\n",
    "            previous_net_worth_change = 0\n",
    "        self.net_worth_changes.append(current_net_worth_change)  # Add the net worth change to the list\n",
    "        return current_net_worth_change - previous_net_worth_change\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if self.current_step == self.start_step:\n",
    "            self.fig, (self.ax1, self.ax2, self.ax3, self.ax4) = plt.subplots(4, 1, figsize=(10, 12), gridspec_kw={'height_ratios': [3, 3, 3, 1]}, sharex=True)\n",
    "            self.ax1.set_title('Stock Price')\n",
    "            self.ax1.set_xlabel('Step')\n",
    "            self.ax1.set_ylabel('Price')\n",
    "\n",
    "            self.ax2.set_title('Portfolio Value')\n",
    "            self.ax2.set_xlabel('Step')\n",
    "            self.ax2.set_ylabel('Amount')\n",
    "\n",
    "            self.ax3.set_title('Rewards')\n",
    "            self.ax3.set_xlabel('Step')\n",
    "            self.ax3.set_ylabel('Sharpe Ratio')\n",
    "\n",
    "            self.ax4.set_title('Action History')\n",
    "            self.ax4.set_xlabel('Step')\n",
    "            self.ax4.set_ylabel('Action')\n",
    "        else:\n",
    "            x_data = np.arange(self.current_step - self.start_step)\n",
    "            y_data = self.price_data[self.start_step:self.current_step]\n",
    "            self.ax1.plot(x_data, y_data, color='C0')\n",
    "            self.ax2.plot(x_data, self.balance_history[:self.current_step - self.start_step], color='C1')\n",
    "            self.ax3.plot(x_data, self.reward_history[:self.current_step - self.start_step], color='C1')\n",
    "            self.ax4.plot(x_data, self.action_history[:self.current_step - self.start_step], color='C1')\n",
    "            plt.pause(0.01)\n",
    "            #time.sleep(0.01)\n",
    "\n",
    "env = StockExchangeEnv(hourly_prices['price'].to_numpy(), hourly_prices['amount'].to_numpy(), 10_000)\n",
    "\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    env.render()\n",
    "    current_step = env.current_step\n",
    "    current_price = env.price_data[current_step]\n",
    "    next_price = env.price_data[current_step + 1]\n",
    "    if next_price > current_price:\n",
    "        env.step(1)\n",
    "    elif next_price < current_price:\n",
    "        env.step(2)\n",
    "    else:\n",
    "        env.step(0)\n",
    "\n",
    "# for i in range(100):\n",
    "#     env.render()\n",
    "#     current_step = env.current_step\n",
    "#     current_price = env.price_data[current_step]\n",
    "#     next_price = env.price_data[current_step + 1]\n",
    "#     try:\n",
    "#         next_next_price = env.price_data[current_step + 2]\n",
    "#     except IndexError:\n",
    "#         next_next_price = 0\n",
    "#     print(f'{current_price=:.2f}\\t{next_price=:.2f}\\t{next_next_price=:.2f}')\n",
    "#     print('Enter next action: 0 HOLD, 1 BUY, 2 SELL\\n')\n",
    "#     time.sleep(0.1)\n",
    "#     action = int(input())\n",
    "#     env.step(action)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from ray.tune.registry import register_env"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 23:20:54,623\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "register_env('StockExchangeEnv-v0', lambda config: StockExchangeEnv(**config))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 23:20:56,043\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\tMean return: -42.865930799546184\n",
      "Step: 2\tMean return: -185.89766800128746\n",
      "Step: 3\tMean return: 169.17498209446853\n",
      "Step: 4\tMean return: -88.3142230583735\n",
      "Step: 5\tMean return: 19.19788326543157\n",
      "Step: 6\tMean return: -16.45068610735584\n",
      "Step: 7\tMean return: 7.063555817371994\n",
      "Step: 8\tMean return: -38.02530962088903\n",
      "Step: 9\tMean return: -41.522897312310235\n",
      "Step: 10\tMean return: -17.97407142151989\n",
      "Step: 11\tMean return: -19.678367718046115\n",
      "Step: 12\tMean return: 11.896916841168824\n",
      "Step: 13\tMean return: -2.235516732331765\n",
      "Step: 14\tMean return: 12.66614309286765\n",
      "Step: 15\tMean return: -4.661710404750021\n",
      "Step: 16\tMean return: -16.956172854057762\n",
      "Step: 17\tMean return: -11.008859576698496\n",
      "Step: 18\tMean return: 2.480511230930242\n",
      "Step: 19\tMean return: -0.4883398345264868\n",
      "Step: 20\tMean return: 26.459753117181773\n",
      "Step: 21\tMean return: -44.16181603506087\n",
      "Step: 22\tMean return: 20.183706555358384\n",
      "Step: 23\tMean return: -3.228635785139504\n",
      "Step: 24\tMean return: 24.918146317321316\n",
      "Step: 25\tMean return: 8.069768562017744\n",
      "Step: 26\tMean return: 21.183064981363295\n",
      "Step: 27\tMean return: 21.986740159274323\n",
      "Step: 28\tMean return: 18.439004376829672\n",
      "Step: 29\tMean return: 11.235094199674695\n",
      "Step: 30\tMean return: -18.454389558274144\n",
      "Step: 31\tMean return: 0.4779703119930309\n",
      "Step: 32\tMean return: -13.879348664528479\n",
      "Step: 33\tMean return: -4.414854881549072\n",
      "Step: 34\tMean return: 25.30627695867275\n",
      "Step: 35\tMean return: 11.386543775751761\n",
      "Step: 36\tMean return: -0.1694824840252113\n",
      "Step: 37\tMean return: 5.89722545505414\n",
      "Step: 38\tMean return: -4.4858072601322965\n",
      "Step: 39\tMean return: 16.594622618559733\n",
      "Step: 40\tMean return: 1.5351458495108272\n",
      "Step: 41\tMean return: -0.5398200925658057\n",
      "Step: 42\tMean return: -24.769327379975476\n",
      "Step: 43\tMean return: -12.216331839527047\n",
      "Step: 44\tMean return: -5.6329169383652875\n",
      "Step: 45\tMean return: 2.9569144049329954\n",
      "Step: 46\tMean return: -6.85947251076328\n",
      "Step: 47\tMean return: -10.889216984027753\n",
      "Step: 48\tMean return: 23.114663099628014\n",
      "Step: 49\tMean return: -0.5502420291690759\n",
      "Step: 50\tMean return: -0.03243519025008936\n",
      "Step: 51\tMean return: 8.155265680051926\n",
      "Step: 52\tMean return: -12.364523852286984\n",
      "Step: 53\tMean return: 1.7423275592588652\n",
      "Step: 54\tMean return: -2.9104647257931537\n",
      "Step: 55\tMean return: -1.274624985697901\n",
      "Step: 56\tMean return: -5.948164801591283\n",
      "Step: 57\tMean return: -4.296843552254159\n",
      "Step: 58\tMean return: 0.7535884564825028\n",
      "Step: 59\tMean return: 1.7556978045066716\n",
      "Step: 60\tMean return: -1.853147364183351\n",
      "Step: 61\tMean return: -3.563379185676786\n",
      "Step: 62\tMean return: -8.15441640664445\n",
      "Step: 63\tMean return: 8.857036566502702\n",
      "Step: 64\tMean return: -5.640472012687715\n",
      "Step: 65\tMean return: 17.890299769167214\n",
      "Step: 66\tMean return: -6.227366412796091\n",
      "Step: 67\tMean return: 6.002241123134899\n",
      "Step: 68\tMean return: -0.6503603378614571\n",
      "Step: 69\tMean return: 14.26222541596473\n",
      "Step: 70\tMean return: -7.96471444914192\n",
      "Step: 71\tMean return: -3.3576494925343106\n",
      "Step: 72\tMean return: 5.9238466558805705\n",
      "Step: 73\tMean return: 2.278869688476243\n",
      "Step: 74\tMean return: 2.1951016048972813\n",
      "Step: 75\tMean return: 5.831000258159238\n",
      "Step: 76\tMean return: 19.954976040613456\n",
      "Step: 77\tMean return: -3.1514098006923086\n",
      "Step: 78\tMean return: 18.18126420690378\n",
      "Step: 79\tMean return: 12.359239818530005\n",
      "Step: 80\tMean return: 7.520029179113571\n",
      "Step: 81\tMean return: 33.06959100589\n",
      "Step: 82\tMean return: -10.78834427043903\n",
      "Step: 83\tMean return: 2.19704148589266\n",
      "Step: 84\tMean return: -11.169366058550713\n",
      "Step: 85\tMean return: -20.55052874727224\n",
      "Step: 86\tMean return: 4.889533920467129\n",
      "Step: 87\tMean return: 9.552917395456152\n",
      "Step: 88\tMean return: 6.827010386960464\n",
      "Step: 89\tMean return: -4.283908869425541\n",
      "Step: 90\tMean return: -5.920463695723538\n",
      "Step: 91\tMean return: -7.696401481802223\n",
      "Step: 92\tMean return: -1.274082156118384\n",
      "Step: 93\tMean return: -0.9966833829155439\n",
      "Step: 94\tMean return: -29.416883048938743\n",
      "Step: 95\tMean return: 1.9115194717049961\n",
      "Step: 96\tMean return: -8.559848147787397\n",
      "Step: 97\tMean return: -12.002049473328151\n",
      "Step: 98\tMean return: 11.763158872308304\n",
      "Step: 99\tMean return: -55.70089418048187\n",
      "Step: 100\tMean return: 8.303099539169597\n",
      "Step: 101\tMean return: -5.387173962683409\n",
      "Step: 102\tMean return: 0.15743374015153677\n",
      "Step: 103\tMean return: 21.253463931579645\n",
      "Step: 104\tMean return: -7.414427446858481\n",
      "Step: 105\tMean return: -20.44106971161342\n",
      "Step: 106\tMean return: 9.22417627098861\n",
      "Step: 107\tMean return: 12.266956697121405\n",
      "Step: 108\tMean return: 15.951100480172444\n",
      "Step: 109\tMean return: -2.1214888447824523\n",
      "Step: 110\tMean return: 2.4203046201045617\n",
      "Step: 111\tMean return: -20.64621630237246\n",
      "Step: 112\tMean return: 1.7186271443492023\n",
      "Step: 113\tMean return: -5.98968408916191\n",
      "Step: 114\tMean return: -3.1010985089665155\n",
      "Step: 115\tMean return: 6.993591601105536\n",
      "Step: 116\tMean return: -8.45396645010389\n",
      "Step: 117\tMean return: 4.443400243291808\n",
      "Step: 118\tMean return: 3.689592120996431\n",
      "Step: 119\tMean return: -0.3308846379082206\n",
      "Step: 120\tMean return: 9.476881326801685\n",
      "Step: 121\tMean return: -2.7493903070168018\n",
      "Step: 122\tMean return: 12.744914064714877\n",
      "Step: 123\tMean return: -27.061213605054583\n",
      "Step: 124\tMean return: 26.032787864073907\n",
      "Step: 125\tMean return: -7.572462710037326\n",
      "Step: 126\tMean return: -14.998715153064985\n",
      "Step: 127\tMean return: 3.944270100024314\n",
      "Step: 128\tMean return: 6.965684618648993\n",
      "Step: 129\tMean return: 28.794405661250575\n",
      "Step: 130\tMean return: -0.09916588066706027\n",
      "Step: 131\tMean return: -12.322697325607097\n",
      "Step: 132\tMean return: -14.614550331935934\n",
      "Step: 133\tMean return: 84.76851835027965\n",
      "Step: 134\tMean return: -6.868187132219736\n",
      "Step: 135\tMean return: 40.19000268373826\n",
      "Step: 136\tMean return: 4.207196198127567\n",
      "Step: 137\tMean return: -6.432826894016298\n",
      "Step: 138\tMean return: -5.636168948553668\n",
      "Step: 139\tMean return: -20.40009909217013\n",
      "Step: 140\tMean return: -12.170406101052741\n",
      "Step: 141\tMean return: 19.217313118841293\n",
      "Step: 142\tMean return: -34.97545079781148\n",
      "Step: 143\tMean return: -0.16706326786783393\n",
      "Step: 144\tMean return: 3.3568042326129763\n",
      "Step: 145\tMean return: 1.3682514977420215\n",
      "Step: 146\tMean return: -16.722597556131277\n",
      "Step: 147\tMean return: 13.484305100075016\n",
      "Step: 148\tMean return: 9.75127413559294\n",
      "Step: 149\tMean return: 13.794498614061768\n",
      "Step: 150\tMean return: 9.268090216662868\n",
      "Step: 151\tMean return: -94.62656722204203\n",
      "Step: 152\tMean return: 3.628508481198314\n",
      "Step: 153\tMean return: -36.984558655835514\n",
      "Step: 154\tMean return: 5.783475479087319\n",
      "Step: 155\tMean return: -16.578770794790643\n",
      "Step: 156\tMean return: 15.539506604347753\n",
      "Step: 157\tMean return: 19.406608537477222\n",
      "Step: 158\tMean return: -0.5668498523283961\n",
      "Step: 159\tMean return: 28.305688278457275\n",
      "Step: 160\tMean return: 1.986488779114261\n",
      "Step: 161\tMean return: 19.821032106878594\n",
      "Step: 162\tMean return: 0.10210554372612023\n",
      "Step: 163\tMean return: 0.07133902890509489\n",
      "Step: 164\tMean return: 4.534802986544073\n",
      "Step: 165\tMean return: -27.914116224533274\n",
      "Step: 166\tMean return: -6.6545316532119525\n",
      "Step: 167\tMean return: -6.508520830540911\n",
      "Step: 168\tMean return: -1.9184358229138343\n",
      "Step: 169\tMean return: 17.747619968080897\n",
      "Step: 170\tMean return: -10.465071247581491\n",
      "Step: 171\tMean return: 5.371390081361169\n",
      "Step: 172\tMean return: -17.177851310903943\n",
      "Step: 173\tMean return: 46.80327538268074\n",
      "Step: 174\tMean return: -10.800183772193023\n",
      "Step: 175\tMean return: 1.1182332198999212\n",
      "Step: 176\tMean return: -0.008003227887156754\n",
      "Step: 177\tMean return: -26.496197278962544\n",
      "Step: 178\tMean return: 47.41159991882909\n",
      "Step: 179\tMean return: -11.288149776480005\n",
      "Step: 180\tMean return: -12.230596457795873\n",
      "Step: 181\tMean return: 21.124654581577616\n",
      "Step: 182\tMean return: 7.931212433246128\n",
      "Step: 183\tMean return: 3.9017469733571306\n",
      "Step: 184\tMean return: -5.004386519557138\n",
      "Step: 185\tMean return: 12.246911855550225\n",
      "Step: 186\tMean return: -2.048084237550893\n",
      "Step: 187\tMean return: 2.848393428627278\n",
      "Step: 188\tMean return: 16.709036106753246\n",
      "Step: 189\tMean return: -8.513016095252588\n",
      "Step: 190\tMean return: 7.938802065297896\n",
      "Step: 191\tMean return: -25.957305509079198\n",
      "Step: 192\tMean return: -12.386892429706204\n",
      "Step: 193\tMean return: -22.274633603826278\n",
      "Step: 194\tMean return: 32.67585524107888\n",
      "Step: 195\tMean return: -0.8759948567091306\n",
      "Step: 196\tMean return: -30.45093463065359\n",
      "Step: 197\tMean return: -8.19929802056904\n",
      "Step: 198\tMean return: 8.353906861480846\n",
      "Step: 199\tMean return: -21.607848427304308\n",
      "Step: 200\tMean return: -14.990751107844552\n",
      "Step: 201\tMean return: 9.970883837191813\n",
      "Step: 202\tMean return: 6.70677799330977\n",
      "Step: 203\tMean return: 1.4004184189770057\n",
      "Step: 204\tMean return: 10.156304615174976\n",
      "Step: 205\tMean return: -14.469463774409105\n",
      "Step: 206\tMean return: -1.2678488104188363\n",
      "Step: 207\tMean return: 4.191845258029807\n",
      "Step: 208\tMean return: 17.7868090551354\n",
      "Step: 209\tMean return: -2.7947625693604823\n",
      "Step: 210\tMean return: 8.599413677847515\n",
      "Step: 211\tMean return: 20.891424103761075\n",
      "Step: 212\tMean return: -24.136229297273967\n",
      "Step: 213\tMean return: 5.664956611129983\n",
      "Step: 214\tMean return: -8.536017861234068\n",
      "Step: 215\tMean return: 1.0402244425585194\n",
      "Step: 216\tMean return: 37.877588601040515\n",
      "Step: 217\tMean return: 19.855785189667586\n",
      "Step: 218\tMean return: 14.711314805616293\n",
      "Step: 219\tMean return: -16.554026220906437\n",
      "Step: 220\tMean return: 0.024757625755337357\n",
      "Step: 221\tMean return: -3.860780498335953\n",
      "Step: 222\tMean return: -2.185691570780218\n",
      "Step: 223\tMean return: -3.7022407038686653\n",
      "Step: 224\tMean return: -5.61107101910151\n",
      "Step: 225\tMean return: 3.567599740838832\n",
      "Step: 226\tMean return: -10.382514400023847\n",
      "Step: 227\tMean return: 23.94794996268889\n",
      "Step: 228\tMean return: 5.435634504529153\n",
      "Step: 229\tMean return: -2.327127636080877\n",
      "Step: 230\tMean return: 1.2317241895134612\n",
      "Step: 231\tMean return: 15.459732007914663\n",
      "Step: 232\tMean return: -11.465084266192735\n",
      "Step: 233\tMean return: -1.3392922420722244\n",
      "Step: 234\tMean return: -38.210664539909956\n",
      "Step: 235\tMean return: -9.183176434055476\n",
      "Step: 236\tMean return: 18.77284998986088\n",
      "Step: 237\tMean return: 13.71348418507805\n",
      "Step: 238\tMean return: 7.8673109802244285\n",
      "Step: 239\tMean return: 2.326054011840788\n",
      "Step: 240\tMean return: 1.5955161114351721\n",
      "Step: 241\tMean return: 8.936768147239963\n",
      "Step: 242\tMean return: 2.9295661368977743\n",
      "Step: 243\tMean return: -10.04214141145756\n",
      "Step: 244\tMean return: -11.30894279311231\n",
      "Step: 245\tMean return: -1.4420483065490226\n",
      "Step: 246\tMean return: -7.461654969497704\n",
      "Step: 247\tMean return: 8.448507296955322\n",
      "Step: 248\tMean return: 3.53372418710077\n",
      "Step: 249\tMean return: 1.2456481817987697\n",
      "Step: 250\tMean return: 15.918581229855063\n",
      "Step: 251\tMean return: 9.557548822081099\n",
      "Step: 252\tMean return: 16.636316825207906\n",
      "Step: 253\tMean return: -10.66424997667189\n",
      "Step: 254\tMean return: -13.320985698361055\n",
      "Step: 255\tMean return: -4.978179059921185\n",
      "Step: 256\tMean return: 13.381738402840602\n",
      "Step: 257\tMean return: -32.75174839801066\n",
      "Step: 258\tMean return: 3.4867083657364857\n",
      "Step: 259\tMean return: -7.540393800660622\n",
      "Step: 260\tMean return: -0.7337180282369808\n",
      "Step: 261\tMean return: 17.889303370262986\n",
      "Step: 262\tMean return: 23.779918826778996\n",
      "Step: 263\tMean return: -16.452459394955476\n",
      "Step: 264\tMean return: -7.638310405343054\n",
      "Step: 265\tMean return: 7.731492529040315\n",
      "Step: 266\tMean return: -9.790426967274616\n",
      "Step: 267\tMean return: -14.560939305861902\n",
      "Step: 268\tMean return: -10.081794670051694\n",
      "Step: 269\tMean return: -19.648489869824715\n",
      "Step: 270\tMean return: -28.598938715287385\n",
      "Step: 271\tMean return: 7.928113005539235\n",
      "Step: 272\tMean return: 2.1607806750454803\n",
      "Step: 273\tMean return: 0.6572535915716071\n",
      "Step: 274\tMean return: -12.763984350489228\n",
      "Step: 275\tMean return: 30.239809576654405\n",
      "Step: 276\tMean return: -5.441746892034371\n",
      "Step: 277\tMean return: 6.416191125782043\n",
      "Step: 278\tMean return: 1.913251398305929\n",
      "Step: 279\tMean return: -5.3856202195034895\n",
      "Step: 280\tMean return: -4.42582702181031\n",
      "Step: 281\tMean return: 8.042259037418408\n",
      "Step: 282\tMean return: 9.40988077072645\n",
      "Step: 283\tMean return: -16.71683206565578\n",
      "Step: 284\tMean return: 8.63266000691965\n",
      "Step: 285\tMean return: -1.6796757680009613\n",
      "Step: 286\tMean return: -2.178852481181184\n",
      "Step: 287\tMean return: 7.4247521627214885\n",
      "Step: 288\tMean return: 14.78014651139545\n",
      "Step: 289\tMean return: -6.243190798692922\n",
      "Step: 290\tMean return: -10.226214503630162\n",
      "Step: 291\tMean return: -2.8740326305251074\n",
      "Step: 292\tMean return: -20.128810033839056\n",
      "Step: 293\tMean return: -6.9940024290211475\n",
      "Step: 294\tMean return: 4.286222023743084\n",
      "Step: 295\tMean return: -5.838022098674337\n",
      "Step: 296\tMean return: -0.9549796727509602\n",
      "Step: 297\tMean return: -1.7022213914870372\n",
      "Step: 298\tMean return: -10.979350587980006\n",
      "Step: 299\tMean return: -21.1306816172284\n",
      "Step: 300\tMean return: -5.867546002535601\n",
      "Step: 301\tMean return: 31.825186342157814\n",
      "Step: 302\tMean return: -9.974205308846594\n",
      "Step: 303\tMean return: -2.6108073307849007\n",
      "Step: 304\tMean return: 3.025126873488771\n",
      "Step: 305\tMean return: -3.2515264162359925\n",
      "Step: 306\tMean return: -3.834668549770904\n",
      "Step: 307\tMean return: -6.51349813320745\n",
      "Step: 308\tMean return: -3.7055032716491043\n",
      "Step: 309\tMean return: -3.4119544571907863\n",
      "Step: 310\tMean return: 17.039125378110967\n",
      "Step: 311\tMean return: 6.611379191602627\n",
      "Step: 312\tMean return: -0.26502215887374403\n",
      "Step: 313\tMean return: 11.244956968124898\n",
      "Step: 314\tMean return: -5.69016861289444\n",
      "Step: 315\tMean return: -7.423286118040223\n",
      "Step: 316\tMean return: -5.3059080520153294\n",
      "Step: 317\tMean return: 12.430579994237505\n",
      "Step: 318\tMean return: 6.2259878681049665\n",
      "Step: 319\tMean return: -26.71954572644833\n",
      "Step: 320\tMean return: 29.73451934957593\n",
      "Step: 321\tMean return: -9.696332053707774\n",
      "Step: 322\tMean return: -1.4627280362101192\n",
      "Step: 323\tMean return: 5.634286672738289\n",
      "Step: 324\tMean return: 0.4483601891393664\n",
      "Step: 325\tMean return: 3.33191341084399\n",
      "Step: 326\tMean return: 6.095973006466174\n",
      "Step: 327\tMean return: -9.265988237379696\n",
      "Step: 328\tMean return: 9.66693949983659\n",
      "Step: 329\tMean return: 0.08543590425835645\n",
      "Step: 330\tMean return: -1.4021600068884073\n",
      "Step: 331\tMean return: -9.117662087812223\n",
      "Step: 332\tMean return: 10.195390978911728\n",
      "Step: 333\tMean return: 5.4423740268138685\n",
      "Step: 334\tMean return: 6.465066357766464\n",
      "Step: 335\tMean return: -3.448029134408498\n",
      "Step: 336\tMean return: 8.912470994930136\n",
      "Step: 337\tMean return: -3.2571561410808316\n",
      "Step: 338\tMean return: -25.926324899775153\n",
      "Step: 339\tMean return: 9.739658305705706\n",
      "Step: 340\tMean return: -4.565040016879757\n",
      "Step: 341\tMean return: 0.5011590789830188\n",
      "Step: 342\tMean return: 2.103618016312175\n",
      "Step: 343\tMean return: 3.0191295903499302\n",
      "Step: 344\tMean return: -13.461298019718123\n",
      "Step: 345\tMean return: 15.251284609395988\n",
      "Step: 346\tMean return: -16.822465195538626\n",
      "Step: 347\tMean return: 28.99749035368608\n",
      "Step: 348\tMean return: 0.47972370907995354\n",
      "Step: 349\tMean return: 2.6535283354252535\n",
      "Step: 350\tMean return: -4.779613567909219\n",
      "Step: 351\tMean return: -0.7001050772949384\n",
      "Step: 352\tMean return: -3.5124091165382016\n",
      "Step: 353\tMean return: 1.88143330970428\n",
      "Step: 354\tMean return: -10.662999526943587\n",
      "Step: 355\tMean return: 2.8134836856560286\n",
      "Step: 356\tMean return: -17.089744164946932\n",
      "Step: 357\tMean return: -2.9631099694805743\n",
      "Step: 358\tMean return: 2.131913174290403\n",
      "Step: 359\tMean return: -2.1044098054170353\n",
      "Step: 360\tMean return: -2.7656132859208267\n",
      "Step: 361\tMean return: 10.56654519423977\n",
      "Step: 362\tMean return: 14.122076063497898\n",
      "Step: 363\tMean return: -3.485549510653818\n",
      "Step: 364\tMean return: 5.933486716524421\n",
      "Step: 365\tMean return: -23.2422217858142\n",
      "Step: 366\tMean return: -0.5918292451790512\n",
      "Step: 367\tMean return: -5.162302189443563\n",
      "Step: 368\tMean return: 2.4508333296966884\n",
      "Step: 369\tMean return: 1.320629078139591\n",
      "Step: 370\tMean return: -0.5190729197737528\n",
      "Step: 371\tMean return: -1.9512485929420655\n",
      "Step: 372\tMean return: 4.127736721050933\n",
      "Step: 373\tMean return: 42.63593597088064\n",
      "Step: 374\tMean return: 90.07926789495865\n",
      "Step: 375\tMean return: -6.429574176640163\n",
      "Step: 376\tMean return: 18.532244315944517\n",
      "Step: 377\tMean return: 4.640227302952662\n",
      "Step: 378\tMean return: 22.347030203423436\n",
      "Step: 379\tMean return: 0.21304620801611235\n",
      "Step: 380\tMean return: -5.049777759798071\n",
      "Step: 381\tMean return: 14.342778426548593\n",
      "Step: 382\tMean return: 13.265493867331697\n",
      "Step: 383\tMean return: -23.09376903223405\n",
      "Step: 384\tMean return: 4.984174109183587\n",
      "Step: 385\tMean return: 4.883107456446068\n",
      "Step: 386\tMean return: 0.03107794740375539\n",
      "Step: 387\tMean return: -27.22454945419374\n",
      "Step: 388\tMean return: -10.88837476753919\n",
      "Step: 389\tMean return: 22.203855262235738\n",
      "Step: 390\tMean return: -1.2504945733810382\n",
      "Step: 391\tMean return: -43.74257142433212\n",
      "Step: 392\tMean return: -84.01242373372907\n",
      "Step: 393\tMean return: 19.991409235581706\n",
      "Step: 394\tMean return: -13.325993491128393\n",
      "Step: 395\tMean return: -4.108140296512956\n",
      "Step: 396\tMean return: -12.36234721437202\n",
      "Step: 397\tMean return: -6.419573134171351\n",
      "Step: 398\tMean return: 7.034328336383287\n",
      "Step: 399\tMean return: 2.235770136344172\n",
      "Step: 400\tMean return: -4.082075675759424\n",
      "Step: 401\tMean return: 26.57879481174705\n",
      "Step: 402\tMean return: -0.2060312505396905\n",
      "Step: 403\tMean return: 5.48216084546144\n",
      "Step: 404\tMean return: 8.541907591422133\n",
      "Step: 405\tMean return: 23.884000289804508\n",
      "Step: 406\tMean return: 45.591658068062955\n",
      "Step: 407\tMean return: -17.121275985670856\n",
      "Step: 408\tMean return: 7.037083430579951\n",
      "Step: 409\tMean return: 2.4544959243391897\n",
      "Step: 410\tMean return: 13.00162306308759\n",
      "Step: 411\tMean return: -7.350266692025852\n",
      "Step: 412\tMean return: -12.249568577866867\n",
      "Step: 413\tMean return: 5.391086774630494\n",
      "Step: 414\tMean return: -5.661202615023686\n",
      "Step: 415\tMean return: -4.0285555080084485\n",
      "Step: 416\tMean return: -18.376261369484382\n",
      "Step: 417\tMean return: -13.409970525145235\n",
      "Step: 418\tMean return: -5.34961768843521\n",
      "Step: 419\tMean return: -9.315886909977234\n",
      "Step: 420\tMean return: 1.5213005296007942\n",
      "Step: 421\tMean return: -5.108154189620691\n",
      "Step: 422\tMean return: -20.64260357121124\n",
      "Step: 423\tMean return: 10.628404268659743\n",
      "Step: 424\tMean return: -16.046503029856993\n",
      "Step: 425\tMean return: -4.041848225632529\n",
      "Step: 426\tMean return: -6.183551517115547\n",
      "Step: 427\tMean return: 0.596860975653235\n",
      "Step: 428\tMean return: 5.779731016444185\n",
      "Step: 429\tMean return: -7.415401102039059\n",
      "Step: 430\tMean return: 2.513105618812706\n",
      "Step: 431\tMean return: 19.201625254973006\n",
      "Step: 432\tMean return: 7.788295438674458\n",
      "Step: 433\tMean return: -2.8448292363139807\n",
      "Step: 434\tMean return: 13.099612445562725\n",
      "Step: 435\tMean return: 0.2143083000865954\n",
      "Step: 436\tMean return: -9.700201141963461\n",
      "Step: 437\tMean return: -10.157945951527909\n",
      "Step: 438\tMean return: -10.905595807313276\n",
      "Step: 439\tMean return: 0.9829880987034084\n",
      "Step: 440\tMean return: 3.4099944013779715\n",
      "Step: 441\tMean return: -19.725853359133236\n",
      "Step: 442\tMean return: -30.559905201402472\n",
      "Step: 443\tMean return: 10.121793811539291\n",
      "Step: 444\tMean return: 56.079290483176464\n",
      "Step: 445\tMean return: -6.825755540906675\n",
      "Step: 446\tMean return: 15.423570391222102\n",
      "Step: 447\tMean return: 51.22437227082017\n",
      "Step: 448\tMean return: -1.197092445493081\n",
      "Step: 449\tMean return: -14.936188273428488\n",
      "Step: 450\tMean return: -2.1266749410131522\n",
      "Step: 451\tMean return: 11.817634708938312\n",
      "Step: 452\tMean return: 12.987840779102116\n",
      "Step: 453\tMean return: -3.804692889823\n",
      "Step: 454\tMean return: 2.9997262016864896\n",
      "Step: 455\tMean return: 9.492914047502245\n",
      "Step: 456\tMean return: -24.83304906376298\n",
      "Step: 457\tMean return: 0.09830808803613764\n",
      "Step: 458\tMean return: 3.84669680954863\n",
      "Step: 459\tMean return: 12.346039707938889\n",
      "Step: 460\tMean return: 12.381818974587278\n",
      "Step: 461\tMean return: -11.2347820234957\n",
      "Step: 462\tMean return: -53.755664845907276\n",
      "Step: 463\tMean return: -0.5007252714354581\n",
      "Step: 464\tMean return: -53.64954195346172\n",
      "Step: 465\tMean return: -39.96898059648234\n",
      "Step: 466\tMean return: 25.590892403761664\n",
      "Step: 467\tMean return: -5.796781008821563\n",
      "Step: 468\tMean return: -20.365474407754647\n",
      "Step: 469\tMean return: -10.795959049013636\n",
      "Step: 470\tMean return: -12.879461482553907\n",
      "Step: 471\tMean return: -6.1487347299463\n",
      "Step: 472\tMean return: 16.774777220297064\n",
      "Step: 473\tMean return: 21.84092300294652\n",
      "Step: 474\tMean return: 59.67304175073193\n",
      "Step: 475\tMean return: 2.2219553863469446\n",
      "Step: 476\tMean return: 14.222086452072636\n",
      "Step: 477\tMean return: 0.3016115607075699\n",
      "Step: 478\tMean return: 2.9780930854363032\n",
      "Step: 479\tMean return: -0.0646601696376274\n",
      "Step: 480\tMean return: -3.3673505695971473\n",
      "Step: 481\tMean return: -1.612258535722667\n",
      "Step: 482\tMean return: 26.46265234902239\n",
      "Step: 483\tMean return: 4.31149862002776\n",
      "Step: 484\tMean return: -26.953274721944563\n",
      "Step: 485\tMean return: 1.470020370650782\n",
      "Step: 486\tMean return: 1.458664356048048\n",
      "Step: 487\tMean return: 5.354697385401396\n",
      "Step: 488\tMean return: -4.865690651934565\n",
      "Step: 489\tMean return: -2.674857239770317\n",
      "Step: 490\tMean return: -18.808134044795096\n",
      "Step: 491\tMean return: -19.502621199511378\n",
      "Step: 492\tMean return: -37.393879560223795\n",
      "Step: 493\tMean return: -43.503727934945324\n",
      "Step: 494\tMean return: -12.815342776802446\n",
      "Step: 495\tMean return: 9.122623034900034\n",
      "Step: 496\tMean return: -8.691910038315346\n",
      "Step: 497\tMean return: 11.065681917033835\n",
      "Step: 498\tMean return: -3.2849380903689234\n",
      "Step: 499\tMean return: -8.57105499430685\n",
      "Step: 500\tMean return: 6.42363866122847\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "dqn = (\n",
    "    PPOConfig()\n",
    "    .rollouts(num_rollout_workers=0)\n",
    "    .resources(num_gpus=1)\n",
    "    .environment(env='StockExchangeEnv-v0', env_config={'price_data': hourly_prices[\"price\"].to_numpy(), 'volume_data': hourly_prices[\"amount\"].to_numpy(), 'initial_cash': 10_000})\n",
    "    .build()\n",
    ")\n",
    "\n",
    "for i in range(500):\n",
    "    result = dqn.train()\n",
    "    print(f'Step: {result[\"training_iteration\"]}\\tMean return: {result[\"episode_reward_mean\"]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Variable.__del__ at 0x7f17eafc2950>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/tkinter/__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[all] in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (0.26.3)\r\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (0.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (1.24.3)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.2.1)\r\n",
      "Collecting mujoco-py<2.2,>=2.1\r\n",
      "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m12.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting mujoco==2.2\r\n",
      "  Downloading mujoco-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: imageio>=2.14.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.28.1)\r\n",
      "Collecting gym==0.26.2\r\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting box2d-py==2.3.5\r\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m374.4/374.4 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting opencv-python>=3.0\r\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.8/61.8 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m�\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m61.8/61.8 MB\u001B[0m \u001B[31m115.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting swig==4.*\r\n",
      "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m24.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting ale-py~=0.8.0\r\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: matplotlib>=3.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (3.7.1)\r\n",
      "Requirement already satisfied: pygame==2.1.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.1.0)\r\n",
      "Collecting moviepy>=1.0.0\r\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m388.3/388.3 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting pytest==7.0.1\r\n",
      "  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m297.0/297.0 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: lz4>=3.1.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (4.3.2)\r\n",
      "Collecting gym-notices>=0.0.4\r\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\r\n",
      "Collecting glfw\r\n",
      "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.8/207.8 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco==2.2->gymnasium[all]) (1.4.0)\r\n",
      "Collecting pyopengl\r\n",
      "  Using cached PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\r\n",
      "Collecting tomli>=1.0.0\r\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: packaging in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from pytest==7.0.1->gymnasium[all]) (23.1)\r\n",
      "Collecting pluggy<2.0,>=0.12\r\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting py>=1.8.2\r\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from pytest==7.0.1->gymnasium[all]) (23.1.0)\r\n",
      "Collecting iniconfig\r\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\r\n",
      "Collecting importlib-resources\r\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from ale-py~=0.8.0->gymnasium[all]) (4.5.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from imageio>=2.14.1->gymnasium[all]) (9.5.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (4.39.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (1.0.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (0.11.0)\r\n",
      "Collecting decorator<5.0,>=4.0.2\r\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[all]) (4.65.0)\r\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[all]) (2.28.1)\r\n",
      "Collecting proglog<=1.0.0\r\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\r\n",
      "Collecting imageio_ffmpeg>=0.2.0\r\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.9/26.9 MB\u001B[0m \u001B[31m23.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting fasteners~=0.15\r\n",
      "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: Cython>=0.27.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco-py<2.2,>=2.1->gymnasium[all]) (0.29.34)\r\n",
      "Requirement already satisfied: cffi>=1.10 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco-py<2.2,>=2.1->gymnasium[all]) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1->gymnasium[all]) (2.21)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->gymnasium[all]) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (1.26.13)\r\n",
      "Building wheels for collected packages: box2d-py, gym, moviepy\r\n",
      "  Building wheel for box2d-py (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[16 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m Using setuptools (version 66.0.0).\r\n",
      "  \u001B[31m   \u001B[0m running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m running build\r\n",
      "  \u001B[31m   \u001B[0m running build_py\r\n",
      "  \u001B[31m   \u001B[0m creating build\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/Box2D.py -> build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/__init__.py -> build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310/Box2D/b2\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/b2/__init__.py -> build/lib.linux-x86_64-cpython-310/Box2D/b2\r\n",
      "  \u001B[31m   \u001B[0m running build_ext\r\n",
      "  \u001B[31m   \u001B[0m building 'Box2D._Box2D' extension\r\n",
      "  \u001B[31m   \u001B[0m swigging Box2D/Box2D.i to Box2D/Box2D_wrap.cpp\r\n",
      "  \u001B[31m   \u001B[0m swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D/Box2D_wrap.cpp Box2D/Box2D.i\r\n",
      "  \u001B[31m   \u001B[0m error: command 'swig' failed: No such file or directory\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for box2d-py\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25h  Running setup.py clean for box2d-py\r\n",
      "  Building wheel for gym (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827631 sha256=ff39f2ad30a47272e9a22a0df7811f42e7192b341213693e30d3603b76f80b9f\r\n",
      "  Stored in directory: /home/fassty/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\r\n",
      "  Building wheel for moviepy (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110727 sha256=bb5f77d5cc61fe09a780676646e407509e4b67906f2a891d8f78e00b97f30dda\r\n",
      "  Stored in directory: /home/fassty/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\r\n",
      "Successfully built gym moviepy\r\n",
      "Failed to build box2d-py\r\n",
      "Installing collected packages: swig, pyopengl, gym-notices, glfw, box2d-py, tomli, py, proglog, pluggy, opencv-python, mujoco, iniconfig, importlib-resources, imageio_ffmpeg, gym, fasteners, decorator, pytest, mujoco-py, moviepy, ale-py\r\n",
      "  Running setup.py install for box2d-py ... \u001B[?25l-\u001B[2m\u001B[1m\u001B[33m(autoscaler +24h56m9s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "done\r\n",
      "\u001B[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[?25h  Attempting uninstall: decorator\r\n",
      "    Found existing installation: decorator 5.1.1\r\n",
      "    Uninstalling decorator-5.1.1:\r\n",
      "      Successfully uninstalled decorator-5.1.1\r\n",
      "Successfully installed ale-py-0.8.1 box2d-py-2.3.5 decorator-4.4.2 fasteners-0.18 glfw-2.5.9 gym-0.26.2 gym-notices-0.0.8 imageio_ffmpeg-0.4.8 importlib-resources-5.12.0 iniconfig-2.0.0 moviepy-1.0.3 mujoco-2.2.0 mujoco-py-2.1.2.14 opencv-python-4.7.0.72 pluggy-1.0.0 proglog-0.1.10 py-1.11.0 pyopengl-3.1.6 pytest-7.0.1 swig-4.1.1 tomli-2.0.1\r\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_prices['price'].isna().any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
