{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7f7ff43e2960>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import talib\n",
    "import gymnasium as gym\n",
    "import ray\n",
    "\n",
    "from rl_trading.simulation.env import StockExchangeEnv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     or model.view_requirements.get(\"state_in_0\") is not None\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m AssertionError: R2D2 requires its model to be a recurrent one! Try using `model.use_lstm` or `model.use_attention` in your config to auto-wrap your model with an LSTM- or attention net.\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=817840)\u001B[0m /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\u001B[32m [repeated 8x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=817840)\u001B[0m   if not isinstance(terminated, (bool, np.bool8)):\u001B[32m [repeated 8x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m 2023-05-13 22:02:06,075\tERROR worker.py:844 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001B[36mray::RolloutWorker.__init__()\u001B[39m (pid=816406, ip=192.168.0.222, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7efa49db6740>)\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m   File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/policy/policy_template.py\", line 279, in __init__\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     self._update_policy_map(policy_dict=self.policy_dict)\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m   File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1985, in _update_policy_map\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     self._build_policy_map(\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m   File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 2097, in _build_policy_map\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     new_policy = create_policy_for_framework(\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m   File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 142, in create_policy_for_framework\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     return policy_class(observation_space, action_space, merged_config)\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m     self.model, dist_class = make_model_and_action_dist(\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=816406)\u001B[0m   File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/algorithms/r2d2/r2d2_torch_policy.py\", line 73, in build_r2d2_model_and_distribution\u001B[32m [repeated 7x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[36m(autoscaler +3m42s)\u001B[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001B[2m\u001B[1m\u001B[33m(autoscaler +3m42s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mr2d2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m R2D2Config\n\u001B[1;32m      3\u001B[0m algo \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m      4\u001B[0m     \u001B[43mR2D2Config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rollout_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menvironment\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCartPole-v1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplay_buffer_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapacity\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100_000\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muse_lstm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m----> 8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     11\u001B[0m render_env \u001B[38;5;241m=\u001B[39m gym\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCartPole-v1\u001B[39m\u001B[38;5;124m'\u001B[39m, render_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm_config.py:1071\u001B[0m, in \u001B[0;36mAlgorithmConfig.build\u001B[0;34m(self, env, logger_creator, use_copy)\u001B[0m\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgo_class, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1069\u001B[0m     algo_class \u001B[38;5;241m=\u001B[39m get_trainable_cls(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgo_class)\n\u001B[0;32m-> 1071\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgo_class\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1072\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muse_copy\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1073\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger_creator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogger_creator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1074\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:466\u001B[0m, in \u001B[0;36mAlgorithm.__init__\u001B[0;34m(self, config, env, logger_creator, **kwargs)\u001B[0m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;66;03m# available. We want to make sure the metrics are always present\u001B[39;00m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001B[39;00m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;66;03m# when we use these as stopping criteria.\u001B[39;00m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_metrics \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mevaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    460\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepisode_reward_max\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mnan,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    463\u001B[0m     }\n\u001B[1;32m    464\u001B[0m }\n\u001B[0;32m--> 466\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger_creator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger_creator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001B[39;00m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001B[39;00m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/tune/trainable/trainable.py:169\u001B[0m, in \u001B[0;36mTrainable.__init__\u001B[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout, sync_config)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_ip \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mutil\u001B[38;5;241m.\u001B[39mget_node_ip_address()\n\u001B[0;32m--> 169\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m setup_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m setup_time \u001B[38;5;241m>\u001B[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:592\u001B[0m, in \u001B[0;36mAlgorithm.setup\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;66;03m# Only if user did not override `_init()`:\u001B[39;00m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _init \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;66;03m# - Create rollout workers here automatically.\u001B[39;00m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;66;03m# - Run the execution plan to create the local iterator to `next()`\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;66;03m#   in each training iteration.\u001B[39;00m\n\u001B[1;32m    590\u001B[0m     \u001B[38;5;66;03m# This matches the behavior of using `build_trainer()`, which\u001B[39;00m\n\u001B[1;32m    591\u001B[0m     \u001B[38;5;66;03m# has been deprecated.\u001B[39;00m\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers \u001B[38;5;241m=\u001B[39m \u001B[43mWorkerSet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43menv_creator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv_creator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefault_policy_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_default_policy_class\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_rollout_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;66;03m# TODO (avnishn): Remove the execution plan API by q1 2023\u001B[39;00m\n\u001B[1;32m    603\u001B[0m     \u001B[38;5;66;03m# Function defining one single training iteration's behavior.\u001B[39;00m\n\u001B[1;32m    604\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_disable_execution_plan_api:\n\u001B[1;32m    605\u001B[0m         \u001B[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:172\u001B[0m, in \u001B[0;36mWorkerSet.__init__\u001B[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _setup:\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalidate_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_worker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001B[39;00m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001B[39;00m\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;66;03m# constructor).\u001B[39;00m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m RayActorError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001B[39;00m\n\u001B[1;32m    183\u001B[0m         \u001B[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001B[39;00m\n\u001B[1;32m    184\u001B[0m         \u001B[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001B[39;00m\n\u001B[1;32m    185\u001B[0m         \u001B[38;5;66;03m# errors.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:242\u001B[0m, in \u001B[0;36mWorkerSet._setup\u001B[0;34m(self, validate_env, config, num_workers, local_worker)\u001B[0m\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ds_shards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# Create a number of @ray.remote workers.\u001B[39;00m\n\u001B[0;32m--> 242\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_workers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_workers_after_construction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# get the observation- and action spaces for each policy from\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# the first remote worker (which does have an env).\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    251\u001B[0m     local_worker\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__worker_manager\u001B[38;5;241m.\u001B[39mnum_actors() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39mcreate_env_on_local_worker\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39mobservation_space \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39maction_space)\n\u001B[1;32m    255\u001B[0m ):\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:629\u001B[0m, in \u001B[0;36mWorkerSet.add_workers\u001B[0;34m(self, num_workers, validate)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;66;03m# Validate here, whether all remote workers have been constructed properly\u001B[39;00m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;66;03m# and are \"up and running\". Establish initial states.\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validate:\n\u001B[0;32m--> 629\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__worker_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforeach_actor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massert_healthy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;66;03m# Simiply raise the error, which will get handled by the try-except\u001B[39;00m\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;66;03m# clause around the _setup().\u001B[39;00m\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result\u001B[38;5;241m.\u001B[39mok:\n\u001B[1;32m    635\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m result\u001B[38;5;241m.\u001B[39mget()\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py:599\u001B[0m, in \u001B[0;36mFaultTolerantActorManager.foreach_actor\u001B[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001B[0m\n\u001B[1;32m    590\u001B[0m     func, remote_actor_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_filter_func_and_remote_actor_id_by_state(\n\u001B[1;32m    591\u001B[0m         func, remote_actor_ids\n\u001B[1;32m    592\u001B[0m     )\n\u001B[1;32m    594\u001B[0m remote_calls \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__call_actors(\n\u001B[1;32m    595\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m    596\u001B[0m     remote_actor_ids\u001B[38;5;241m=\u001B[39mremote_actor_ids,\n\u001B[1;32m    597\u001B[0m )\n\u001B[0;32m--> 599\u001B[0m _, remote_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__fetch_result\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_actor_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremote_actor_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremote_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_seconds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_seconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmark_healthy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmark_healthy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m remote_results\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py:467\u001B[0m, in \u001B[0;36mFaultTolerantActorManager.__fetch_result\u001B[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001B[0m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m remote_calls:\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [], RemoteCallResults()\n\u001B[0;32m--> 467\u001B[0m ready, _ \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    471\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001B[39;49;00m\n\u001B[1;32m    472\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetch_local\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001B[39;00m\n\u001B[1;32m    476\u001B[0m remote_results \u001B[38;5;241m=\u001B[39m RemoteCallResults()\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/_private/worker.py:2719\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_refs, num_returns, timeout, fetch_local)\u001B[0m\n\u001B[1;32m   2717\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeout \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m6\u001B[39m\n\u001B[1;32m   2718\u001B[0m timeout_milliseconds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m-> 2719\u001B[0m ready_ids, remaining_ids \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcore_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_milliseconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_task_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetch_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2725\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ready_ids, remaining_ids\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:1870\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.wait\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:201\u001B[0m, in \u001B[0;36mray._raylet.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.r2d2 import R2D2Config\n",
    "\n",
    "algo = (\n",
    "    R2D2Config()\n",
    "    .rollouts(num_rollout_workers=8)\n",
    "    .environment('CartPole-v1')\n",
    "    .training(replay_buffer_config={'capacity': 100_000}, model={'use_lstm': True})\n",
    "    .build()\n",
    ")\n",
    "\n",
    "render_env = gym.make('CartPole-v1', render_mode='human')\n",
    "\n",
    "for i in range(10):\n",
    "    result = algo.train()\n",
    "    print(f'Mean return: {result[\"episode_reward_mean\"]}')\n",
    "    if i % 5 == 0:\n",
    "        state, done = render_env.reset()[0], False\n",
    "        while not done:\n",
    "            render_env.render()\n",
    "            action = algo.compute_single_action(state)\n",
    "            state, reward, terminated, truncated, _ = render_env.step(action)\n",
    "            done = terminated or truncated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "              amount    price\ntimestamp                    \n1502942460  1.775183  4261.48\n1502942520  0.000000  4261.48\n1502942580  0.261074  4280.56\n1502942640  0.012008  4261.48\n1502942700  0.140796  4261.48",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1502942460</th>\n      <td>1.775183</td>\n      <td>4261.48</td>\n    </tr>\n    <tr>\n      <th>1502942520</th>\n      <td>0.000000</td>\n      <td>4261.48</td>\n    </tr>\n    <tr>\n      <th>1502942580</th>\n      <td>0.261074</td>\n      <td>4280.56</td>\n    </tr>\n    <tr>\n      <th>1502942640</th>\n      <td>0.012008</td>\n      <td>4261.48</td>\n    </tr>\n    <tr>\n      <th>1502942700</th>\n      <td>0.140796</td>\n      <td>4261.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                           price     amount\ntimestamp                                  \n2017-08-17 04:00:00  4311.749242  46.620743\n2017-08-17 05:00:00  4315.320000  23.795182\n2017-08-17 06:00:00  4324.350000   7.229691\n2017-08-17 07:00:00  4334.000000   2.482438\n2017-08-17 08:00:00  4360.690000   2.933618",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>amount</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-17 04:00:00</th>\n      <td>4311.749242</td>\n      <td>46.620743</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 05:00:00</th>\n      <td>4315.320000</td>\n      <td>23.795182</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 06:00:00</th>\n      <td>4324.350000</td>\n      <td>7.229691</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 07:00:00</th>\n      <td>4334.000000</td>\n      <td>2.482438</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 08:00:00</th>\n      <td>4360.690000</td>\n      <td>2.933618</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "              price       amount\ntimestamp                       \n2017-08-17  4285.08   795.150377\n2017-08-18  4115.40  1199.699723\n2017-08-19  4139.98   381.498304\n2017-08-20  4069.13   466.704213\n2017-08-21  4016.00   691.925435",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>amount</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-17</th>\n      <td>4285.08</td>\n      <td>795.150377</td>\n    </tr>\n    <tr>\n      <th>2017-08-18</th>\n      <td>4115.40</td>\n      <td>1199.699723</td>\n    </tr>\n    <tr>\n      <th>2017-08-19</th>\n      <td>4139.98</td>\n      <td>381.498304</td>\n    </tr>\n    <tr>\n      <th>2017-08-20</th>\n      <td>4069.13</td>\n      <td>466.704213</td>\n    </tr>\n    <tr>\n      <th>2017-08-21</th>\n      <td>4016.00</td>\n      <td>691.925435</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  price       amount\ntimestamp                           \n2017-08-20  4069.130000  2843.052617\n2017-08-27  4346.972375  4599.745731\n2017-09-03  4505.581286  4753.873083\n2017-09-10  4150.230425  6381.632307\n2017-09-17  3699.015885  8107.831437",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>amount</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-20</th>\n      <td>4069.130000</td>\n      <td>2843.052617</td>\n    </tr>\n    <tr>\n      <th>2017-08-27</th>\n      <td>4346.972375</td>\n      <td>4599.745731</td>\n    </tr>\n    <tr>\n      <th>2017-09-03</th>\n      <td>4505.581286</td>\n      <td>4753.873083</td>\n    </tr>\n    <tr>\n      <th>2017-09-10</th>\n      <td>4150.230425</td>\n      <td>6381.632307</td>\n    </tr>\n    <tr>\n      <th>2017-09-17</th>\n      <td>3699.015885</td>\n      <td>8107.831437</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  price        amount\ntimestamp                            \n2017-08-20  4069.130000   2843.052617\n2017-09-03  4505.581286   9353.618814\n2017-09-17  3699.015885  14489.463744\n2017-10-01  4378.480000  11690.657902\n2017-10-15  5699.844347  12620.142176",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>amount</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-20</th>\n      <td>4069.130000</td>\n      <td>2843.052617</td>\n    </tr>\n    <tr>\n      <th>2017-09-03</th>\n      <td>4505.581286</td>\n      <td>9353.618814</td>\n    </tr>\n    <tr>\n      <th>2017-09-17</th>\n      <td>3699.015885</td>\n      <td>14489.463744</td>\n    </tr>\n    <tr>\n      <th>2017-10-01</th>\n      <td>4378.480000</td>\n      <td>11690.657902</td>\n    </tr>\n    <tr>\n      <th>2017-10-15</th>\n      <td>5699.844347</td>\n      <td>12620.142176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                   price         amount\ntimestamp                              \n2017-08-31   4724.885015   10015.640272\n2017-09-30   4347.630427   27634.043533\n2017-10-31   6476.467415   41625.312848\n2017-11-30   9846.140933  108483.883600\n2017-12-31  13735.118870  408477.194296",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>amount</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-31</th>\n      <td>4724.885015</td>\n      <td>10015.640272</td>\n    </tr>\n    <tr>\n      <th>2017-09-30</th>\n      <td>4347.630427</td>\n      <td>27634.043533</td>\n    </tr>\n    <tr>\n      <th>2017-10-31</th>\n      <td>6476.467415</td>\n      <td>41625.312848</td>\n    </tr>\n    <tr>\n      <th>2017-11-30</th>\n      <td>9846.140933</td>\n      <td>108483.883600</td>\n    </tr>\n    <tr>\n      <th>2017-12-31</th>\n      <td>13735.118870</td>\n      <td>408477.194296</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exchange_data = pd.read_hdf('../data/binance_BTC_USDT.h5')\n",
    "exchange_data.sort_index(inplace=True)\n",
    "exchange_data = exchange_data[~exchange_data.index.duplicated(keep='first')]\n",
    "exchange_data = exchange_data.reindex(np.arange(exchange_data.index[0], exchange_data.index[-1] + 1, 60))\n",
    "exchange_data['price'] = exchange_data['price'].ffill()\n",
    "exchange_data['amount'] = exchange_data['amount'].fillna(value=0)\n",
    "\n",
    "display(exchange_data.head(5))\n",
    "\n",
    "exchange_data.index = pd.to_datetime(exchange_data.index * 1e9)\n",
    "price_data_1m = exchange_data['price'].to_numpy()\n",
    "volume_data_1m = exchange_data['amount'].to_numpy()\n",
    "\n",
    "agg_mapping = {'price': 'last', 'amount': 'sum'}\n",
    "hourly_data = exchange_data.groupby(pd.Grouper(freq='1h')).agg(agg_mapping)\n",
    "daily_data = exchange_data.groupby(pd.Grouper(freq='1d')).agg(agg_mapping)\n",
    "weekly_data = exchange_data.groupby(pd.Grouper(freq='1w')).agg(agg_mapping)\n",
    "biweekly_data = exchange_data.groupby(pd.Grouper(freq='2w')).agg(agg_mapping)\n",
    "monthly_data = exchange_data.groupby(pd.Grouper(freq='1M')).agg(agg_mapping)\n",
    "\n",
    "display(hourly_data.head(5))\n",
    "display(daily_data.head(5))\n",
    "display(weekly_data.head(5))\n",
    "display(biweekly_data.head(5))\n",
    "display(monthly_data.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ohlcv_1h = exchange_data['price'].groupby(pd.Grouper(freq='1h')).agg(open='first', high='max', low='min', close='last')\n",
    "ohlcv_1h['volume'] = exchange_data['amount'].groupby(pd.Grouper(freq='1h')).agg('sum')\n",
    "ohlcv_1h = ohlcv_1h.loc[pd.Timestamp('2017-08-18 00:00:00'):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                             open          high           low         close   \ntimestamp                                                                     \n2017-08-18 00:00:00   4285.080000   4319.986355   4249.317527   4273.052256  \\\n2017-08-18 01:00:00   4286.530000   4286.530000   4162.771089   4244.618032   \n2017-08-18 02:00:00   4244.618032   4288.781267   4234.441705   4267.590000   \n2017-08-18 03:00:00   4267.590000   4308.700000   4244.770000   4279.236936   \n2017-08-18 04:00:00   4279.702720   4292.390000   4237.032409   4287.920000   \n...                           ...           ...           ...           ...   \n2022-12-08 02:00:00  16830.380506  16872.627489  16811.416299  16843.812041   \n2022-12-08 03:00:00  16843.887596  16862.316315  16828.768225  16832.783395   \n2022-12-08 04:00:00  16834.000203  16846.291704  16812.830201  16825.994048   \n2022-12-08 05:00:00  16819.488906  16823.667239  16804.183731  16823.667239   \n2022-12-08 06:00:00  16820.593849  16820.593849  16812.328981  16812.328981   \n\n                          volume            tp  \ntimestamp                                       \n2017-08-18 00:00:00    82.378434   4280.785380  \n2017-08-18 01:00:00    75.741923   4231.306374  \n2017-08-18 02:00:00    53.841434   4263.604324  \n2017-08-18 03:00:00    63.688138   4277.568979  \n2017-08-18 04:00:00    51.340629   4272.447470  \n...                          ...           ...  \n2022-12-08 02:00:00  8047.727090  16842.618610  \n2022-12-08 03:00:00  7780.884650  16841.289312  \n2022-12-08 04:00:00  8179.241020  16828.371985  \n2022-12-08 05:00:00  6115.983030  16817.172736  \n2022-12-08 06:00:00   472.507280  16815.083937  \n\n[46519 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tp</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-18 00:00:00</th>\n      <td>4285.080000</td>\n      <td>4319.986355</td>\n      <td>4249.317527</td>\n      <td>4273.052256</td>\n      <td>82.378434</td>\n      <td>4280.785380</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 01:00:00</th>\n      <td>4286.530000</td>\n      <td>4286.530000</td>\n      <td>4162.771089</td>\n      <td>4244.618032</td>\n      <td>75.741923</td>\n      <td>4231.306374</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 02:00:00</th>\n      <td>4244.618032</td>\n      <td>4288.781267</td>\n      <td>4234.441705</td>\n      <td>4267.590000</td>\n      <td>53.841434</td>\n      <td>4263.604324</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 03:00:00</th>\n      <td>4267.590000</td>\n      <td>4308.700000</td>\n      <td>4244.770000</td>\n      <td>4279.236936</td>\n      <td>63.688138</td>\n      <td>4277.568979</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 04:00:00</th>\n      <td>4279.702720</td>\n      <td>4292.390000</td>\n      <td>4237.032409</td>\n      <td>4287.920000</td>\n      <td>51.340629</td>\n      <td>4272.447470</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 02:00:00</th>\n      <td>16830.380506</td>\n      <td>16872.627489</td>\n      <td>16811.416299</td>\n      <td>16843.812041</td>\n      <td>8047.727090</td>\n      <td>16842.618610</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 03:00:00</th>\n      <td>16843.887596</td>\n      <td>16862.316315</td>\n      <td>16828.768225</td>\n      <td>16832.783395</td>\n      <td>7780.884650</td>\n      <td>16841.289312</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 04:00:00</th>\n      <td>16834.000203</td>\n      <td>16846.291704</td>\n      <td>16812.830201</td>\n      <td>16825.994048</td>\n      <td>8179.241020</td>\n      <td>16828.371985</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:00:00</th>\n      <td>16819.488906</td>\n      <td>16823.667239</td>\n      <td>16804.183731</td>\n      <td>16823.667239</td>\n      <td>6115.983030</td>\n      <td>16817.172736</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:00:00</th>\n      <td>16820.593849</td>\n      <td>16820.593849</td>\n      <td>16812.328981</td>\n      <td>16812.328981</td>\n      <td>472.507280</td>\n      <td>16815.083937</td>\n    </tr>\n  </tbody>\n</table>\n<p>46519 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlcv_1h['tp'] = (ohlcv_1h['high'] + ohlcv_1h['low'] + ohlcv_1h['close']) / 3\n",
    "ohlcv_1h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                             open          high           low         close   \ntimestamp                                                                     \n2017-08-18 00:00:00   4285.080000   4319.986355   4249.317527   4273.052256  \\\n2017-08-18 01:00:00   4286.530000   4286.530000   4162.771089   4244.618032   \n2017-08-18 02:00:00   4244.618032   4288.781267   4234.441705   4267.590000   \n2017-08-18 03:00:00   4267.590000   4308.700000   4244.770000   4279.236936   \n2017-08-18 04:00:00   4279.702720   4292.390000   4237.032409   4287.920000   \n...                           ...           ...           ...           ...   \n2022-12-08 02:00:00  16830.380506  16872.627489  16811.416299  16843.812041   \n2022-12-08 03:00:00  16843.887596  16862.316315  16828.768225  16832.783395   \n2022-12-08 04:00:00  16834.000203  16846.291704  16812.830201  16825.994048   \n2022-12-08 05:00:00  16819.488906  16823.667239  16804.183731  16823.667239   \n2022-12-08 06:00:00  16820.593849  16820.593849  16812.328981  16812.328981   \n\n                          volume            tp          vwap  \ntimestamp                                                     \n2017-08-18 00:00:00    82.378434   4280.785380   4280.785380  \n2017-08-18 01:00:00    75.741923   4231.306374   4257.084225  \n2017-08-18 02:00:00    53.841434   4263.604324   4258.740427  \n2017-08-18 03:00:00    63.688138   4277.568979   4263.090710  \n2017-08-18 04:00:00    51.340629   4272.447470   4264.559811  \n...                          ...           ...           ...  \n2022-12-08 02:00:00  8047.727090  16842.618610  16833.025808  \n2022-12-08 03:00:00  7780.884650  16841.289312  16834.805009  \n2022-12-08 04:00:00  8179.241020  16828.371985  16833.617732  \n2022-12-08 05:00:00  6115.983030  16817.172736  16831.623478  \n2022-12-08 06:00:00   472.507280  16815.083937  16831.469959  \n\n[46519 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tp</th>\n      <th>vwap</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-18 00:00:00</th>\n      <td>4285.080000</td>\n      <td>4319.986355</td>\n      <td>4249.317527</td>\n      <td>4273.052256</td>\n      <td>82.378434</td>\n      <td>4280.785380</td>\n      <td>4280.785380</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 01:00:00</th>\n      <td>4286.530000</td>\n      <td>4286.530000</td>\n      <td>4162.771089</td>\n      <td>4244.618032</td>\n      <td>75.741923</td>\n      <td>4231.306374</td>\n      <td>4257.084225</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 02:00:00</th>\n      <td>4244.618032</td>\n      <td>4288.781267</td>\n      <td>4234.441705</td>\n      <td>4267.590000</td>\n      <td>53.841434</td>\n      <td>4263.604324</td>\n      <td>4258.740427</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 03:00:00</th>\n      <td>4267.590000</td>\n      <td>4308.700000</td>\n      <td>4244.770000</td>\n      <td>4279.236936</td>\n      <td>63.688138</td>\n      <td>4277.568979</td>\n      <td>4263.090710</td>\n    </tr>\n    <tr>\n      <th>2017-08-18 04:00:00</th>\n      <td>4279.702720</td>\n      <td>4292.390000</td>\n      <td>4237.032409</td>\n      <td>4287.920000</td>\n      <td>51.340629</td>\n      <td>4272.447470</td>\n      <td>4264.559811</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 02:00:00</th>\n      <td>16830.380506</td>\n      <td>16872.627489</td>\n      <td>16811.416299</td>\n      <td>16843.812041</td>\n      <td>8047.727090</td>\n      <td>16842.618610</td>\n      <td>16833.025808</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 03:00:00</th>\n      <td>16843.887596</td>\n      <td>16862.316315</td>\n      <td>16828.768225</td>\n      <td>16832.783395</td>\n      <td>7780.884650</td>\n      <td>16841.289312</td>\n      <td>16834.805009</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 04:00:00</th>\n      <td>16834.000203</td>\n      <td>16846.291704</td>\n      <td>16812.830201</td>\n      <td>16825.994048</td>\n      <td>8179.241020</td>\n      <td>16828.371985</td>\n      <td>16833.617732</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:00:00</th>\n      <td>16819.488906</td>\n      <td>16823.667239</td>\n      <td>16804.183731</td>\n      <td>16823.667239</td>\n      <td>6115.983030</td>\n      <td>16817.172736</td>\n      <td>16831.623478</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:00:00</th>\n      <td>16820.593849</td>\n      <td>16820.593849</td>\n      <td>16812.328981</td>\n      <td>16812.328981</td>\n      <td>472.507280</td>\n      <td>16815.083937</td>\n      <td>16831.469959</td>\n    </tr>\n  </tbody>\n</table>\n<p>46519 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vwap(df):\n",
    "    df['vwap'] = (df['tp'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "    return df\n",
    "\n",
    "ohlcv_1h.groupby(ohlcv_1h.index.date).apply(vwap).droplevel(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2017-08-17 00:00:00')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2017-08-17 04:03:00').floor(freq='1d')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "exchange_data = exchange_data.loc[pd.Timestamp('2017-08-18 00:00:00'):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67 s ± 2.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def vwap(df):\n",
    "    df['vwap'] = (df['price'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "    return df\n",
    "\n",
    "exchange_data.groupby(exchange_data.index.date).apply(vwap).droplevel(0).ffill().bfill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "SimulationConfig(granularity={}, max_steps=1440, initial_cash=10000)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl_trading.simulation.env import SimulationConfig\n",
    "\n",
    "SimulationConfig()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 1.65069189e+04,  1.65337229e+04,  1.65026921e+04,  1.64990000e+04,\n         7.08373999e+01,  1.65120371e+04,  1.64793043e+04,  1.65759318e+04,\n         1.65456385e+04,  4.81486633e+01,  1.66394564e+04,  1.65062512e+04,\n        -5.05073731e+00,  1.86984973e+04,  2.19959123e+04,  4.21926302e+01,\n         1.97912144e+04,  1.44120051e+04,  2.31243044e+02,  1.00000000e+04,\n         0.00000000e+00]),\n {})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl_trading.data.provider import MarketDataProvider\n",
    "from rl_trading.data.indicators import *\n",
    "\n",
    "env = StockExchangeEnv0(\n",
    "    state_config={\n",
    "        'market_state': ['price', 'vwap'],\n",
    "        'technical_indicators': [\n",
    "            (EMA, dict(timeperiod=5), '1min'),\n",
    "            (EMA, dict(timeperiod=13), '1min'),\n",
    "            (RSI, dict(timeperiod=7), '1min'),\n",
    "            (BBANDS, dict(timeperiod=10), '1min'),\n",
    "            (EMA, dict(timeperiod=20), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1h'),\n",
    "            (RSI, dict(timeperiod=14), '1h'),\n",
    "            (BBANDS, dict(timeperiod=20), '1h'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1d'),\n",
    "            (EMA, dict(timeperiod=200), '1d'),\n",
    "            (RSI, dict(timeperiod=14), '1d'),\n",
    "            (BBANDS, dict(timeperiod=20), '1d'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1d'),\n",
    "        ],\n",
    "    })\n",
    "env.market_data.keys()\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "3000"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:05:37,883\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=1043977)\u001B[0m 2023-05-11 19:05:48,486\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1    Mean return: 11.054210175418575\t +- 682.8472323183978\n",
      "Step: 2    Mean return: 22.51906906119217\t +- 701.8839957572454\n",
      "Step: 3    Mean return: 41.6492745353601\t +- 1421.322676290094\n",
      "Step: 4    Mean return: 78.35231343930818\t +- 1421.322676290094\n",
      "Step: 5    Mean return: 94.95856714453976\t +- 1476.5776312627913\n",
      "Step: 6    Mean return: 65.45305453670181\t +- 1671.729725747693\n",
      "Step: 7    Mean return: 89.62004549320326\t +- 1671.729725747693\n",
      "Step: 8    Mean return: 79.98371282023513\t +- 1671.729725747693\n",
      "Step: 9    Mean return: 57.37391732418186\t +- 1624.297522403509\n",
      "Step: 10   Mean return: 51.99980404636202\t +- 1624.297522403509\n",
      "Step: 11   Mean return: 42.257349389383656\t +- 1232.9795344705617\n",
      "Step: 12   Mean return: 58.63088455451591\t +- 1298.0162584396148\n",
      "Step: 13   Mean return: 48.12888751001268\t +- 1192.3565403888624\n",
      "Step: 14   Mean return: 43.250097994843216\t +- 1808.8996616474542\n",
      "Step: 15   Mean return: 48.581189434795235\t +- 2361.2751753598823\n",
      "Step: 16   Mean return: 49.005706086195296\t +- 2361.2751753598823\n",
      "Step: 17   Mean return: 32.90449811688845\t +- 2361.2751753598823\n",
      "Step: 18   Mean return: 30.85714638445648\t +- 2361.2751753598823\n",
      "Step: 19   Mean return: 15.724297402398442\t +- 2361.2751753598823\n",
      "Step: 20   Mean return: 47.789534117590414\t +- 1973.8704428344809\n",
      "Step: 21   Mean return: 35.021014317895606\t +- 1460.9708835025103\n",
      "Step: 22   Mean return: 27.51876301542916\t +- 1279.5457994735134\n",
      "Step: 23   Mean return: 51.37632251372259\t +- 2760.5610562287784\n",
      "Step: 24   Mean return: 79.98165839411303\t +- 2760.5610562287784\n",
      "Step: 25   Mean return: 82.70334423362729\t +- 2760.5610562287784\n",
      "Step: 26   Mean return: 101.61341122124479\t +- 2760.5610562287784\n",
      "Step: 27   Mean return: 101.33940177853758\t +- 2760.5610562287784\n",
      "Step: 28   Mean return: 146.96176159103035\t +- 2623.645489157956\n",
      "Step: 29   Mean return: 129.07831050865468\t +- 2623.645489157956\n",
      "Step: 30   Mean return: 108.32665489060346\t +- 2623.645489157956\n",
      "Step: 31   Mean return: 108.3773534228871\t +- 2623.645489157956\n",
      "Step: 32   Mean return: 101.73165907225466\t +- 2623.645489157956\n",
      "Step: 33   Mean return: 117.31614180344206\t +- 2796.426882141337\n",
      "Step: 34   Mean return: 77.85380530050303\t +- 2379.795662607956\n",
      "Step: 35   Mean return: 86.22201812588847\t +- 2216.56043637698\n",
      "Step: 36   Mean return: 107.42859866618373\t +- 2216.56043637698\n",
      "Step: 37   Mean return: 77.45289868849379\t +- 2216.56043637698\n",
      "Step: 38   Mean return: 89.77472656773202\t +- 2216.56043637698\n",
      "Step: 39   Mean return: 83.24705739380623\t +- 2173.517685957966\n",
      "Step: 40   Mean return: 67.12566346536116\t +- 1480.4466918642138\n",
      "Step: 41   Mean return: 86.35192913190161\t +- 1393.2015109133263\n",
      "Step: 42   Mean return: 76.49944668121701\t +- 1328.080581980883\n",
      "Step: 43   Mean return: 93.143996335593\t +- 1328.080581980883\n",
      "Step: 44   Mean return: 94.37209274170287\t +- 1459.6444040656115\n",
      "Step: 45   Mean return: 102.30227782990029\t +- 1734.7971704963384\n",
      "Step: 46   Mean return: 117.57952378328856\t +- 1734.7971704963384\n",
      "Step: 47   Mean return: 103.21066315155977\t +- 1734.7971704963384\n",
      "Step: 48   Mean return: 55.93761550087243\t +- 1734.7971704963384\n",
      "Step: 49   Mean return: 51.6893048953584\t +- 1640.0307618577299\n",
      "Step: 50   Mean return: 62.79201368232947\t +- 1842.6657011969855\n",
      "Step: 51   Mean return: 65.72781412906376\t +- 1842.6657011969855\n",
      "Step: 52   Mean return: 72.40067546353183\t +- 1852.6424068214474\n",
      "Step: 53   Mean return: 75.3958613944062\t +- 1852.6424068214474\n",
      "Step: 54   Mean return: 96.99783203559493\t +- 1843.2369686373913\n",
      "Step: 55   Mean return: 98.1557456197514\t +- 1967.4758093065939\n",
      "Step: 56   Mean return: 76.06660917613071\t +- 1967.4758093065939\n",
      "Step: 57   Mean return: 68.67675969258067\t +- 1967.4758093065939\n",
      "Step: 58   Mean return: 66.47144850050292\t +- 1471.118769929466\n",
      "Step: 59   Mean return: 92.54626437486739\t +- 1471.118769929466\n",
      "Step: 60   Mean return: 87.36566745003867\t +- 1735.650826303181\n",
      "Step: 61   Mean return: 73.99423642072823\t +- 1735.650826303181\n",
      "Step: 62   Mean return: 94.68464342736532\t +- 1484.1535270173881\n",
      "Step: 63   Mean return: 68.75851097121878\t +- 3323.2974804936257\n",
      "Step: 64   Mean return: 68.25710236616\t +- 3323.2974804936257\n",
      "Step: 65   Mean return: 66.56068854046532\t +- 3323.2974804936257\n",
      "Step: 66   Mean return: 51.91981774224778\t +- 3323.2974804936257\n",
      "Step: 67   Mean return: 68.63193097177913\t +- 3350.833376335826\n",
      "Step: 68   Mean return: 58.28101477859729\t +- 3350.833376335826\n",
      "Step: 69   Mean return: 80.91322117011265\t +- 1829.433285159108\n",
      "Step: 70   Mean return: 71.30225815358537\t +- 1835.7055543387905\n",
      "Step: 71   Mean return: 63.88921307154536\t +- 1835.7055543387905\n",
      "Step: 72   Mean return: 80.1690159928262\t +- 2050.5529557586033\n",
      "Step: 73   Mean return: 90.1989713996208\t +- 2050.5529557586033\n",
      "Step: 74   Mean return: 86.94989312544052\t +- 2177.499352305047\n",
      "Step: 75   Mean return: 108.367015248992\t +- 2177.499352305047\n",
      "Step: 76   Mean return: 100.79763867094472\t +- 2177.499352305047\n",
      "Step: 77   Mean return: 133.23485807334347\t +- 2177.499352305047\n",
      "Step: 78   Mean return: 126.40976484960427\t +- 1959.069208578081\n",
      "Step: 79   Mean return: 141.37652094397126\t +- 1959.069208578081\n",
      "Step: 80   Mean return: 156.71283851029494\t +- 1778.7791711155223\n",
      "Step: 81   Mean return: 142.56774977408463\t +- 2073.294360418893\n",
      "Step: 82   Mean return: 133.57528676327595\t +- 2073.294360418893\n",
      "Step: 83   Mean return: 117.20641466310984\t +- 2073.294360418893\n",
      "Step: 84   Mean return: 99.06664030344409\t +- 2073.294360418893\n",
      "Step: 85   Mean return: 76.7206104841765\t +- 2073.294360418893\n",
      "Step: 86   Mean return: 78.37865630679839\t +- 2198.759296657845\n",
      "Step: 87   Mean return: 70.9965674866111\t +- 1740.4033828585398\n",
      "Step: 88   Mean return: 78.87445997794266\t +- 1740.4033828585398\n",
      "Step: 89   Mean return: 62.689920636061885\t +- 1740.4033828585398\n",
      "Step: 90   Mean return: 92.87727704607721\t +- 1740.4033828585398\n",
      "Step: 91   Mean return: 114.38709743713362\t +- 2021.3110647027133\n",
      "Step: 92   Mean return: 104.85219260912612\t +- 2021.3110647027133\n",
      "Step: 93   Mean return: 140.31516683125673\t +- 1801.2262157499572\n",
      "Step: 94   Mean return: 154.945832975499\t +- 1801.2262157499572\n",
      "Step: 95   Mean return: 165.9067473138865\t +- 1634.6782756249831\n",
      "Step: 96   Mean return: 184.15419277657188\t +- 1316.2641139286334\n",
      "Step: 97   Mean return: 184.50140881676023\t +- 1316.2641139286334\n",
      "Step: 98   Mean return: 159.13437938410337\t +- 1316.2641139286334\n",
      "Step: 99   Mean return: 144.84981624010305\t +- 1316.2641139286334\n",
      "Step: 100  Mean return: 116.43772646748369\t +- 1531.289589018861\n",
      "Step: 101  Mean return: 116.56851433500046\t +- 1581.549409316376\n",
      "Step: 102  Mean return: 102.90746881301908\t +- 1581.549409316376\n",
      "Step: 103  Mean return: 93.10618558611147\t +- 1581.549409316376\n",
      "Step: 104  Mean return: 169.63036597627237\t +- 2337.3431190439005\n",
      "Step: 105  Mean return: 191.40342704589793\t +- 2485.5238194215217\n",
      "Step: 106  Mean return: 225.17087248499914\t +- 2485.5238194215217\n",
      "Step: 107  Mean return: 252.9505370384589\t +- 2485.5238194215217\n",
      "Step: 108  Mean return: 261.2705637051411\t +- 2485.5238194215217\n",
      "Step: 109  Mean return: 264.39827012607464\t +- 2485.5238194215217\n",
      "Step: 110  Mean return: 202.63259638233646\t +- 2451.837099092989\n",
      "Step: 111  Mean return: 201.46611991199075\t +- 1705.648405687718\n",
      "Step: 112  Mean return: 200.64723914707653\t +- 2161.656080441482\n",
      "Step: 113  Mean return: 184.0440839726721\t +- 2161.656080441482\n",
      "Step: 114  Mean return: 192.387372344866\t +- 2161.656080441482\n",
      "Step: 115  Mean return: 214.2425251929301\t +- 2310.0570651560483\n",
      "Step: 116  Mean return: 242.2860727884061\t +- 3467.520349930186\n",
      "Step: 117  Mean return: 234.4567733017366\t +- 3467.520349930186\n",
      "Step: 118  Mean return: 265.55955369376517\t +- 3245.589853385056\n",
      "Step: 119  Mean return: 245.767747232177\t +- 3245.589853385056\n",
      "Step: 120  Mean return: 226.23950911607747\t +- 3245.589853385056\n",
      "Step: 121  Mean return: 195.947444995318\t +- 2353.6317917231427\n",
      "Step: 122  Mean return: 216.68823518182035\t +- 2353.6317917231427\n",
      "Step: 123  Mean return: 205.73980649961123\t +- 2353.6317917231427\n",
      "Step: 124  Mean return: 212.06320643293253\t +- 2290.730407527173\n",
      "Step: 125  Mean return: 193.75438924052443\t +- 2290.730407527173\n",
      "Step: 126  Mean return: 173.93742567955323\t +- 2081.392401764713\n",
      "Step: 127  Mean return: 175.7454328155901\t +- 1977.226373992322\n",
      "Step: 128  Mean return: 148.18973627862815\t +- 1977.226373992322\n",
      "Step: 129  Mean return: 151.15014906113313\t +- 1981.1055975025902\n",
      "Step: 130  Mean return: 108.10026365466456\t +- 1326.1211979729906\n",
      "Step: 131  Mean return: 107.88601483835183\t +- 1326.1211979729906\n",
      "Step: 132  Mean return: 104.91442422396187\t +- 1326.1211979729906\n",
      "Step: 133  Mean return: 73.12457794761231\t +- 1326.1211979729906\n",
      "Step: 134  Mean return: 88.12268919105554\t +- 1326.1211979729906\n",
      "Step: 135  Mean return: 73.63379106058377\t +- 1106.3305458159903\n",
      "Step: 136  Mean return: 79.87268529696671\t +- 1013.3918812410157\n",
      "Step: 137  Mean return: 84.49431127044966\t +- 1051.1850985520232\n",
      "Step: 138  Mean return: 93.26498834536497\t +- 1114.5154717724527\n",
      "Step: 139  Mean return: 157.61887388320352\t +- 1801.3332004359854\n",
      "Step: 140  Mean return: 162.58284902634247\t +- 1879.4100065309485\n",
      "Step: 141  Mean return: 185.1160239145242\t +- 2273.0902685024757\n",
      "Step: 142  Mean return: 209.7772885627265\t +- 2273.0902685024757\n",
      "Step: 143  Mean return: 243.86585570488282\t +- 2273.0902685024757\n",
      "Step: 144  Mean return: 227.40082810526962\t +- 1866.0731527812222\n",
      "Step: 145  Mean return: 211.37678660261167\t +- 1783.7156983128752\n",
      "Step: 146  Mean return: 201.38311307823366\t +- 1345.7860451257493\n",
      "Step: 147  Mean return: 175.2615223327343\t +- 1345.7860451257493\n",
      "Step: 148  Mean return: 134.22276915644682\t +- 1345.7860451257493\n",
      "Step: 149  Mean return: 102.38154271315535\t +- 900.0713560926706\n",
      "Step: 150  Mean return: 97.1308950297262\t +- 775.5018132198547\n",
      "Step: 151  Mean return: 95.99403865729857\t +- 1362.766785201935\n",
      "Step: 152  Mean return: 95.95988034405558\t +- 1362.766785201935\n",
      "Step: 153  Mean return: 123.14392630820795\t +- 1735.8140924672607\n",
      "Step: 154  Mean return: 128.28822717806068\t +- 1735.8140924672607\n",
      "Step: 155  Mean return: 160.05132003943382\t +- 2995.0644520142196\n",
      "Step: 156  Mean return: 174.59635963088712\t +- 2896.603736400808\n",
      "Step: 157  Mean return: 162.13641190699482\t +- 2896.603736400808\n",
      "Step: 158  Mean return: 184.57251311875373\t +- 2963.431975370215\n",
      "Step: 159  Mean return: 160.69581124715617\t +- 2963.431975370215\n",
      "Step: 160  Mean return: 197.6367008885945\t +- 2963.431975370215\n",
      "Step: 161  Mean return: 176.27486905962826\t +- 1239.6718498442915\n",
      "Step: 162  Mean return: 184.36098957890187\t +- 1239.6718498442915\n",
      "Step: 163  Mean return: 182.95773229139377\t +- 1239.6718498442915\n",
      "Step: 164  Mean return: 169.87113974140303\t +- 1203.4415236410605\n",
      "Step: 165  Mean return: 173.65421792707485\t +- 1203.4415236410605\n",
      "Step: 166  Mean return: 139.55905962560814\t +- 1203.4415236410605\n",
      "Step: 167  Mean return: 108.3714621756635\t +- 1070.2250821637663\n",
      "Step: 168  Mean return: 72.54637692803425\t +- 1008.8081699955492\n",
      "Step: 169  Mean return: 82.76920769754483\t +- 987.6927080149217\n",
      "Step: 170  Mean return: 102.97897754351614\t +- 1942.5290007958101\n",
      "Step: 171  Mean return: 115.8033297770611\t +- 2213.162762459957\n",
      "Step: 172  Mean return: 158.33712861243782\t +- 2213.162762459957\n",
      "Step: 173  Mean return: 208.71152044224175\t +- 2213.162762459957\n",
      "Step: 174  Mean return: 237.04881032054237\t +- 2213.162762459957\n",
      "Step: 175  Mean return: 247.2562228412795\t +- 2213.162762459957\n",
      "Step: 176  Mean return: 252.97653172665517\t +- 1904.8441021279286\n",
      "Step: 177  Mean return: 275.50695449384364\t +- 2708.350273072814\n",
      "Step: 178  Mean return: 299.5646689435755\t +- 2556.701516762623\n",
      "Step: 179  Mean return: 264.010793983025\t +- 2683.512844320996\n",
      "Step: 180  Mean return: 301.85502793399735\t +- 3494.0736687714707\n",
      "Step: 181  Mean return: 318.4188173106703\t +- 3523.8537848758115\n",
      "Step: 182  Mean return: 329.8642247326276\t +- 3523.8537848758115\n",
      "Step: 183  Mean return: 348.9464381775631\t +- 3523.8537848758115\n",
      "Step: 184  Mean return: 345.2771767930272\t +- 3523.8537848758115\n",
      "Step: 185  Mean return: 345.72315735186277\t +- 3523.8537848758115\n",
      "Step: 186  Mean return: 348.32234925890293\t +- 3523.8537848758115\n",
      "Step: 187  Mean return: 268.0681341939596\t +- 2198.5803280705386\n",
      "Step: 188  Mean return: 253.0799315499724\t +- 2160.988338283669\n",
      "Step: 189  Mean return: 221.0681615974145\t +- 2160.988338283669\n",
      "Step: 190  Mean return: 189.1792866217445\t +- 2160.988338283669\n",
      "Step: 191  Mean return: 212.60564149723143\t +- 2160.988338283669\n",
      "Step: 192  Mean return: 192.5768047940241\t +- 1656.851968185505\n",
      "Step: 193  Mean return: 212.58508722863075\t +- 2020.98298764223\n",
      "Step: 194  Mean return: 215.32872870000617\t +- 1935.8978778518467\n",
      "Step: 195  Mean return: 245.68456272360189\t +- 2473.1170026542713\n",
      "Step: 196  Mean return: 304.5851686358778\t +- 2473.1170026542713\n",
      "Step: 197  Mean return: 321.4410614560643\t +- 2621.8208954059337\n",
      "Step: 198  Mean return: 353.9450835478279\t +- 2621.8208954059337\n",
      "Step: 199  Mean return: 373.4092882578926\t +- 2621.8208954059337\n",
      "Step: 200  Mean return: 361.78020704035725\t +- 2621.8208954059337\n",
      "Step: 201  Mean return: 384.8415585239511\t +- 2621.8208954059337\n",
      "Step: 202  Mean return: 334.7724095034562\t +- 2553.1753056560065\n",
      "Step: 203  Mean return: 309.23863354269827\t +- 1902.4316392794299\n",
      "Step: 204  Mean return: 340.0552162954797\t +- 3272.5401044294813\n",
      "Step: 205  Mean return: 303.6270614727164\t +- 3272.5401044294813\n",
      "Step: 206  Mean return: 311.2079188744633\t +- 3479.3080882079557\n",
      "Step: 207  Mean return: 323.99280779503323\t +- 3479.3080882079557\n",
      "Step: 208  Mean return: 273.0680203932443\t +- 3479.3080882079557\n",
      "Step: 209  Mean return: 270.1337751235983\t +- 3479.3080882079557\n",
      "Step: 210  Mean return: 252.42474062260786\t +- 2305.0592818206096\n",
      "Step: 211  Mean return: 269.1735992279732\t +- 2305.0592818206096\n",
      "Step: 212  Mean return: 273.6137065555559\t +- 2472.749290863967\n",
      "Step: 213  Mean return: 277.07371072192296\t +- 2199.5175387765867\n",
      "Step: 214  Mean return: 322.76829884929793\t +- 3159.0855954278286\n",
      "Step: 215  Mean return: 320.6752782419251\t +- 3159.0855954278286\n",
      "Step: 216  Mean return: 327.2532185446704\t +- 3159.0855954278286\n",
      "Step: 217  Mean return: 307.1356212316522\t +- 3058.237037558998\n",
      "Step: 218  Mean return: 350.46088130258374\t +- 2939.704356355991\n",
      "Step: 219  Mean return: 276.12750536824484\t +- 2689.6342686972584\n",
      "Step: 220  Mean return: 321.1254671411004\t +- 2621.445970776331\n",
      "Step: 221  Mean return: 328.18897737283294\t +- 2621.445970776331\n",
      "Step: 222  Mean return: 299.89414765519524\t +- 2621.445970776331\n",
      "Step: 223  Mean return: 357.4932882165963\t +- 4003.9083504674218\n",
      "Step: 224  Mean return: 361.0288489908229\t +- 4062.9852171266684\n",
      "Step: 225  Mean return: 395.7716315345847\t +- 4062.9852171266684\n",
      "Step: 226  Mean return: 402.65164498269223\t +- 4062.9852171266684\n",
      "Step: 227  Mean return: 396.3525913393359\t +- 4062.9852171266684\n",
      "Step: 228  Mean return: 357.48070745686556\t +- 4062.9852171266684\n",
      "Step: 229  Mean return: 296.8547858883298\t +- 2444.052040267099\n",
      "Step: 230  Mean return: 290.86465668961233\t +- 4316.828848354366\n",
      "Step: 231  Mean return: 259.1109407893646\t +- 4316.828848354366\n",
      "Step: 232  Mean return: 242.5606524700487\t +- 4316.828848354366\n",
      "Step: 233  Mean return: 240.66259059715034\t +- 4316.828848354366\n",
      "Step: 234  Mean return: 291.8201892278734\t +- 4316.828848354366\n",
      "Step: 235  Mean return: 326.4799687840282\t +- 4316.828848354366\n",
      "Step: 236  Mean return: 346.2559291020381\t +- 3156.358099893312\n",
      "Step: 237  Mean return: 359.4733604128553\t +- 2414.6214981101857\n",
      "Step: 238  Mean return: 355.90756620625484\t +- 2414.6214981101857\n",
      "Step: 239  Mean return: 338.9256629868628\t +- 1951.409360721169\n",
      "Step: 240  Mean return: 302.2390640566544\t +- 1936.8402003967258\n",
      "Step: 241  Mean return: 302.7570774592674\t +- 1732.6768474524579\n",
      "Step: 242  Mean return: 282.31401927445876\t +- 1546.6710801862755\n",
      "Step: 243  Mean return: 289.8792093017325\t +- 1629.0636334442388\n",
      "Step: 244  Mean return: 303.7967715218008\t +- 2291.3191605274696\n",
      "Step: 245  Mean return: 307.2573689209514\t +- 2291.3191605274696\n",
      "Step: 246  Mean return: 284.4508498176702\t +- 2243.933442687019\n",
      "Step: 247  Mean return: 274.2202143704257\t +- 2275.15412064068\n",
      "Step: 248  Mean return: 282.2809011594216\t +- 2275.15412064068\n",
      "Step: 249  Mean return: 376.5779502028802\t +- 3116.2868088520972\n",
      "Step: 250  Mean return: 363.54938133980465\t +- 3116.2868088520972\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from rl_trading.simulation.env import StockExchangeEnv0\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "register_env('StockExchangeEnv-v0', lambda config: StockExchangeEnv0(**config))\n",
    "\n",
    "ppo = (\n",
    "    PPOConfig()\n",
    "    .rollouts(num_rollout_workers=4, num_envs_per_worker=4)\n",
    "    .training(use_gae=True, model={'use_lstm': True, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True})\n",
    "    .resources(num_gpus=1)\n",
    "    .environment(env='StockExchangeEnv-v0', env_config={'state_config':{\n",
    "        'market_state': ['price', 'vwap'],\n",
    "        'technical_indicators': [\n",
    "            (EMA, dict(timeperiod=5), '1min'),\n",
    "            (EMA, dict(timeperiod=13), '1min'),\n",
    "            (RSI, dict(timeperiod=7), '1min'),\n",
    "            (BBANDS, dict(timeperiod=10), '1min'),\n",
    "            (EMA, dict(timeperiod=20), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1h'),\n",
    "            (RSI, dict(timeperiod=14), '1h'),\n",
    "            (BBANDS, dict(timeperiod=20), '1h'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1d'),\n",
    "            (EMA, dict(timeperiod=200), '1d'),\n",
    "            (RSI, dict(timeperiod=14), '1d'),\n",
    "            (BBANDS, dict(timeperiod=20), '1d'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1d'),\n",
    "        ],\n",
    "    }})\n",
    "    .reporting(min_sample_timesteps_per_iteration=16 * 1440)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "render_env = StockExchangeEnv0()\n",
    "\n",
    "for i in range(250):\n",
    "    result = ppo.train()\n",
    "    print(f'Step: {result[\"training_iteration\"]:<5}Mean return: {result[\"episode_reward_mean\"]}\\t +- {result[\"episode_reward_max\"] - result[\"episode_reward_min\"]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:51<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "env = StockExchangeEnv0(state_config={\n",
    "        'market_state': ['price', 'vwap'],\n",
    "        'technical_indicators': [\n",
    "            (EMA, dict(timeperiod=5), '1min'),\n",
    "            (EMA, dict(timeperiod=13), '1min'),\n",
    "            (RSI, dict(timeperiod=7), '1min'),\n",
    "            (BBANDS, dict(timeperiod=10), '1min'),\n",
    "            (EMA, dict(timeperiod=20), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1h'),\n",
    "            (RSI, dict(timeperiod=14), '1h'),\n",
    "            (BBANDS, dict(timeperiod=20), '1h'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1d'),\n",
    "            (EMA, dict(timeperiod=200), '1d'),\n",
    "            (RSI, dict(timeperiod=14), '1d'),\n",
    "            (BBANDS, dict(timeperiod=20), '1d'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1d'),\n",
    "        ],\n",
    "    })\n",
    "\n",
    "def eval_episode():\n",
    "    for _ in tqdm(range(10)):\n",
    "        obs, done = env.reset()[0], False\n",
    "        pa, pr = 0, 0\n",
    "        total_reward = 0\n",
    "        state = [np.zeros([256], np.float32) for _ in range(2)]\n",
    "        while not done:\n",
    "            # env.render()\n",
    "            pa, state, _ = ppo.compute_single_action(observation=obs, state=state, prev_action=pa, prev_reward=pr)\n",
    "            obs, pr, done, _, _ = env.step(pa)\n",
    "            total_reward += pr\n",
    "\n",
    "%lprun -f eval_episode eval_episode()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "env = StockExchangeEnv0(state_config={\n",
    "        'market_state': ['price', 'vwap'],\n",
    "        'technical_indicators': [\n",
    "            (EMA, dict(timeperiod=5), '1min'),\n",
    "            (EMA, dict(timeperiod=13), '1min'),\n",
    "            (RSI, dict(timeperiod=7), '1min'),\n",
    "            (BBANDS, dict(timeperiod=10), '1min'),\n",
    "            (EMA, dict(timeperiod=20), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1h'),\n",
    "            (RSI, dict(timeperiod=14), '1h'),\n",
    "            (BBANDS, dict(timeperiod=20), '1h'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1h'),\n",
    "            (EMA, dict(timeperiod=50), '1d'),\n",
    "            (EMA, dict(timeperiod=200), '1d'),\n",
    "            (RSI, dict(timeperiod=14), '1d'),\n",
    "            (BBANDS, dict(timeperiod=20), '1d'),\n",
    "            (MACD_DIFF, dict(fastperiod=12, slowperiod=26, signalperiod=9), '1d'),\n",
    "        ],\n",
    "    })\n",
    "\n",
    "state = env.reset()[0]\n",
    "\n",
    "def step_bench():\n",
    "    for _ in range(100):\n",
    "        env._get_observation()\n",
    "%lprun -f env._get_observation step_bench()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 17:48:06,173\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/tune/experiment/experiment.py:170: UserWarning: The `local_dir` argument of `Experiment is deprecated. Use `storage_path` or set the `TUNE_RESULT_DIR` environment variable instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(DQN pid=679423)\u001B[0m 2023-05-08 17:48:11,273\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=679423)\u001B[0m 2023-05-08 17:48:11,714\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=679578)\u001B[0m 2023-05-08 17:48:16,100\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=679423)\u001B[0m 2023-05-08 17:48:16,402\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=679770)\u001B[0m 2023-05-08 17:48:19,010\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=679770)\u001B[0m 2023-05-08 17:48:19,438\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=679921)\u001B[0m 2023-05-08 17:48:23,860\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=679770)\u001B[0m 2023-05-08 17:48:24,100\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=680153)\u001B[0m 2023-05-08 17:48:26,714\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=680153)\u001B[0m 2023-05-08 17:48:27,149\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=680311)\u001B[0m 2023-05-08 17:48:31,596\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name                         </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics  </th><th>counters                                                                                                                  </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>hostname  </th><th>info                                                                                                                                     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                                                                          </th><th style=\"text-align: right;\">   pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                        </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_StockExchangeEnv-v0_b9c9d_00000</td><td style=\"text-align: right;\">                   1000</td><td>{}                 </td><td>{&#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td>{}              </td><td>2023-05-08_17-48-18</td><td>False </td><td style=\"text-align: right;\">               nan</td><td>{}             </td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                  nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">               0</td><td>seymour   </td><td>{&#x27;learner&#x27;: {}, &#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td style=\"text-align: right;\">                         1</td><td>192.168.0.222</td><td style=\"text-align: right;\">                     1000</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                   1000</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                            0</td><td>{&#x27;cpu_util_percent&#x27;: 34.699999999999996, &#x27;ram_util_percent&#x27;: 39.93333333333333, &#x27;gpu_util_percent0&#x27;: 0.056666666666666664, &#x27;vram_util_percent0&#x27;: 0.0576171875}</td><td style=\"text-align: right;\">679423</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{}            </td><td>{&#x27;episode_reward_max&#x27;: nan, &#x27;episode_reward_min&#x27;: nan, &#x27;episode_reward_mean&#x27;: nan, &#x27;episode_len_mean&#x27;: nan, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [], &#x27;episode_lengths&#x27;: []}, &#x27;sampler_perf&#x27;: {}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}</td><td style=\"text-align: right;\">             1.80517</td><td style=\"text-align: right;\">           1.80517</td><td style=\"text-align: right;\">       1.80517</td><td>{&#x27;training_iteration_time_ms&#x27;: 7.039, &#x27;sample_time_ms&#x27;: 6.532}</td><td style=\"text-align: right;\"> 1683560898</td><td style=\"text-align: right;\">             1000</td><td style=\"text-align: right;\">                   1</td><td>b9c9d_00000</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(DQN pid=680153)\u001B[0m 2023-05-08 17:48:31,835\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=746382)\u001B[0m 2023-05-08 18:15:58,748\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=746382)\u001B[0m 2023-05-08 18:15:59,201\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=746574)\u001B[0m 2023-05-08 18:16:03,733\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=746382)\u001B[0m 2023-05-08 18:16:04,210\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=746459)\u001B[0m 2023-05-08 18:16:04,210\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=746459)\u001B[0m 2023-05-08 18:16:05,102\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-05-08 18:42:32,692\tINFO tune.py:945 -- Total run time: 3265.68 seconds (3265.50 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResultGrid<[\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 1.1499625444412231, 'min_q': 1.1472853422164917, 'max_q': 1.1981370449066162, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 57500.0, 'diff_num_grad_updates_vs_sampler_policy': 57499.0, 'td_error': array([ 5.2051014e+01,  2.9675703e+00,  3.1171062e+01,  5.6244116e+00,\n       -4.1599060e+01, -2.1577101e+00, -3.3543293e+01,  1.6538687e+01,\n        1.0576648e+00, -1.0789150e+01, -6.0554333e+00, -1.4377775e+01,\n       -4.9149961e+00, -4.6388084e+01,  6.7986093e+00, -1.9250404e+00,\n       -1.3620989e+01, -7.2477303e+00, -5.5489788e+00, -4.9443917e+00,\n        1.1751221e+00,  8.6072655e+00, -4.7233269e+01, -7.3030949e-02,\n       -3.7860980e+00, -1.8501219e+01, -3.5854874e+01, -6.2660813e-02,\n       -3.2709913e+00, -1.3305000e+01, -4.4570055e+00,  9.6619129e-03],\n      dtype=float32), 'mean_td_error': -6.051741600036621}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 809.143078516503, 'episode_reward_min': -1814.5597415712355, 'episode_reward_mean': -64.64343800881323, 'episode_len_mean': 1440.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [16.60733210429862, -26.18701674046133, -281.5481305166195, 54.88515811679099, 17.885569912010396, -311.5937553748281, 208.26555354196717, 92.09889380663662, 264.2356272274792, -43.23259679881994, -124.78826968638168, -131.51120011004787, 599.9171807568546, -250.2517260294826, 468.3797396536211, 113.76550423553272, -1092.8403478592463, -63.61525128364701, -213.83448223169034, -251.740206848066, 40.222559301437286, 435.4548807819956, 62.87838080047186, 243.00740798996048, -588.6991984784709, -101.68030930632813, -287.7111911100819, 63.96295044441467, -95.68664852288748, 295.9873328590875, 809.143078516503, 37.22392774818945, 217.96261272327683, -82.07371058096396, 282.881935519752, 16.053966574792867, 125.20358919654427, -122.0995430396415, 523.8955694399046, 28.040311951401236, -464.8905742941279, -18.26272584479011, 322.07547861840794, -146.38258040806068, -518.1931838414966, -1621.6969129950285, 250.8670900682573, 236.34815800805336, 252.7516816562711, -322.1655029470967, -247.8518580419459, -753.1123743678745, 152.19776081598684, 149.07332289301485, -1814.5597415712355, -516.3564635031034, -149.89679798362158, -9.245292602903646, -378.31588523540086, 305.31875023000794, 239.53293937190756, -30.93613895206363, -89.49251858557909, 173.27909854845166, 653.7368163785704, -71.96034780601985, 26.432903616347176, -591.5317282874585, 128.31998083065992, -69.52709848230006, -108.78397582352227, 56.04918978516616, 94.69775126416971, -169.19740483794703, 57.15832655150189, -290.6306589668711, -1140.7196458020444, 164.75594009965243, 300.4997447418009, 315.94512839638264, -54.26656948415439, 33.672106812444326, 49.5062940926382, -1618.4107991432156, 316.23052006937723, -28.08813176140211, -91.2663582607056, -521.1321062598636, -19.532741422448453, -9.86025029625307, 2.8791861320914904, -1.0725542368454626, 25.581530559560633, -4.2193576138324715, -49.97966997096228, -65.56904147369823, 193.48214339907463, 0.9569566007721733, 46.96623554562393, 25.58267645109845], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.346820580262597, 'mean_inference_ms': 1.3675663847179098, 'mean_action_processing_ms': 0.26763480530957595, 'mean_env_wait_ms': 0.5213419823974924, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0049591064453125, 'StateBufferConnector_ms': 0.008357048034667969, 'ViewRequirementAgentConnector_ms': 0.09712839126586914}}, 'episode_reward_max': 809.143078516503, 'episode_reward_min': -1814.5597415712355, 'episode_reward_mean': -64.64343800881323, 'episode_len_mean': 1440.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [16.60733210429862, -26.18701674046133, -281.5481305166195, 54.88515811679099, 17.885569912010396, -311.5937553748281, 208.26555354196717, 92.09889380663662, 264.2356272274792, -43.23259679881994, -124.78826968638168, -131.51120011004787, 599.9171807568546, -250.2517260294826, 468.3797396536211, 113.76550423553272, -1092.8403478592463, -63.61525128364701, -213.83448223169034, -251.740206848066, 40.222559301437286, 435.4548807819956, 62.87838080047186, 243.00740798996048, -588.6991984784709, -101.68030930632813, -287.7111911100819, 63.96295044441467, -95.68664852288748, 295.9873328590875, 809.143078516503, 37.22392774818945, 217.96261272327683, -82.07371058096396, 282.881935519752, 16.053966574792867, 125.20358919654427, -122.0995430396415, 523.8955694399046, 28.040311951401236, -464.8905742941279, -18.26272584479011, 322.07547861840794, -146.38258040806068, -518.1931838414966, -1621.6969129950285, 250.8670900682573, 236.34815800805336, 252.7516816562711, -322.1655029470967, -247.8518580419459, -753.1123743678745, 152.19776081598684, 149.07332289301485, -1814.5597415712355, -516.3564635031034, -149.89679798362158, -9.245292602903646, -378.31588523540086, 305.31875023000794, 239.53293937190756, -30.93613895206363, -89.49251858557909, 173.27909854845166, 653.7368163785704, -71.96034780601985, 26.432903616347176, -591.5317282874585, 128.31998083065992, -69.52709848230006, -108.78397582352227, 56.04918978516616, 94.69775126416971, -169.19740483794703, 57.15832655150189, -290.6306589668711, -1140.7196458020444, 164.75594009965243, 300.4997447418009, 315.94512839638264, -54.26656948415439, 33.672106812444326, 49.5062940926382, -1618.4107991432156, 316.23052006937723, -28.08813176140211, -91.2663582607056, -521.1321062598636, -19.532741422448453, -9.86025029625307, 2.8791861320914904, -1.0725542368454626, 25.581530559560633, -4.2193576138324715, -49.97966997096228, -65.56904147369823, 193.48214339907463, 0.9569566007721733, 46.96623554562393, 25.58267645109845], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.346820580262597, 'mean_inference_ms': 1.3675663847179098, 'mean_action_processing_ms': 0.26763480530957595, 'mean_env_wait_ms': 0.5213419823974924, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0049591064453125, 'StateBufferConnector_ms': 0.008357048034667969, 'ViewRequirementAgentConnector_ms': 0.09712839126586914}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 28.215, 'sample_time_ms': 9.765, 'load_time_ms': 0.698, 'load_throughput': 45842.519, 'learn_time_ms': 6.745, 'learn_throughput': 4744.352, 'synch_weights_time_ms': 1.893}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'done': True, 'trial_id': 'b9c9d_00000', 'perf': {'cpu_util_percent': 58.95, 'ram_util_percent': 47.269999999999996, 'gpu_util_percent0': 0.139, 'vram_util_percent0': 0.08175455729166667}, 'experiment_tag': '0'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00000_0_2023-05-08_17-48-08',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00000_0_2023-05-08_17-48-08/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 0.1914111226797104, 'min_q': 0.17861604690551758, 'max_q': 0.21011164784431458, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 57500.0, 'diff_num_grad_updates_vs_sampler_policy': 57499.0, 'td_error': array([ 4.8485494e+00, -1.0112907e+01,  6.8455610e+00,  1.1754694e+01,\n       -5.0966458e+00, -1.6322151e+01,  2.8415020e+00,  6.5529003e+00,\n       -3.6689281e+00,  2.6838226e+01,  5.9676914e+00, -3.6341577e+00,\n        6.8997974e+00, -1.2938296e+00, -3.6483622e-01, -3.9197235e+00,\n       -8.0191965e+00,  1.1229022e+01,  3.9942429e+01, -5.1486826e+00,\n       -1.4383984e+01, -3.8562943e+01, -1.1632147e+01, -5.5456500e+00,\n        1.6541861e+01,  4.7529331e+01, -3.6040299e+00,  7.6899946e-01,\n        1.1427292e+01, -9.3357086e+00,  1.2063448e+00, -7.1263313e-03],\n      dtype=float32), 'mean_td_error': 1.891923427581787}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 1902.0720171883604, 'episode_reward_min': -1266.8857957663186, 'episode_reward_mean': 8.755526893126898, 'episode_len_mean': 1440.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-8.989289607105093, 425.3145458953295, -265.8315754865871, 105.0876558594955, -99.59738058795119, 205.0412794613094, -5.498499696575891, 209.74586072870625, 170.75184886490752, 359.746513644337, 1902.0720171883604, -525.9637426908594, -466.96620357823485, 19.173016263775935, 238.07487750938526, 58.51668114446693, 9.45376566210507, -147.97147554476578, 32.63219093354928, 794.9063275091703, 40.291858923839754, 464.6389281888387, -31.483393380414782, -17.142542137293276, -212.9199824382522, 2.095179570826076, 1000.9170796701183, 328.03555506735574, -211.0450544405303, 440.7790585547682, 826.6135583083415, 81.48434585191171, 222.9330188036729, 45.9711268402134, -241.59519252444807, 51.89966734891277, -45.3298271725871, -474.09460835491336, 259.04018452838864, -162.94474725201871, -1095.0140254775524, 135.90167846164877, 322.33529845022167, -836.6894654663665, 81.06437044664744, -1266.8857957663186, -19.33841562847556, -334.47658789675006, -505.32404466160006, -403.61732633806787, -1124.003698587967, 125.73287173808058, 1020.3172706691257, -523.749070278227, 294.666885186778, 732.9966630399085, 261.5770920872528, 189.19890837329694, -27.537275554335793, -86.00124750738723, 92.4434792465272, -455.86749987119765, 13.384433989591344, 265.31760604429473, 0.8070742539221101, 36.806016660138994, 87.01996397889525, 125.6552680891491, -54.52927327377074, 22.26565910318459, -124.98760144126754, -353.2424162607349, 206.40641680135013, 227.80495944372342, 351.34531449478527, -542.9838498175322, 29.191694782535706, 454.4971319919787, -214.96568564502923, 395.47973058990465, 101.11125575355618, -44.16827288058994, 320.36255813504613, -41.705464650614886, -507.80266881712487, -106.4670855568911, -661.1438276218232, 31.290450347196384, -13.747471007138302, -189.8709228862026, -1026.639435017185, -64.9168799163399, 34.22228714281118, 443.2680665348289, 259.78851799279255, -38.40129199941657, -124.65689652064066, 7.212096393473985, -393.22370594064523, 10.196243947686526], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.289758371875746, 'mean_inference_ms': 1.328918979010407, 'mean_action_processing_ms': 0.2581225600856472, 'mean_env_wait_ms': 0.5258685226351117, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005148649215698242, 'StateBufferConnector_ms': 0.00835275650024414, 'ViewRequirementAgentConnector_ms': 0.09636545181274414}}, 'episode_reward_max': 1902.0720171883604, 'episode_reward_min': -1266.8857957663186, 'episode_reward_mean': 8.755526893126898, 'episode_len_mean': 1440.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-8.989289607105093, 425.3145458953295, -265.8315754865871, 105.0876558594955, -99.59738058795119, 205.0412794613094, -5.498499696575891, 209.74586072870625, 170.75184886490752, 359.746513644337, 1902.0720171883604, -525.9637426908594, -466.96620357823485, 19.173016263775935, 238.07487750938526, 58.51668114446693, 9.45376566210507, -147.97147554476578, 32.63219093354928, 794.9063275091703, 40.291858923839754, 464.6389281888387, -31.483393380414782, -17.142542137293276, -212.9199824382522, 2.095179570826076, 1000.9170796701183, 328.03555506735574, -211.0450544405303, 440.7790585547682, 826.6135583083415, 81.48434585191171, 222.9330188036729, 45.9711268402134, -241.59519252444807, 51.89966734891277, -45.3298271725871, -474.09460835491336, 259.04018452838864, -162.94474725201871, -1095.0140254775524, 135.90167846164877, 322.33529845022167, -836.6894654663665, 81.06437044664744, -1266.8857957663186, -19.33841562847556, -334.47658789675006, -505.32404466160006, -403.61732633806787, -1124.003698587967, 125.73287173808058, 1020.3172706691257, -523.749070278227, 294.666885186778, 732.9966630399085, 261.5770920872528, 189.19890837329694, -27.537275554335793, -86.00124750738723, 92.4434792465272, -455.86749987119765, 13.384433989591344, 265.31760604429473, 0.8070742539221101, 36.806016660138994, 87.01996397889525, 125.6552680891491, -54.52927327377074, 22.26565910318459, -124.98760144126754, -353.2424162607349, 206.40641680135013, 227.80495944372342, 351.34531449478527, -542.9838498175322, 29.191694782535706, 454.4971319919787, -214.96568564502923, 395.47973058990465, 101.11125575355618, -44.16827288058994, 320.36255813504613, -41.705464650614886, -507.80266881712487, -106.4670855568911, -661.1438276218232, 31.290450347196384, -13.747471007138302, -189.8709228862026, -1026.639435017185, -64.9168799163399, 34.22228714281118, 443.2680665348289, 259.78851799279255, -38.40129199941657, -124.65689652064066, 7.212096393473985, -393.22370594064523, 10.196243947686526], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.289758371875746, 'mean_inference_ms': 1.328918979010407, 'mean_action_processing_ms': 0.2581225600856472, 'mean_env_wait_ms': 0.5258685226351117, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005148649215698242, 'StateBufferConnector_ms': 0.00835275650024414, 'ViewRequirementAgentConnector_ms': 0.09636545181274414}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 27.495, 'sample_time_ms': 9.233, 'load_time_ms': 0.901, 'load_throughput': 35515.792, 'learn_time_ms': 6.91, 'learn_throughput': 4631.184, 'synch_weights_time_ms': 1.638}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'done': True, 'trial_id': 'b9c9d_00001', 'perf': {'cpu_util_percent': 60.9, 'ram_util_percent': 48.21, 'gpu_util_percent0': 0.164, 'vram_util_percent0': 0.08585611979166666}, 'experiment_tag': '1'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00001_1_2023-05-08_17-48-16',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00001_1_2023-05-08_17-48-16/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 1.9027429819107056, 'min_q': 1.3952275514602661, 'max_q': 2.0157923698425293, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 57500.0, 'diff_num_grad_updates_vs_sampler_policy': 57499.0, 'td_error': array([ 4.6742277e+00, -1.1933959e+01,  2.1321470e+01, -9.3386519e-01,\n        5.7589741e+00,  2.2963090e+00,  4.5477057e-01, -1.5307789e+01,\n       -8.1946344e+00,  1.7628674e+01,  1.2262478e+01,  2.2911060e-01,\n       -5.7847571e+00,  4.3412712e+01,  3.1494431e+01,  2.3018904e+00,\n        5.5503716e+00, -5.2516987e+01,  4.6356916e-03,  1.3555145e-01,\n        2.0585418e-02, -1.8530306e+01, -5.9171009e-01,  1.2239631e+00,\n        4.5471466e-01,  2.0404816e-02,  1.2705040e-01,  3.8472675e+01,\n       -2.0443659e+00, -7.3961675e-01, -7.1435618e+00,  5.4026842e+00],\n      dtype=float32), 'mean_td_error': 2.172691822052002}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 799.1358357094123, 'episode_reward_min': -1365.3554391156922, 'episode_reward_mean': 8.537297944275997, 'episode_len_mean': 1440.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-76.71999605156088, 3.0584803547662887, 584.2523279892994, 165.20377450710657, 64.24707415501325, -135.64602964539154, -171.41001480339764, 22.486402309477853, -61.55347723382147, 26.719550974548838, 2.0381053329492715, 40.66591676452299, -138.57974700433442, 433.3592187002414, 119.92167934503414, -41.758100842700514, 212.59315418774895, 64.83337102258338, 1.8853684218283888, 306.40274808348113, 498.6460518531112, -428.46468840753914, -277.9657209968773, 394.85975340473306, 86.63379595521474, -41.01000541173744, -494.5277147492725, -186.6602592041345, -35.646727818038926, 10.0620856626374, -226.09624870162042, 335.2708285231838, -404.8627762645392, -60.42352370518529, -5.1314748903569125, -888.658273089799, -93.17054450549949, -133.12308260175814, 52.561029112517645, -17.548763291510113, 297.09101843196186, 31.180519396271848, -100.3668087087317, 799.1358357094123, -1365.3554391156922, 139.53800371957004, -575.7103176874862, -39.685861293362905, -132.7577424503561, 83.04050786607877, -43.03256966856861, 207.86846886571402, -100.6966276602343, 50.235168561903265, -577.4449233425821, -141.36647008201544, 17.80623404489961, -240.5143500458853, 487.6957833184406, 50.042550725715046, 17.65064255253492, -22.215216487611542, 39.477869073754846, -2.625912045057703, 7.979691699527393, -27.09234059636583, -6.132192261013188, -87.49751081506838, -53.62326517238762, -133.88011762647693, 56.018838632860934, 292.39712368285655, -158.62158934766012, 20.34185667822203, 210.90254781801195, 193.6474134743221, 66.70122310920488, 131.3973164517265, 191.6558271363756, 12.026440672849276, -102.89460519025852, -42.611986043399156, -26.4212500201902, 187.32127342404965, 408.2826009950295, -36.31905309436115, -140.98392957308533, -85.88485821630093, 5.06847323783586, 543.8883554859149, 73.67282233283913, 23.00012489985056, -145.18609275396375, -2.2598253119795118, 8.185051624515836, 190.9949503739772, -33.414578071086, 60.19000636642704, 96.71557432399823, 770.4315649812033], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3349884888220696, 'mean_inference_ms': 1.3405743332439004, 'mean_action_processing_ms': 0.270380808242327, 'mean_env_wait_ms': 0.5304914937154352, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.004999637603759766, 'StateBufferConnector_ms': 0.008498668670654297, 'ViewRequirementAgentConnector_ms': 0.09834504127502441}}, 'episode_reward_max': 799.1358357094123, 'episode_reward_min': -1365.3554391156922, 'episode_reward_mean': 8.537297944275997, 'episode_len_mean': 1440.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-76.71999605156088, 3.0584803547662887, 584.2523279892994, 165.20377450710657, 64.24707415501325, -135.64602964539154, -171.41001480339764, 22.486402309477853, -61.55347723382147, 26.719550974548838, 2.0381053329492715, 40.66591676452299, -138.57974700433442, 433.3592187002414, 119.92167934503414, -41.758100842700514, 212.59315418774895, 64.83337102258338, 1.8853684218283888, 306.40274808348113, 498.6460518531112, -428.46468840753914, -277.9657209968773, 394.85975340473306, 86.63379595521474, -41.01000541173744, -494.5277147492725, -186.6602592041345, -35.646727818038926, 10.0620856626374, -226.09624870162042, 335.2708285231838, -404.8627762645392, -60.42352370518529, -5.1314748903569125, -888.658273089799, -93.17054450549949, -133.12308260175814, 52.561029112517645, -17.548763291510113, 297.09101843196186, 31.180519396271848, -100.3668087087317, 799.1358357094123, -1365.3554391156922, 139.53800371957004, -575.7103176874862, -39.685861293362905, -132.7577424503561, 83.04050786607877, -43.03256966856861, 207.86846886571402, -100.6966276602343, 50.235168561903265, -577.4449233425821, -141.36647008201544, 17.80623404489961, -240.5143500458853, 487.6957833184406, 50.042550725715046, 17.65064255253492, -22.215216487611542, 39.477869073754846, -2.625912045057703, 7.979691699527393, -27.09234059636583, -6.132192261013188, -87.49751081506838, -53.62326517238762, -133.88011762647693, 56.018838632860934, 292.39712368285655, -158.62158934766012, 20.34185667822203, 210.90254781801195, 193.6474134743221, 66.70122310920488, 131.3973164517265, 191.6558271363756, 12.026440672849276, -102.89460519025852, -42.611986043399156, -26.4212500201902, 187.32127342404965, 408.2826009950295, -36.31905309436115, -140.98392957308533, -85.88485821630093, 5.06847323783586, 543.8883554859149, 73.67282233283913, 23.00012489985056, -145.18609275396375, -2.2598253119795118, 8.185051624515836, 190.9949503739772, -33.414578071086, 60.19000636642704, 96.71557432399823, 770.4315649812033], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3349884888220696, 'mean_inference_ms': 1.3405743332439004, 'mean_action_processing_ms': 0.270380808242327, 'mean_env_wait_ms': 0.5304914937154352, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.004999637603759766, 'StateBufferConnector_ms': 0.008498668670654297, 'ViewRequirementAgentConnector_ms': 0.09834504127502441}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 27.398, 'sample_time_ms': 9.347, 'load_time_ms': 0.658, 'load_throughput': 48650.764, 'learn_time_ms': 6.865, 'learn_throughput': 4661.277, 'synch_weights_time_ms': 1.844}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'done': True, 'trial_id': 'b9c9d_00002', 'perf': {'cpu_util_percent': 57.588888888888896, 'ram_util_percent': 46.54444444444445, 'gpu_util_percent0': 0.14, 'vram_util_percent0': 0.07826063368055555}, 'experiment_tag': '2'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00002_2_2023-05-08_17-48-24',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00002_2_2023-05-08_17-48-24/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 3.1298463344573975, 'min_q': 2.9879205226898193, 'max_q': 3.3527145385742188, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 57500.0, 'diff_num_grad_updates_vs_sampler_policy': 57499.0, 'td_error': array([  9.607554  ,   0.0739634 ,  10.016837  ,  -4.507201  ,\n        -5.68943   , -17.835588  ,  -3.6962912 ,  25.638512  ,\n         0.11463952,  -6.2816772 ,   0.11463952, -21.56944   ,\n         0.12207484,  -9.135307  ,  -5.379179  ,   0.12205958,\n         0.1222024 ,  11.27871   ,   5.0475097 , -50.33327   ,\n       -16.788708  ,   0.12910771,  13.4798565 , -29.081024  ,\n         0.11463952,   0.11463952,  -7.4815044 ,   0.12207484,\n         9.3898    ,   0.12910771,   0.0739634 ,  25.020382  ],\n      dtype=float32), 'mean_td_error': -2.092073440551758}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 806.6921230796233, 'episode_reward_min': -1816.2543055222877, 'episode_reward_mean': -13.890947335639458, 'episode_len_mean': 1440.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-139.18867646135732, -95.60666148544988, 71.86882015918854, -27.789552975198603, -1816.2543055222877, -181.5634525909154, -9.937624431886434, 52.709088456054815, 568.9918996267625, 76.39531148586866, 151.23285462928652, -114.38060081831463, 45.704859450755976, 225.1260212161742, -247.73305241004527, -269.32811614159255, 90.66420727685181, -0.16607717576880532, -35.217482541555, 4.3864591421152, 13.126409389877153, 72.56164791567244, -20.64418207642848, -186.77664297583942, 91.70684835451902, 74.31363797206541, -221.15968975310898, -18.52203789068153, 5.456117060115503, 68.99486183967383, -45.2095988203655, 51.05254056911144, -53.46891530506582, 68.21585393317037, 10.103797837618913, 20.018365625848674, -12.923930062468571, 110.08523951738971, -19.7947948818819, -12.13484066449928, 18.10442811730718, 49.29626918078975, -130.54145403539042, -98.67367557271427, 146.92800122301014, 806.6921230796233, -216.96310962145617, -105.22922802432186, -6.1506733195619745, -4.052090024246354, 10.825274280310623, -36.46092699800465, -90.97915286900206, -166.4641730213334, 129.0328544647964, -66.82682774894056, -32.46708370674423, 36.63578612844867, 156.29367119713788, -203.06683376023648, -63.393475151047824, 112.33149212994067, 5.661883299055262, -57.46521629041126, -37.18832825906429, -96.76521784288343, 115.99765820003086, 19.04045063052581, 197.15554144239286, -15.059021356089943, 40.71044320220972, 177.04209366246505, -231.20795279393496, 43.32688010245147, 8.947394009073832, 106.27285538897195, 32.99270136004816, 100.31245081689121, -59.83697592039607, 183.261435119588, 125.81627301454137, -77.69910977281688, -309.3266655828138, 127.55303234515122, -66.13766578404284, -41.968971023421545, -29.019815813249807, -54.886833250699055, 15.649152305059033, -57.29696014415458, -73.45059353170473, -23.556461787893568, 23.440280396638627, 6.536440437159399, -13.012509122678239, -64.69340185686087, -5.150557584498529, -10.1057342752556, -2.800171813891211, 18.03066208878772], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.244894092369719, 'mean_inference_ms': 1.2713592194837564, 'mean_action_processing_ms': 0.25059163668341045, 'mean_env_wait_ms': 0.5061812497361755, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005449771881103516, 'StateBufferConnector_ms': 0.008035659790039062, 'ViewRequirementAgentConnector_ms': 0.09914898872375488}}, 'episode_reward_max': 806.6921230796233, 'episode_reward_min': -1816.2543055222877, 'episode_reward_mean': -13.890947335639458, 'episode_len_mean': 1440.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-139.18867646135732, -95.60666148544988, 71.86882015918854, -27.789552975198603, -1816.2543055222877, -181.5634525909154, -9.937624431886434, 52.709088456054815, 568.9918996267625, 76.39531148586866, 151.23285462928652, -114.38060081831463, 45.704859450755976, 225.1260212161742, -247.73305241004527, -269.32811614159255, 90.66420727685181, -0.16607717576880532, -35.217482541555, 4.3864591421152, 13.126409389877153, 72.56164791567244, -20.64418207642848, -186.77664297583942, 91.70684835451902, 74.31363797206541, -221.15968975310898, -18.52203789068153, 5.456117060115503, 68.99486183967383, -45.2095988203655, 51.05254056911144, -53.46891530506582, 68.21585393317037, 10.103797837618913, 20.018365625848674, -12.923930062468571, 110.08523951738971, -19.7947948818819, -12.13484066449928, 18.10442811730718, 49.29626918078975, -130.54145403539042, -98.67367557271427, 146.92800122301014, 806.6921230796233, -216.96310962145617, -105.22922802432186, -6.1506733195619745, -4.052090024246354, 10.825274280310623, -36.46092699800465, -90.97915286900206, -166.4641730213334, 129.0328544647964, -66.82682774894056, -32.46708370674423, 36.63578612844867, 156.29367119713788, -203.06683376023648, -63.393475151047824, 112.33149212994067, 5.661883299055262, -57.46521629041126, -37.18832825906429, -96.76521784288343, 115.99765820003086, 19.04045063052581, 197.15554144239286, -15.059021356089943, 40.71044320220972, 177.04209366246505, -231.20795279393496, 43.32688010245147, 8.947394009073832, 106.27285538897195, 32.99270136004816, 100.31245081689121, -59.83697592039607, 183.261435119588, 125.81627301454137, -77.69910977281688, -309.3266655828138, 127.55303234515122, -66.13766578404284, -41.968971023421545, -29.019815813249807, -54.886833250699055, 15.649152305059033, -57.29696014415458, -73.45059353170473, -23.556461787893568, 23.440280396638627, 6.536440437159399, -13.012509122678239, -64.69340185686087, -5.150557584498529, -10.1057342752556, -2.800171813891211, 18.03066208878772], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.244894092369719, 'mean_inference_ms': 1.2713592194837564, 'mean_action_processing_ms': 0.25059163668341045, 'mean_env_wait_ms': 0.5061812497361755, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005449771881103516, 'StateBufferConnector_ms': 0.008035659790039062, 'ViewRequirementAgentConnector_ms': 0.09914898872375488}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 25.777, 'sample_time_ms': 9.059, 'load_time_ms': 0.667, 'load_throughput': 47986.317, 'learn_time_ms': 6.173, 'learn_throughput': 5183.873, 'synch_weights_time_ms': 1.565}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'done': True, 'trial_id': 'b9c9d_00003', 'perf': {'cpu_util_percent': 42.03, 'ram_util_percent': 45.73, 'gpu_util_percent0': 0.13699999999999998, 'vram_util_percent0': 0.07405598958333334}, 'experiment_tag': '3'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00003_3_2023-05-08_18-15-55',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00003_3_2023-05-08_18-15-55/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 2.918905735015869, 'min_q': 2.6644093990325928, 'max_q': 3.032886505126953, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 57500.0, 'diff_num_grad_updates_vs_sampler_policy': 57499.0, 'td_error': array([-1.3742979e+01, -3.9439907e+00, -1.4937445e+01,  1.1018828e+01,\n        1.1018828e+01, -1.2678385e-02, -9.0630951e+00, -6.2871056e+00,\n        3.3389168e+00,  7.5267448e+00, -1.8072319e+00, -1.2601852e-02,\n       -1.2656689e-02, -3.5527130e+01, -2.2354126e-03, -3.0124168e+00,\n       -2.9187355e+01,  2.8079372e+01, -1.4356928e+01, -2.0932198e-02,\n       -2.0941496e-02,  1.1497147e+00,  6.6654148e+00, -7.1260443e+00,\n       -1.2678385e-02,  6.0519004e+00, -1.2656689e-02, -1.2656689e-02,\n       -2.0873547e-02, -9.6535625e+00, -2.2354126e-03, -2.5959539e+00],\n      dtype=float32), 'mean_td_error': -2.3917083740234375}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 647.6377929856917, 'episode_reward_min': -857.5327565000171, 'episode_reward_mean': -7.131019566620198, 'episode_len_mean': 1440.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [66.38504296375868, -105.35179763141787, 134.25270695318795, -244.3715593264551, 505.6029759877074, 524.6010623419807, -857.5327565000171, -139.10706398760522, -158.78372756344288, -145.79884706309713, 92.50234596160044, -565.9457551134619, 74.72028603567742, -121.42765657881137, -68.26748903461339, -199.9600471171234, 4.692704410443184, -486.4706123916076, -233.478096450046, 216.01010137663616, -148.54058892083594, 221.82824113699826, -486.9103479369296, -176.90422621072867, -6.035041458495471, -304.78997606437406, 237.11117194718463, -148.86406145108595, -38.49167876515094, 1.2219734150330623, 647.6377929856917, 287.30724875680426, -1.2313371030322742, -63.82760310231242, 8.67444751331459, 644.0133255990713, -52.07973544941342, -155.64229031797004, -111.96552198644531, 48.34553399707511, -321.4356252875441, -31.72322596293452, 14.071577242395506, -125.94552263154947, 34.28772501983076, 137.87621988208593, -245.86667820232105, -47.9053874761903, -138.6013639286848, -178.20088372375903, -16.475032357622695, -58.42472345358692, 228.60877340640036, 115.03094762041292, 61.41977065617357, 198.68169655808742, 100.21019372141745, 25.34722528110251, 243.97253207553695, 45.000736433778, 7.011615565104876, 37.68021332417993, -38.81379434211158, 15.14211001511103, -12.690838769764014, -22.561716495689325, 6.37728505661471, 5.806188846425357, -10.180939553187272, -17.882651989575606, -28.835158443585897, 136.06692010789084, -66.62442202085003, 23.693464139571006, -54.980754289887045, 49.8630696803084, 9.58378041823562, 38.11214075353746, 10.849093150460249, -22.40494134769142, -203.34287224716354, 1.993145251797614, -102.05231358354467, -290.216209003991, 14.724304263863814, 201.420732989136, 394.06339011833006, -65.99671646068236, 59.87079711003207, -11.289765088697095, 376.99559725838844, 67.57341224801348, -30.457480047121862, -102.97316287926697, -39.64823364629774, -148.4722132169154, 164.4835425583169, -20.879817751319933, 285.86577724575363, -63.03263431646883], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3327584873930225, 'mean_inference_ms': 1.3119411737673818, 'mean_action_processing_ms': 0.2535293950633263, 'mean_env_wait_ms': 0.5259305943880905, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00571441650390625, 'StateBufferConnector_ms': 0.008605480194091797, 'ViewRequirementAgentConnector_ms': 0.0998377799987793}}, 'episode_reward_max': 647.6377929856917, 'episode_reward_min': -857.5327565000171, 'episode_reward_mean': -7.131019566620198, 'episode_len_mean': 1440.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [66.38504296375868, -105.35179763141787, 134.25270695318795, -244.3715593264551, 505.6029759877074, 524.6010623419807, -857.5327565000171, -139.10706398760522, -158.78372756344288, -145.79884706309713, 92.50234596160044, -565.9457551134619, 74.72028603567742, -121.42765657881137, -68.26748903461339, -199.9600471171234, 4.692704410443184, -486.4706123916076, -233.478096450046, 216.01010137663616, -148.54058892083594, 221.82824113699826, -486.9103479369296, -176.90422621072867, -6.035041458495471, -304.78997606437406, 237.11117194718463, -148.86406145108595, -38.49167876515094, 1.2219734150330623, 647.6377929856917, 287.30724875680426, -1.2313371030322742, -63.82760310231242, 8.67444751331459, 644.0133255990713, -52.07973544941342, -155.64229031797004, -111.96552198644531, 48.34553399707511, -321.4356252875441, -31.72322596293452, 14.071577242395506, -125.94552263154947, 34.28772501983076, 137.87621988208593, -245.86667820232105, -47.9053874761903, -138.6013639286848, -178.20088372375903, -16.475032357622695, -58.42472345358692, 228.60877340640036, 115.03094762041292, 61.41977065617357, 198.68169655808742, 100.21019372141745, 25.34722528110251, 243.97253207553695, 45.000736433778, 7.011615565104876, 37.68021332417993, -38.81379434211158, 15.14211001511103, -12.690838769764014, -22.561716495689325, 6.37728505661471, 5.806188846425357, -10.180939553187272, -17.882651989575606, -28.835158443585897, 136.06692010789084, -66.62442202085003, 23.693464139571006, -54.980754289887045, 49.8630696803084, 9.58378041823562, 38.11214075353746, 10.849093150460249, -22.40494134769142, -203.34287224716354, 1.993145251797614, -102.05231358354467, -290.216209003991, 14.724304263863814, 201.420732989136, 394.06339011833006, -65.99671646068236, 59.87079711003207, -11.289765088697095, 376.99559725838844, 67.57341224801348, -30.457480047121862, -102.97316287926697, -39.64823364629774, -148.4722132169154, 164.4835425583169, -20.879817751319933, 285.86577724575363, -63.03263431646883], 'episode_lengths': [1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440, 1440]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3327584873930225, 'mean_inference_ms': 1.3119411737673818, 'mean_action_processing_ms': 0.2535293950633263, 'mean_env_wait_ms': 0.5259305943880905, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00571441650390625, 'StateBufferConnector_ms': 0.008605480194091797, 'ViewRequirementAgentConnector_ms': 0.0998377799987793}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 25.757, 'sample_time_ms': 8.761, 'load_time_ms': 0.625, 'load_throughput': 51192.97, 'learn_time_ms': 6.2, 'learn_throughput': 5161.228, 'synch_weights_time_ms': 1.595}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1840000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1840000, 'last_target_update_ts': 248004, 'num_target_updates': 58}, 'done': True, 'trial_id': 'b9c9d_00004', 'perf': {'cpu_util_percent': 22.48888888888889, 'ram_util_percent': 42.2, 'gpu_util_percent0': 0.03666666666666667, 'vram_util_percent0': 0.060384114583333336}, 'experiment_tag': '4'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00004_4_2023-05-08_18-15-57',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_fixed_seed/DQN_StockExchangeEnv-v0_b9c9d_00004_4_2023-05-08_18-15-57/checkpoint_000250)\n  )\n]>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune, air\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "from rl_trading.simulation.env import StockExchangeEnv0\n",
    "\n",
    "config = (\n",
    "    DQNConfig()\n",
    "    .rollouts(num_rollout_workers=1, num_envs_per_worker=4)\n",
    "    .resources(num_gpus=0.2)\n",
    "    .environment(env='StockExchangeEnv-v0')\n",
    "    .training(hiddens=[512], num_steps_sampled_before_learning_starts=20_000, target_network_update_freq=4_000)\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"DQN\",\n",
    "    run_config=air.RunConfig(\n",
    "        name='DQN_fixed_seed',\n",
    "        local_dir='../exp_results/DQN',\n",
    "        stop={\"training_iteration\": 250},\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=5\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_total=4861.41\n"
     ]
    }
   ],
   "source": [
    "env = StockExchangeEnv0()\n",
    "\n",
    "env.reset(seed=52)\n",
    "done = False\n",
    "reward_total = 0\n",
    "while not done:\n",
    "    env.render()\n",
    "    current_idx = env.current_idx\n",
    "    current_price = env.price_data[current_idx]\n",
    "    next_price = env.price_data[current_idx + 1]\n",
    "    if next_price > current_price:\n",
    "        action = 1\n",
    "    elif next_price < current_price:\n",
    "        action = 2\n",
    "    else:\n",
    "        action = 0\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    reward_total += reward\n",
    "\n",
    "print(f'{reward_total=:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_total=625.41\n"
     ]
    }
   ],
   "source": [
    "from rl_trading.simulation.env import SimulationConfig, ExchangeConfig\n",
    "env = StockExchangeEnv0(sim_config=SimulationConfig(initial_cash=10_000), exchange_config=ExchangeConfig(maker_fee=1e-3))\n",
    "\n",
    "env.reset(seed=52)\n",
    "done = False\n",
    "reward_total = 0\n",
    "while not done:\n",
    "    #env.render()\n",
    "    current_idx = env.current_idx\n",
    "    current_price = env.price_data[current_idx]\n",
    "    next_price = env.price_data[current_idx + 1]\n",
    "    balance = env.cash_balance\n",
    "    position = env.asset_holdings\n",
    "    rpc = (next_price - current_price) / current_price\n",
    "    if next_price > current_price and balance > 0 and rpc > 1.2e-3:\n",
    "        action = 1\n",
    "    elif next_price < current_price and position > 0:\n",
    "        action = 2\n",
    "    else:\n",
    "        action = 0\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    reward_total += reward\n",
    "\n",
    "print(f'{reward_total=:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy after 0 steps\n",
      "Sell after 58 steps\n",
      "Trade period 58\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 12 steps\n",
      "Trade period 12\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 35 steps\n",
      "Trade period 35\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 283 steps\n",
      "Trade period 283\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 9 steps\n",
      "Trade period 9\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 18 steps\n",
      "Trade period 18\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 21 steps\n",
      "Trade period 21\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 14 steps\n",
      "Trade period 14\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 18 steps\n",
      "Trade period 18\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 6 steps\n",
      "Trade period 6\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 20 steps\n",
      "Trade period 20\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 150 steps\n",
      "Trade period 150\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 15 steps\n",
      "Trade period 15\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 29 steps\n",
      "Trade period 29\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 26 steps\n",
      "Trade period 26\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 42 steps\n",
      "Trade period 42\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 11 steps\n",
      "Trade period 11\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 5 steps\n",
      "Trade period 5\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 12 steps\n",
      "Trade period 12\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 18 steps\n",
      "Trade period 18\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 22 steps\n",
      "Trade period 22\n",
      "\n",
      "Buy after 0 steps\n",
      "Sell after 82 steps\n",
      "Trade period 82\n",
      "\n",
      "reward_total=1158.42\n"
     ]
    }
   ],
   "source": [
    "from rl_trading.simulation.env import SimulationConfig, ExchangeConfig\n",
    "env = StockExchangeEnv0(sim_config=SimulationConfig(initial_cash=10_000), exchange_config=ExchangeConfig(maker_fee=1e-3))\n",
    "\n",
    "def find_next_buy_idx(cix):\n",
    "    current_price = env.price_data[cix]\n",
    "    buy_rpc, buy_idx = 0, cix\n",
    "    for idx in range(cix, env.start_idx + env.max_steps - 1):\n",
    "        next_price = env.price_data[idx + 1]\n",
    "        if next_price > current_price:\n",
    "            break\n",
    "        rpc = (next_price - current_price) / current_price\n",
    "        if rpc < buy_rpc:\n",
    "            buy_rpc = rpc\n",
    "            buy_idx = idx\n",
    "    return buy_idx\n",
    "\n",
    "def find_next_sell_idx(cix, fee=2e-3):\n",
    "    current_price = env.price_data[cix]\n",
    "    sell_rpc, sell_idx = 0, cix\n",
    "    for idx in range(cix, env.start_idx + env.max_steps - 1):\n",
    "        next_price = env.price_data[idx + 1]\n",
    "        if next_price < current_price:\n",
    "            break\n",
    "        rpc = (next_price - current_price) / current_price\n",
    "        if rpc > sell_rpc:\n",
    "            sell_rpc = rpc\n",
    "            sell_idx = idx\n",
    "    return sell_idx if sell_rpc > fee else cix\n",
    "\n",
    "env.reset(seed=52)\n",
    "done = False\n",
    "reward_total = 0\n",
    "buy_idx, sell_idx = None, None\n",
    "while not done:\n",
    "    env.render()\n",
    "    current_idx = env.current_idx\n",
    "    current_price = env.price_data[current_idx]\n",
    "    balance = env.cash_balance\n",
    "    if balance > 0 and buy_idx is None and sell_idx is None:\n",
    "        buy_idx = find_next_buy_idx(current_idx)\n",
    "        sell_idx = find_next_sell_idx(buy_idx)\n",
    "        if np.abs(buy_idx - sell_idx) < 5:\n",
    "            buy_idx = sell_idx = None\n",
    "        else:\n",
    "            print(f'Buy after {buy_idx - env.current_idx} steps')\n",
    "            print(f'Sell after {sell_idx - env.current_idx} steps')\n",
    "            print(f'Trade period {sell_idx - buy_idx}')\n",
    "            print()\n",
    "    if buy_idx is not None and current_idx == buy_idx:\n",
    "        buy_idx = None\n",
    "        action = 1\n",
    "    elif sell_idx is not None and current_idx == sell_idx:\n",
    "        sell_idx = None\n",
    "        action = 2\n",
    "    else:\n",
    "        action = 0\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    reward_total += reward\n",
    "\n",
    "print(f'{reward_total=:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rl_trading.simulation.env import StockExchangeEnv1\n",
    "\n",
    "env = StockExchangeEnv1(sim_config={'granularity': '1d', 'max_steps': 30})\n",
    "done = False\n",
    "env.reset()\n",
    "while not done:\n",
    "    env.render()\n",
    "    state, reward, done, _, _ = env.step(np.random.randint(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 22:56:58,937\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages/ray/tune/experiment/experiment.py:170: UserWarning: The `local_dir` argument of `Experiment is deprecated. Use `storage_path` or set the `TUNE_RESULT_DIR` environment variable instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(DQN pid=1442911)\u001B[0m 2023-05-08 22:57:04,475\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=1442911)\u001B[0m 2023-05-08 22:57:04,940\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=1443069)\u001B[0m 2023-05-08 22:57:10,315\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=1442911)\u001B[0m 2023-05-08 22:57:10,849\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=1443313)\u001B[0m 2023-05-08 22:57:13,644\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=1443313)\u001B[0m 2023-05-08 22:57:14,111\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=1443501)\u001B[0m 2023-05-08 22:57:18,906\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=1443313)\u001B[0m 2023-05-08 22:57:19,364\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=1443734)\u001B[0m 2023-05-08 22:57:22,075\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=1443734)\u001B[0m 2023-05-08 22:57:22,533\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=1443891)\u001B[0m 2023-05-08 22:57:27,209\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name                         </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                              </th><th>counters                                                                                                                  </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>hostname  </th><th>info                                                                                                                                     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                                                                  </th><th style=\"text-align: right;\">    pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                        </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_StockExchangeEnv-v1_e0354_00001</td><td style=\"text-align: right;\">                   1000</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.004503875970840454, &#x27;StateBufferConnector_ms&#x27;: 0.007937848567962646, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.09392797946929932}</td><td>{&#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td>{}              </td><td>2023-05-08_22-57-21</td><td>False </td><td style=\"text-align: right;\">                30</td><td>{}             </td><td style=\"text-align: right;\">             3469.58</td><td style=\"text-align: right;\">             -430.682</td><td style=\"text-align: right;\">            -3457.52</td><td style=\"text-align: right;\">                  32</td><td style=\"text-align: right;\">              32</td><td>seymour   </td><td>{&#x27;learner&#x27;: {}, &#x27;num_env_steps_sampled&#x27;: 1000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 1000, &#x27;num_agent_steps_trained&#x27;: 0}</td><td style=\"text-align: right;\">                         1</td><td>192.168.0.222</td><td style=\"text-align: right;\">                     1000</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                   1000</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                            0</td><td>{&#x27;cpu_util_percent&#x27;: 47.26666666666667, &#x27;ram_util_percent&#x27;: 43.0, &#x27;gpu_util_percent0&#x27;: 0.09333333333333334, &#x27;vram_util_percent0&#x27;: 0.08308919270833333}</td><td style=\"text-align: right;\">1443313</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 2.354254285652799, &#x27;mean_inference_ms&#x27;: 1.3133263682939142, &#x27;mean_action_processing_ms&#x27;: 0.2668654301252023, &#x27;mean_env_wait_ms&#x27;: 0.4541959420618308, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 3469.5800320231665, &#x27;episode_reward_min&#x27;: -3457.5212727048793, &#x27;episode_reward_mean&#x27;: -430.68205518945325, &#x27;episode_len_mean&#x27;: 30.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 32, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-2500.04274758891, -512.8307417985961, -1273.6865750049637, 1733.4447958525543, 10.114891306227946, 2589.2849614948427, -70.10214516004271, -795.4055995302479, -410.4967926872705, -995.569969954844, -246.43124687011368, -1652.4171011887302, -342.1916201364711, -2311.150006707241, 180.80874994796613, -187.2972336815892, 283.6635246990827, -731.6369512781384, 973.9020299930344, 1074.2199611716442, -265.49101096542836, -3457.5212727048793, -371.5881167043117, -1460.6249755388435, -955.2961529465683, -1147.1377868969466, 691.4383685029188, -814.0020311571025, 3469.5800320231665, -3324.026625412879, 19.458779973305354, -982.7951571131289], &#x27;episode_lengths&#x27;: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 2.354254285652799, &#x27;mean_inference_ms&#x27;: 1.3133263682939142, &#x27;mean_action_processing_ms&#x27;: 0.2668654301252023, &#x27;mean_env_wait_ms&#x27;: 0.4541959420618308, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.004503875970840454, &#x27;StateBufferConnector_ms&#x27;: 0.007937848567962646, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.09392797946929932}}</td><td style=\"text-align: right;\">              1.8581</td><td style=\"text-align: right;\">            1.8581</td><td style=\"text-align: right;\">        1.8581</td><td>{&#x27;training_iteration_time_ms&#x27;: 7.872, &#x27;sample_time_ms&#x27;: 7.343}</td><td style=\"text-align: right;\"> 1683579441</td><td style=\"text-align: right;\">             1000</td><td style=\"text-align: right;\">                   1</td><td>e0354_00001</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(DQN pid=1443734)\u001B[0m 2023-05-08 22:57:27,669\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=1513872)\u001B[0m 2023-05-08 23:26:24,034\tWARNING algorithm_config.py:635 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001B[2m\u001B[36m(DQN pid=1513897)\u001B[0m 2023-05-08 23:26:24,533\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=1514084)\u001B[0m 2023-05-08 23:26:29,236\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=1513897)\u001B[0m 2023-05-08 23:26:29,236\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(DQN pid=1513897)\u001B[0m 2023-05-08 23:26:29,771\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001B[2m\u001B[36m(DQN pid=1513872)\u001B[0m 2023-05-08 23:26:29,771\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "2023-05-08 23:54:18,867\tINFO tune.py:945 -- Total run time: 3439.04 seconds (3438.33 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResultGrid<[\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 997.37890625, 'min_q': 645.4097290039062, 'max_q': 4936.7841796875, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 62250.0, 'diff_num_grad_updates_vs_sampler_policy': 62249.0, 'td_error': array([ -840.6677   ,  -864.65283  ,  -617.3421   ,  -398.42664  ,\n         422.38892  ,   294.2863   , -1647.2065   ,     7.1083374,\n         314.30743  ,   557.4609   ,  -215.11768  ,   -40.32794  ,\n         427.96448  ,  -343.78387  ,   156.38074  ,  -381.0603   ,\n           7.343628 , -1283.1091   ,   163.56226  ,   223.42618  ,\n         -34.72101  ,   291.45343  ,  -568.25867  , -2439.538    ,\n         260.00385  ,   -98.30902  ,  -222.34882  ,   584.7792   ,\n         133.24792  , -3316.2568   ,  -291.16803  ,  -100.52789  ],\n      dtype=float32), 'mean_td_error': -308.09716796875}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'sampler_results': {'episode_reward_max': 11836.141443153203, 'episode_reward_min': -4390.180780210425, 'episode_reward_mean': 183.76078542690595, 'episode_len_mean': 30.0, 'episode_media': {}, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [11836.141443153203, -387.7311936605074, -877.3155218653155, -865.9348171797428, -554.0129432510857, -882.3684204486781, -219.90280819824693, 2751.0331369004944, -578.8481917474492, 2244.644585911239, 626.5047162048722, -1475.6231843847836, -2027.3607884432313, -1536.0704269682556, -465.82888305264714, -775.5098423223426, -3141.5070273974425, 1821.1547463417028, -482.77344684487434, 3921.592757857661, 0.0, -301.32113057416245, 765.1632517541966, -552.143589500105, 0.0, 593.4602101473265, 0.0, 0.0, -643.8292215722813, 1118.7531813632231, 0.0, 0.0, -2487.3762051767308, 0.0, -79.39476300174647, -484.73130020743156, 10189.983477262143, -872.4301902145689, -290.53309036761493, 0.0, 3430.8737823128376, -3964.7815370128283, -816.8329883175138, 2669.801593040951, -3653.2739923814825, -4390.180780210425, -1599.9659382886166, 217.0306244441872, 1067.611732193658, -2391.2192681371153, 8451.097067906201, -428.90002466279475, -3549.1113439979017, 1045.6338388106014, 886.9053292805784, 97.06283096712468, 3118.560887457077, -2174.8532460188935, 270.20767936366974, -304.66587888232425, 1157.8715697227835, 262.4744833387467, 0.0, -2820.168289178974, 58.49925872705353, 205.66017010630094, 0.0, 0.0, 561.0206899905752, 365.02139489014735, 3966.6681460929813, 1949.761109785577, 1318.5476372997127, 4240.872045493143, 1194.8822718090414, 2415.352642387352, -651.2419166564869, -1939.833526696797, -2176.791711132718, -2297.6618006868557, -1529.81029623215, 140.09050849017513, 3557.535744394767, -3115.4702763310897, 335.67459157212943, 60.90317336274529, 3050.347343109943, -207.52459032473962, -1128.67189258695, -3390.7765309380284, -590.3014200106954, 2750.823486378573, 127.05920140083435, -1031.585381851657, -991.8440887871493, -3699.573568732243, -430.5295304154042, 1263.8125799266509, 78.72794427300505, 1449.3724823164848], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.458489177280118, 'mean_inference_ms': 1.285853705612997, 'mean_action_processing_ms': 0.2649701099793667, 'mean_env_wait_ms': 0.44790512256711507, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0052030086517333984, 'StateBufferConnector_ms': 0.008443832397460938, 'ViewRequirementAgentConnector_ms': 0.0974569320678711}}, 'episode_reward_max': 11836.141443153203, 'episode_reward_min': -4390.180780210425, 'episode_reward_mean': 183.76078542690595, 'episode_len_mean': 30.0, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [11836.141443153203, -387.7311936605074, -877.3155218653155, -865.9348171797428, -554.0129432510857, -882.3684204486781, -219.90280819824693, 2751.0331369004944, -578.8481917474492, 2244.644585911239, 626.5047162048722, -1475.6231843847836, -2027.3607884432313, -1536.0704269682556, -465.82888305264714, -775.5098423223426, -3141.5070273974425, 1821.1547463417028, -482.77344684487434, 3921.592757857661, 0.0, -301.32113057416245, 765.1632517541966, -552.143589500105, 0.0, 593.4602101473265, 0.0, 0.0, -643.8292215722813, 1118.7531813632231, 0.0, 0.0, -2487.3762051767308, 0.0, -79.39476300174647, -484.73130020743156, 10189.983477262143, -872.4301902145689, -290.53309036761493, 0.0, 3430.8737823128376, -3964.7815370128283, -816.8329883175138, 2669.801593040951, -3653.2739923814825, -4390.180780210425, -1599.9659382886166, 217.0306244441872, 1067.611732193658, -2391.2192681371153, 8451.097067906201, -428.90002466279475, -3549.1113439979017, 1045.6338388106014, 886.9053292805784, 97.06283096712468, 3118.560887457077, -2174.8532460188935, 270.20767936366974, -304.66587888232425, 1157.8715697227835, 262.4744833387467, 0.0, -2820.168289178974, 58.49925872705353, 205.66017010630094, 0.0, 0.0, 561.0206899905752, 365.02139489014735, 3966.6681460929813, 1949.761109785577, 1318.5476372997127, 4240.872045493143, 1194.8822718090414, 2415.352642387352, -651.2419166564869, -1939.833526696797, -2176.791711132718, -2297.6618006868557, -1529.81029623215, 140.09050849017513, 3557.535744394767, -3115.4702763310897, 335.67459157212943, 60.90317336274529, 3050.347343109943, -207.52459032473962, -1128.67189258695, -3390.7765309380284, -590.3014200106954, 2750.823486378573, 127.05920140083435, -1031.585381851657, -991.8440887871493, -3699.573568732243, -430.5295304154042, 1263.8125799266509, 78.72794427300505, 1449.3724823164848], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.458489177280118, 'mean_inference_ms': 1.285853705612997, 'mean_action_processing_ms': 0.2649701099793667, 'mean_env_wait_ms': 0.44790512256711507, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0052030086517333984, 'StateBufferConnector_ms': 0.008443832397460938, 'ViewRequirementAgentConnector_ms': 0.0974569320678711}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 26.339, 'sample_time_ms': 9.065, 'load_time_ms': 0.644, 'load_throughput': 49723.161, 'learn_time_ms': 6.544, 'learn_throughput': 4889.606, 'synch_weights_time_ms': 1.61}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'done': True, 'trial_id': 'e0354_00000', 'perf': {'cpu_util_percent': 58.50999999999999, 'ram_util_percent': 48.519999999999996, 'gpu_util_percent0': 0.10800000000000001, 'vram_util_percent0': 0.09476725260416666}, 'experiment_tag': '0'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00000_0_2023-05-08_22-57-01',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00000_0_2023-05-08_22-57-01/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 830.696044921875, 'min_q': 598.7127075195312, 'max_q': 3740.342529296875, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 62250.0, 'diff_num_grad_updates_vs_sampler_policy': 62249.0, 'td_error': array([ -494.90778 ,   700.87665 ,   -49.31543 ,  -414.51056 ,\n        -142.86005 ,   275.40427 ,   183.0188  ,    16.275146,\n         -97.127625,   423.50797 ,   140.36664 ,   908.44904 ,\n        -325.50836 ,   690.793   ,   751.3129  ,  -117.524475,\n         510.63824 ,   754.5011  ,   733.8905  ,  -919.09094 ,\n        1022.54114 ,   112.25018 ,  -194.01544 , -1987.2849  ,\n        -832.207   ,   584.0542  ,   328.01736 ,  -103.41821 ,\n         136.14087 ,  -393.32452 ,   266.92004 ,  -440.346   ],\n      dtype=float32), 'mean_td_error': 63.35989761352539}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'sampler_results': {'episode_reward_max': 9286.486208018661, 'episode_reward_min': -4794.2555237449515, 'episode_reward_mean': 341.0700783347602, 'episode_len_mean': 30.0, 'episode_media': {}, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [88.84006547710487, 631.0056507240733, 896.2834304699973, -1353.0596827610534, 3032.9269338516497, -492.4175972799021, 300.66271568513, 265.0390887348458, -209.51268735224767, 990.4133352299614, -572.4704076672388, -9.39417194172347, 413.02091707193176, -821.9625792208353, 1856.222433212526, -2533.037658736438, -4794.2555237449515, -412.29097663385437, 9286.486208018661, -1067.723009760457, 131.2761890451966, -97.59300419630381, -870.4989028550481, 910.1449903247903, 552.5948584936868, 20.238885990796916, -304.0228752341791, -210.9401074958514, 1575.2712466475186, 138.9842149304459, 6150.314589785536, -151.52569381320245, -1330.6082952377674, -932.121177832405, 222.8157772735267, -1965.111739944321, 2751.512181087115, 3951.007430843498, 1082.220838377074, 3117.6057616599555, -2873.065955635887, -2362.193132228629, -236.61113460056004, 841.8537221463357, 1674.050183493693, 2893.1156097161966, 2233.4394567614618, 2186.7770684568895, -3208.9962148463746, 3229.5647078024704, -1182.2358824300645, 1221.279788261394, 0.0, 3133.7477146406527, 1383.2660761008283, 1258.6530178539851, 536.6612356718906, -79.02965083120944, -2627.836537282691, -1795.734414268034, 1239.500470803674, 894.9306118231598, 1151.067715200912, 186.92880717652042, 182.2911803699044, 3326.152761544383, 917.3151985010372, 2099.004486366797, 847.6877483073786, 1203.6226226329109, -200.82514659633125, 671.5948861125962, 1589.3868571244566, 1050.946817975626, 1040.8845309033059, -173.3659160446132, -1551.9329191837514, -4130.792734007685, -2181.7083607059767, 2146.0489673244374, -299.0238954829674, 1215.674642729935, -1992.0241349609814, 1141.0410549232874, -2676.4247737931546, -969.3831369453274, 223.48727358691576, 281.47926606758483, -129.41781862209973, 299.2178009480922, 201.18118145377048, 127.3194134760488, 1590.1015279293515, -1274.290908946672, 1745.1470995082327, 757.0636673865702, -1340.840471521702, 404.0561688467769, -1061.224474231205, -907.9175445147612], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.398250965664971, 'mean_inference_ms': 1.2812900129075147, 'mean_action_processing_ms': 0.2647514041121147, 'mean_env_wait_ms': 0.4400486709898593, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005103111267089844, 'StateBufferConnector_ms': 0.008459329605102539, 'ViewRequirementAgentConnector_ms': 0.10594606399536133}}, 'episode_reward_max': 9286.486208018661, 'episode_reward_min': -4794.2555237449515, 'episode_reward_mean': 341.0700783347602, 'episode_len_mean': 30.0, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [88.84006547710487, 631.0056507240733, 896.2834304699973, -1353.0596827610534, 3032.9269338516497, -492.4175972799021, 300.66271568513, 265.0390887348458, -209.51268735224767, 990.4133352299614, -572.4704076672388, -9.39417194172347, 413.02091707193176, -821.9625792208353, 1856.222433212526, -2533.037658736438, -4794.2555237449515, -412.29097663385437, 9286.486208018661, -1067.723009760457, 131.2761890451966, -97.59300419630381, -870.4989028550481, 910.1449903247903, 552.5948584936868, 20.238885990796916, -304.0228752341791, -210.9401074958514, 1575.2712466475186, 138.9842149304459, 6150.314589785536, -151.52569381320245, -1330.6082952377674, -932.121177832405, 222.8157772735267, -1965.111739944321, 2751.512181087115, 3951.007430843498, 1082.220838377074, 3117.6057616599555, -2873.065955635887, -2362.193132228629, -236.61113460056004, 841.8537221463357, 1674.050183493693, 2893.1156097161966, 2233.4394567614618, 2186.7770684568895, -3208.9962148463746, 3229.5647078024704, -1182.2358824300645, 1221.279788261394, 0.0, 3133.7477146406527, 1383.2660761008283, 1258.6530178539851, 536.6612356718906, -79.02965083120944, -2627.836537282691, -1795.734414268034, 1239.500470803674, 894.9306118231598, 1151.067715200912, 186.92880717652042, 182.2911803699044, 3326.152761544383, 917.3151985010372, 2099.004486366797, 847.6877483073786, 1203.6226226329109, -200.82514659633125, 671.5948861125962, 1589.3868571244566, 1050.946817975626, 1040.8845309033059, -173.3659160446132, -1551.9329191837514, -4130.792734007685, -2181.7083607059767, 2146.0489673244374, -299.0238954829674, 1215.674642729935, -1992.0241349609814, 1141.0410549232874, -2676.4247737931546, -969.3831369453274, 223.48727358691576, 281.47926606758483, -129.41781862209973, 299.2178009480922, 201.18118145377048, 127.3194134760488, 1590.1015279293515, -1274.290908946672, 1745.1470995082327, 757.0636673865702, -1340.840471521702, 404.0561688467769, -1061.224474231205, -907.9175445147612], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.398250965664971, 'mean_inference_ms': 1.2812900129075147, 'mean_action_processing_ms': 0.2647514041121147, 'mean_env_wait_ms': 0.4400486709898593, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005103111267089844, 'StateBufferConnector_ms': 0.008459329605102539, 'ViewRequirementAgentConnector_ms': 0.10594606399536133}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 26.406, 'sample_time_ms': 8.531, 'load_time_ms': 0.681, 'load_throughput': 47008.17, 'learn_time_ms': 6.792, 'learn_throughput': 4711.444, 'synch_weights_time_ms': 1.537}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'done': True, 'trial_id': 'e0354_00001', 'perf': {'cpu_util_percent': 59.111111111111114, 'ram_util_percent': 49.01111111111111, 'gpu_util_percent0': 0.11444444444444445, 'vram_util_percent0': 0.09618236400462962}, 'experiment_tag': '1'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00001_1_2023-05-08_22-57-10',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00001_1_2023-05-08_22-57-10/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 820.7243041992188, 'min_q': 524.4407348632812, 'max_q': 3207.036865234375, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 62250.0, 'diff_num_grad_updates_vs_sampler_policy': 62249.0, 'td_error': array([ 588.7447  ,  578.3297  , -425.0055  , -216.39728 ,  681.02075 ,\n       -271.229   , -492.11353 , 1053.7468  ,  229.36517 ,  175.01999 ,\n       -316.82477 ,  487.3993  , -236.91467 ,  280.8276  ,  542.509   ,\n        628.00037 ,  164.37714 ,  -16.595459,  181.57977 , -184.9082  ,\n        524.44073 ,  100.17694 ,  591.47156 ,  212.97107 ,  278.24423 ,\n       -282.14886 ,  463.4768  , -625.2848  ,  725.72394 ,  205.1109  ,\n        -38.18628 , -177.30646 ], dtype=float32), 'mean_td_error': 169.05067443847656}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'sampler_results': {'episode_reward_max': 14401.74091051632, 'episode_reward_min': -4710.047519417207, 'episode_reward_mean': 916.6605062713262, 'episode_len_mean': 30.0, 'episode_media': {}, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-781.7568859792536, 121.04818842667191, 2899.1132195736973, -150.4788473005574, 4557.100184238119, 1315.0722288975412, 635.2579051803023, 1713.9178481260315, -488.1127261371803, -1197.6259338330747, 374.7604094897215, -658.8913057269165, -570.861555326268, -2358.9085524207594, 2246.6655336894655, 2246.6655336894655, -1230.3536120995523, 4016.642310385392, -402.4543113996406, 770.4408444399796, 751.8233756497611, 0.0, -797.5317201994985, 522.3358187221856, -616.509369493042, 4068.2762813178506, 1823.7225396219292, 1098.1504145925937, 2868.2998000658918, -2178.5868776115303, 1250.1448953000254, -72.00692798175442, -385.5924014452339, 2171.2486043098015, 11083.740382329896, -350.420767814001, 3583.3782040056685, 168.98125735412032, 483.5731953697923, 14401.74091051632, -140.36865864136053, 5144.893816909158, 656.1280173804716, -4710.047519417207, 478.87146000749453, 4403.2847038049695, 4125.864013480608, -617.6885886444325, 2699.862202585944, -1227.2773044663172, 934.5866784633326, 3755.674773656954, 47.24474719911632, 758.7657384931863, -566.3511980171115, 807.1479363236849, -863.7407350701578, 3682.321606168285, 1703.5291068901497, 3360.4866670344836, -275.58183141020345, -1036.2599271693362, -1658.1412785425855, -117.20200266235406, -360.1855026382691, 2057.2360080351937, 132.11523411722555, 9.604243697960555, -1014.0557168864325, 311.10852947012245, 1071.706699737715, -1533.60221209687, 0.0, 0.0, 0.0, -192.96776760092507, -224.34856246898198, -1861.0656550616432, -733.9975236434893, 1730.7593494750818, 2344.1373335329954, 1894.949774816605, 1544.6674467320881, -1086.4199512874893, 739.8778517321371, 536.5754056695478, -595.3485584709106, 527.2589932355677, 0.0, 5736.387518979302, 0.0, 0.0, 201.50381306585587, -1164.662758092485, 1301.243504958773, 778.2984762328833, -1155.1925117731462, 1354.6694604563654, 3808.579778218731, 1229.2074101083672], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.4235531266281747, 'mean_inference_ms': 1.273865912396112, 'mean_action_processing_ms': 0.2609201575689162, 'mean_env_wait_ms': 0.441916375588207, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005361795425415039, 'StateBufferConnector_ms': 0.008097171783447266, 'ViewRequirementAgentConnector_ms': 0.10656261444091797}}, 'episode_reward_max': 14401.74091051632, 'episode_reward_min': -4710.047519417207, 'episode_reward_mean': 916.6605062713262, 'episode_len_mean': 30.0, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-781.7568859792536, 121.04818842667191, 2899.1132195736973, -150.4788473005574, 4557.100184238119, 1315.0722288975412, 635.2579051803023, 1713.9178481260315, -488.1127261371803, -1197.6259338330747, 374.7604094897215, -658.8913057269165, -570.861555326268, -2358.9085524207594, 2246.6655336894655, 2246.6655336894655, -1230.3536120995523, 4016.642310385392, -402.4543113996406, 770.4408444399796, 751.8233756497611, 0.0, -797.5317201994985, 522.3358187221856, -616.509369493042, 4068.2762813178506, 1823.7225396219292, 1098.1504145925937, 2868.2998000658918, -2178.5868776115303, 1250.1448953000254, -72.00692798175442, -385.5924014452339, 2171.2486043098015, 11083.740382329896, -350.420767814001, 3583.3782040056685, 168.98125735412032, 483.5731953697923, 14401.74091051632, -140.36865864136053, 5144.893816909158, 656.1280173804716, -4710.047519417207, 478.87146000749453, 4403.2847038049695, 4125.864013480608, -617.6885886444325, 2699.862202585944, -1227.2773044663172, 934.5866784633326, 3755.674773656954, 47.24474719911632, 758.7657384931863, -566.3511980171115, 807.1479363236849, -863.7407350701578, 3682.321606168285, 1703.5291068901497, 3360.4866670344836, -275.58183141020345, -1036.2599271693362, -1658.1412785425855, -117.20200266235406, -360.1855026382691, 2057.2360080351937, 132.11523411722555, 9.604243697960555, -1014.0557168864325, 311.10852947012245, 1071.706699737715, -1533.60221209687, 0.0, 0.0, 0.0, -192.96776760092507, -224.34856246898198, -1861.0656550616432, -733.9975236434893, 1730.7593494750818, 2344.1373335329954, 1894.949774816605, 1544.6674467320881, -1086.4199512874893, 739.8778517321371, 536.5754056695478, -595.3485584709106, 527.2589932355677, 0.0, 5736.387518979302, 0.0, 0.0, 201.50381306585587, -1164.662758092485, 1301.243504958773, 778.2984762328833, -1155.1925117731462, 1354.6694604563654, 3808.579778218731, 1229.2074101083672], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.4235531266281747, 'mean_inference_ms': 1.273865912396112, 'mean_action_processing_ms': 0.2609201575689162, 'mean_env_wait_ms': 0.441916375588207, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005361795425415039, 'StateBufferConnector_ms': 0.008097171783447266, 'ViewRequirementAgentConnector_ms': 0.10656261444091797}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 26.236, 'sample_time_ms': 8.53, 'load_time_ms': 0.674, 'load_throughput': 47475.409, 'learn_time_ms': 6.845, 'learn_throughput': 4675.256, 'synch_weights_time_ms': 1.531}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'done': True, 'trial_id': 'e0354_00002', 'perf': {'cpu_util_percent': 59.111111111111114, 'ram_util_percent': 49.01111111111111, 'gpu_util_percent0': 0.1111111111111111, 'vram_util_percent0': 0.09618236400462962}, 'experiment_tag': '2'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00002_2_2023-05-08_22-57-19',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00002_2_2023-05-08_22-57-19/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 1007.6778564453125, 'min_q': 647.23486328125, 'max_q': 3442.6640625, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 62250.0, 'diff_num_grad_updates_vs_sampler_policy': 62249.0, 'td_error': array([ -292.72095 ,   673.4886  ,   -39.943115,   710.74884 ,\n        -868.88135 ,   -87.53064 ,   232.81714 ,   765.2707  ,\n        2219.437   ,   377.7622  , -1329.6433  ,    67.00751 ,\n       -1540.22    ,  -180.9187  ,   186.71631 , -1782.2517  ,\n        -869.12305 ,   158.99115 ,  -551.2317  ,   729.0738  ,\n        1773.2593  ,   225.88843 ,    72.535095,  -197.42224 ,\n       -1024.4429  ,   751.3044  ,    20.211609,  -185.09528 ,\n         433.6814  ,   125.117004,   -67.202515,   147.99393 ],\n      dtype=float32), 'mean_td_error': 20.458656311035156}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'sampler_results': {'episode_reward_max': 6492.909179205581, 'episode_reward_min': -4614.737952138948, 'episode_reward_mean': 515.0257694955372, 'episode_len_mean': 30.0, 'episode_media': {}, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1492.6195620477192, 0.0, 0.0, -437.4722706914363, 175.40687762061498, 1650.2442836223581, 1082.66977433162, -93.94386439458685, 3047.4742648488736, 915.0388541912962, -111.61669733677081, 805.336148046028, -1788.7434294633786, 1274.4508854944215, -816.8719487060971, 5539.865019625799, 539.4689028001976, 983.3990730501464, 707.8335021239964, 4369.018289852282, -496.5233192968408, -4614.737952138948, 4947.707719497817, 4036.2477115806814, -41.93548591957551, 2765.6105378351913, -696.9789309704393, 121.7842678053803, -1270.8174435495948, 6492.909179205581, 2322.2003255486397, -725.42955989236, 5442.214789402464, -395.94603220790486, 1063.7009419836759, 5311.490486602097, 2160.4851327585966, 491.62230651985556, -351.94875157623574, -366.59163844924115, 204.45711367392687, -670.9858993846647, -794.501021266653, 93.45733541155278, -1772.5386536378628, 720.4756903197231, -1158.3523724349798, -2102.596260065481, -1584.1140941460671, 4220.55648170235, -1245.0993988532227, -2471.9074206451905, -200.01708808625517, 569.0447725129306, 407.97005251034534, -310.1404460439553, -2845.943779042721, -1472.7878423901457, -745.5954798923576, 3545.813542994032, 3004.9537790041613, 2065.883428294612, 3413.2028824659665, -1319.175649971341, -400.7978534080885, 38.40511058228367, 1418.9752780628587, -1.804044342288762, 625.3529838493923, -106.40547721510848, 1401.7454966776822, -988.7778002468367, 1046.0886128846341, 881.6274163704184, 899.7123301636748, -942.7779887685665, 557.3549552996974, 1145.9960823620695, -756.3169816177742, 3339.8769126064763, -1825.8687312401216, -87.07099475874384, -1907.2116876864957, 1020.632112261299, 1925.1850228706408, 158.01202045198988, 4666.533610285762, -1433.6825619363954, -544.5663625893412, -57.09569980183369, 148.96628115477506, -856.3086360901652, 395.1519281665278, 3151.580938043535, -1748.6363561795115, -984.7584861885989, -835.9625506721732, -3002.4990524422556, -330.69746510898403, 411.3174029226684], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.328430283781042, 'mean_inference_ms': 1.2419254373239608, 'mean_action_processing_ms': 0.2597332373917719, 'mean_env_wait_ms': 0.4266154262459677, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00476384162902832, 'StateBufferConnector_ms': 0.007829904556274414, 'ViewRequirementAgentConnector_ms': 0.09486627578735352}}, 'episode_reward_max': 6492.909179205581, 'episode_reward_min': -4614.737952138948, 'episode_reward_mean': 515.0257694955372, 'episode_len_mean': 30.0, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1492.6195620477192, 0.0, 0.0, -437.4722706914363, 175.40687762061498, 1650.2442836223581, 1082.66977433162, -93.94386439458685, 3047.4742648488736, 915.0388541912962, -111.61669733677081, 805.336148046028, -1788.7434294633786, 1274.4508854944215, -816.8719487060971, 5539.865019625799, 539.4689028001976, 983.3990730501464, 707.8335021239964, 4369.018289852282, -496.5233192968408, -4614.737952138948, 4947.707719497817, 4036.2477115806814, -41.93548591957551, 2765.6105378351913, -696.9789309704393, 121.7842678053803, -1270.8174435495948, 6492.909179205581, 2322.2003255486397, -725.42955989236, 5442.214789402464, -395.94603220790486, 1063.7009419836759, 5311.490486602097, 2160.4851327585966, 491.62230651985556, -351.94875157623574, -366.59163844924115, 204.45711367392687, -670.9858993846647, -794.501021266653, 93.45733541155278, -1772.5386536378628, 720.4756903197231, -1158.3523724349798, -2102.596260065481, -1584.1140941460671, 4220.55648170235, -1245.0993988532227, -2471.9074206451905, -200.01708808625517, 569.0447725129306, 407.97005251034534, -310.1404460439553, -2845.943779042721, -1472.7878423901457, -745.5954798923576, 3545.813542994032, 3004.9537790041613, 2065.883428294612, 3413.2028824659665, -1319.175649971341, -400.7978534080885, 38.40511058228367, 1418.9752780628587, -1.804044342288762, 625.3529838493923, -106.40547721510848, 1401.7454966776822, -988.7778002468367, 1046.0886128846341, 881.6274163704184, 899.7123301636748, -942.7779887685665, 557.3549552996974, 1145.9960823620695, -756.3169816177742, 3339.8769126064763, -1825.8687312401216, -87.07099475874384, -1907.2116876864957, 1020.632112261299, 1925.1850228706408, 158.01202045198988, 4666.533610285762, -1433.6825619363954, -544.5663625893412, -57.09569980183369, 148.96628115477506, -856.3086360901652, 395.1519281665278, 3151.580938043535, -1748.6363561795115, -984.7584861885989, -835.9625506721732, -3002.4990524422556, -330.69746510898403, 411.3174029226684], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.328430283781042, 'mean_inference_ms': 1.2419254373239608, 'mean_action_processing_ms': 0.2597332373917719, 'mean_env_wait_ms': 0.4266154262459677, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00476384162902832, 'StateBufferConnector_ms': 0.007829904556274414, 'ViewRequirementAgentConnector_ms': 0.09486627578735352}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 25.941, 'sample_time_ms': 8.401, 'load_time_ms': 0.668, 'load_throughput': 47909.237, 'learn_time_ms': 6.793, 'learn_throughput': 4710.386, 'synch_weights_time_ms': 1.534}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'done': True, 'trial_id': 'e0354_00003', 'perf': {'cpu_util_percent': 43.43333333333333, 'ram_util_percent': 46.08888888888889, 'gpu_util_percent0': 0.07222222222222223, 'vram_util_percent0': 0.08382161458333333}, 'experiment_tag': '3'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00003_3_2023-05-08_23-26-21',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00003_3_2023-05-08_23-26-21/checkpoint_000250)\n  ),\n  Result(\n    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'mean_q': 645.5509033203125, 'min_q': 498.14642333984375, 'max_q': 2580.9814453125, 'cur_lr': 0.0005}, 'model': {}, 'num_grad_updates_lifetime': 62250.0, 'diff_num_grad_updates_vs_sampler_policy': 62249.0, 'td_error': array([  775.4562  ,  -175.47064 ,   475.0012  ,   378.65326 ,\n        -236.08026 , -1916.2292  ,   545.3888  ,   -23.301636,\n        -308.95105 ,    18.03186 ,  -592.37103 , -1060.7195  ,\n         771.38556 , -1161.8762  ,  -239.75995 ,   -98.680176,\n        -634.98395 ,  -541.64417 ,   278.516   ,  -421.1704  ,\n         864.7262  ,  -289.14252 ,   -16.51471 ,  -104.609375,\n        -809.8446  ,  -225.93994 ,  -464.45453 ,  -287.42578 ,\n         729.15015 ,   596.4624  ,   709.34143 ,  -107.711365],\n      dtype=float32), 'mean_td_error': -111.71150207519531}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'sampler_results': {'episode_reward_max': 9442.460725921326, 'episode_reward_min': -2675.781535324638, 'episode_reward_mean': 721.0745383248693, 'episode_len_mean': 30.0, 'episode_media': {}, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1275.8260658817999, 1233.8991449257428, 1598.8390007439539, 71.27606599942374, -84.85621464323776, -120.28158106027513, 2172.7658977718056, -638.9149225738711, 126.73936239257273, -458.5571467287973, 1081.3708169394831, 1481.8486272003847, 4020.2007356797385, 85.1492509499567, -922.9312209443706, -338.96835488598117, 86.41870377008127, 217.65092233865835, 1113.1804112819755, 3535.2742109901938, -2346.411578817526, -2254.999028147806, -1544.397978350953, 3152.5215050737424, -771.4236358635408, 1200.158485184098, -437.16959022640003, 1920.7617872092324, 387.57542254135296, 903.0400370565258, 227.19845937154787, -1387.0438304140025, -1713.2318501796071, 9442.460725921326, 277.5442569177303, -249.0648400029586, 0.0, 0.0, 0.0, 60.90317336274529, 4237.521666114728, -1488.7998859520212, -91.03423844595636, 1335.495624150839, -61.42393560273922, 1071.4485356953937, -432.9861281866597, -1218.6777404091827, -2378.169200869236, 557.7346138120447, 2194.506057534856, -942.3911834007831, -1769.8631845350392, 3535.468817699095, 1289.4852133606382, -104.32313840700772, -226.75295536164958, 2476.3102647983487, 343.22672920084005, -1603.6334831411805, -299.1514281417094, 2501.1189777281543, -2130.7755005697163, 2657.1005656074067, 1808.1241724686151, 912.5290933081451, -2476.7923809098766, -798.9046354908005, 7133.66830155268, -209.82727271704607, 4984.348360930242, 7277.267556854753, 4512.975526002481, -175.26227029727124, 6372.911445338443, -617.7213667756441, 3869.7500194292024, 2551.6150418201196, -2675.781535324638, -1175.481063014413, 60.82305251478101, -353.9499341711562, -1171.2542802375337, 530.0339762566309, 1953.5025825435896, 974.8537921084735, 577.1247430666226, 869.3459809941742, 5302.502625993837, -728.293102777734, 375.8096567143166, 1606.240615867171, 349.8009609446144, 1601.3567726266247, -1455.0038258360746, -1406.7305716376432, -127.9145650029568, 0.0, 0.0, 0.0], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3650437455874695, 'mean_inference_ms': 1.2471179458749573, 'mean_action_processing_ms': 0.25845147357268405, 'mean_env_wait_ms': 0.4346733442228473, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005007266998291016, 'StateBufferConnector_ms': 0.007889986038208008, 'ViewRequirementAgentConnector_ms': 0.09683346748352051}}, 'episode_reward_max': 9442.460725921326, 'episode_reward_min': -2675.781535324638, 'episode_reward_mean': 721.0745383248693, 'episode_len_mean': 30.0, 'episodes_this_iter': 32, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1275.8260658817999, 1233.8991449257428, 1598.8390007439539, 71.27606599942374, -84.85621464323776, -120.28158106027513, 2172.7658977718056, -638.9149225738711, 126.73936239257273, -458.5571467287973, 1081.3708169394831, 1481.8486272003847, 4020.2007356797385, 85.1492509499567, -922.9312209443706, -338.96835488598117, 86.41870377008127, 217.65092233865835, 1113.1804112819755, 3535.2742109901938, -2346.411578817526, -2254.999028147806, -1544.397978350953, 3152.5215050737424, -771.4236358635408, 1200.158485184098, -437.16959022640003, 1920.7617872092324, 387.57542254135296, 903.0400370565258, 227.19845937154787, -1387.0438304140025, -1713.2318501796071, 9442.460725921326, 277.5442569177303, -249.0648400029586, 0.0, 0.0, 0.0, 60.90317336274529, 4237.521666114728, -1488.7998859520212, -91.03423844595636, 1335.495624150839, -61.42393560273922, 1071.4485356953937, -432.9861281866597, -1218.6777404091827, -2378.169200869236, 557.7346138120447, 2194.506057534856, -942.3911834007831, -1769.8631845350392, 3535.468817699095, 1289.4852133606382, -104.32313840700772, -226.75295536164958, 2476.3102647983487, 343.22672920084005, -1603.6334831411805, -299.1514281417094, 2501.1189777281543, -2130.7755005697163, 2657.1005656074067, 1808.1241724686151, 912.5290933081451, -2476.7923809098766, -798.9046354908005, 7133.66830155268, -209.82727271704607, 4984.348360930242, 7277.267556854753, 4512.975526002481, -175.26227029727124, 6372.911445338443, -617.7213667756441, 3869.7500194292024, 2551.6150418201196, -2675.781535324638, -1175.481063014413, 60.82305251478101, -353.9499341711562, -1171.2542802375337, 530.0339762566309, 1953.5025825435896, 974.8537921084735, 577.1247430666226, 869.3459809941742, 5302.502625993837, -728.293102777734, 375.8096567143166, 1606.240615867171, 349.8009609446144, 1601.3567726266247, -1455.0038258360746, -1406.7305716376432, -127.9145650029568, 0.0, 0.0, 0.0], 'episode_lengths': [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.3650437455874695, 'mean_inference_ms': 1.2471179458749573, 'mean_action_processing_ms': 0.25845147357268405, 'mean_env_wait_ms': 0.4346733442228473, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005007266998291016, 'StateBufferConnector_ms': 0.007889986038208008, 'ViewRequirementAgentConnector_ms': 0.09683346748352051}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 8000, 'num_steps_trained_this_iter': 8000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 25.116, 'sample_time_ms': 8.179, 'load_time_ms': 0.601, 'load_throughput': 53244.1, 'learn_time_ms': 6.316, 'learn_throughput': 5066.885, 'synch_weights_time_ms': 1.503}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 1992000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 1992000, 'last_target_update_ts': 249504, 'num_target_updates': 498}, 'done': True, 'trial_id': 'e0354_00004', 'perf': {'cpu_util_percent': 43.388888888888886, 'ram_util_percent': 46.1, 'gpu_util_percent0': 0.07111111111111111, 'vram_util_percent0': 0.08382161458333333}, 'experiment_tag': '4'},\n    path='/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00004_4_2023-05-08_23-26-21',\n    checkpoint=Checkpoint(local_path=/home/fassty/Devel/school/diploma_thesis/code/exp_results/DQN/DQN_1h/DQN_StockExchangeEnv-v1_e0354_00004_4_2023-05-08_23-26-21/checkpoint_000250)\n  )\n]>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune, air\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "from rl_trading.simulation.env import StockExchangeEnv1\n",
    "\n",
    "config = (\n",
    "    DQNConfig()\n",
    "    .rollouts(num_rollout_workers=1, num_envs_per_worker=4)\n",
    "    .resources(num_gpus=0.25)\n",
    "    .environment(env='StockExchangeEnv-v1', env_config={'sim_config': {'granularity': '1d', 'max_steps': 30}})\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"DQN\",\n",
    "    run_config=air.RunConfig(\n",
    "        name='DQN_1h',\n",
    "        local_dir='../exp_results/DQN',\n",
    "        stop={\"training_iteration\": 250},\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=5\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Network:\n",
    "    def __init__(self) -> None:\n",
    "        # Use GPU if available.\n",
    "        self._device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        ).to(self._device)\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=1e-3)\n",
    "        self._loss = nn.MSELoss()\n",
    "\n",
    "    def train(self, states: np.ndarray, actions: np.ndarray, q_values: np.ndarray) -> None:\n",
    "        states = torch.from_numpy(states).float().to(self._device)\n",
    "        q_values = torch.from_numpy(q_values).float().to(self._device)\n",
    "        actions = torch.from_numpy(actions).long().to(self._device)\n",
    "\n",
    "        self._model.train()\n",
    "        self._optimizer.zero_grad()\n",
    "        predictions = self._model(states)\n",
    "        predictions = torch.gather(predictions, dim=1, index=actions)\n",
    "        loss = self._loss(predictions, q_values)\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self._model.parameters(), 10)\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def predict(self, states: np.ndarray) -> np.ndarray:\n",
    "        states = torch.from_numpy(states).float().to(self._device)\n",
    "        self._model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self._model(states).cpu().numpy()\n",
    "\n",
    "    def copy_weights_from(self, other) -> None:\n",
    "        params = dict(self._model.named_parameters())\n",
    "        params_other = dict(other._model.named_parameters())\n",
    "        with torch.no_grad():\n",
    "            for name, value in params_other.items():\n",
    "                params[name].data.copy_(value.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 return: 224.99744838047303\n",
      "Episode: 1 return: 264.531597508022\n",
      "Episode: 2 return: 10.526600750194191\n",
      "Episode: 3 return: 463.344433536383\n",
      "Episode: 4 return: 107.36902379122189\n",
      "Episode: 5 return: 659.0909868725554\n",
      "Episode: 6 return: 93.25250433980881\n",
      "Episode: 7 return: -754.3228877029144\n",
      "Episode: 8 return: -12.09655519360639\n",
      "Episode: 9 return: -4.448079854905141\n",
      "Episode: 10 return: 404.5836446362279\n",
      "Episode: 11 return: 202.75678159449467\n",
      "Episode: 12 return: -403.27718192251444\n",
      "Episode: 13 return: -319.655870002426\n",
      "Episode: 14 return: -126.48002786972344\n",
      "Episode: 15 return: -267.77574004643776\n",
      "Episode: 16 return: 175.35113259349407\n",
      "Episode: 17 return: 712.920821829259\n",
      "Episode: 18 return: 370.2768818837727\n",
      "Episode: 19 return: -240.6320419818552\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "network = Network()\n",
    "\n",
    "epsilon = 0.5\n",
    "gamma = 0.99\n",
    "\n",
    "replay_buffer = collections.deque()\n",
    "\n",
    "Transition = collections.namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"done\", \"next_state\"])\n",
    "\n",
    "for episode in range(20):\n",
    "    state, done = env.reset()\n",
    "    episode_return = 0\n",
    "\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            q_values = network.predict(np.array([state], dtype=np.float32))[0]\n",
    "        if np.random.uniform() >= epsilon:\n",
    "            action = np.argmax(q_values)\n",
    "        else:\n",
    "            action = np.random.randint(0, 3)\n",
    "\n",
    "        next_state, reward, done = env.step(action)\n",
    "        episode_return += reward\n",
    "        replay_buffer.append(Transition(state, action, reward, done, next_state))\n",
    "\n",
    "\n",
    "        if len(replay_buffer) > 512:\n",
    "            minibatch = random.sample(replay_buffer, 512)\n",
    "            states = np.vstack([t.state for t in minibatch])\n",
    "            actions = np.vstack([t.action for t in minibatch])\n",
    "            rewards = np.vstack([t.reward for t in minibatch])\n",
    "            next_states = np.vstack([t.next_state for t in minibatch])\n",
    "            dones = np.vstack([t.done for t in minibatch]).astype(np.uint8)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_values_next = network.predict(next_states)\n",
    "                q_values_next = q_values_next.max(axis=1).reshape(-1, 1)\n",
    "                target_q_values = rewards + (1 - dones) * gamma * q_values_next\n",
    "            network.train(states, actions, target_q_values)\n",
    "\n",
    "        state = next_state\n",
    "    print(f'Episode: {episode} return: {episode_return}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "-19.080000000000837"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4261.48 - 4280.56"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 3829.47615283,   872.362006  ,  3829.47615283,  3829.47615283,\n            0.        ,    50.        ,  3829.47615283, 10000.        ,\n            0.        ]),\n {})"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 3.80494806e+03,  3.85813469e+02,  3.80876260e+03,  3.81634181e+03,\n        -6.61621262e-01,  4.21757695e+01,  3.81111808e+03,  0.00000000e+00,\n         2.62047935e+00]),\n -13.047519166573693,\n False,\n False,\n {})"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "                amount         price\ntimestamp                           \n1502942460    1.775183   4261.480000\n1502942580    0.261074   4280.560000\n1502942640    0.012008   4261.480000\n1502942700    0.140796   4261.480000\n1502943480    0.075455   4262.187216\n...                ...           ...\n1670479020  140.372990  16822.509019\n1670479080  135.652550  16823.593779\n1670479140  106.761210  16823.667239\n1670479200  160.929330  16820.593849\n1670479260  311.577950  16812.328981\n\n[2760153 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1502942460</th>\n      <td>1.775183</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502942580</th>\n      <td>0.261074</td>\n      <td>4280.560000</td>\n    </tr>\n    <tr>\n      <th>1502942640</th>\n      <td>0.012008</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502942700</th>\n      <td>0.140796</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>1502943480</th>\n      <td>0.075455</td>\n      <td>4262.187216</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1670479020</th>\n      <td>140.372990</td>\n      <td>16822.509019</td>\n    </tr>\n    <tr>\n      <th>1670479080</th>\n      <td>135.652550</td>\n      <td>16823.593779</td>\n    </tr>\n    <tr>\n      <th>1670479140</th>\n      <td>106.761210</td>\n      <td>16823.667239</td>\n    </tr>\n    <tr>\n      <th>1670479200</th>\n      <td>160.929330</td>\n      <td>16820.593849</td>\n    </tr>\n    <tr>\n      <th>1670479260</th>\n      <td>311.577950</td>\n      <td>16812.328981</td>\n    </tr>\n  </tbody>\n</table>\n<p>2760153 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prices_df = pd.read_hdf('data/binance_BTC_USDT.h5')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                         amount         price\ntimestamp                                    \n2017-08-17 04:01:00    1.775183   4261.480000\n2017-08-17 04:03:00    0.261074   4280.560000\n2017-08-17 04:04:00    0.012008   4261.480000\n2017-08-17 04:05:00    0.140796   4261.480000\n2017-08-17 04:18:00    0.075455   4262.187216\n...                         ...           ...\n2022-12-08 05:57:00  140.372990  16822.509019\n2022-12-08 05:58:00  135.652550  16823.593779\n2022-12-08 05:59:00  106.761210  16823.667239\n2022-12-08 06:00:00  160.929330  16820.593849\n2022-12-08 06:01:00  311.577950  16812.328981\n\n[2760153 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-08-17 04:01:00</th>\n      <td>1.775183</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:03:00</th>\n      <td>0.261074</td>\n      <td>4280.560000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:04:00</th>\n      <td>0.012008</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:05:00</th>\n      <td>0.140796</td>\n      <td>4261.480000</td>\n    </tr>\n    <tr>\n      <th>2017-08-17 04:18:00</th>\n      <td>0.075455</td>\n      <td>4262.187216</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:57:00</th>\n      <td>140.372990</td>\n      <td>16822.509019</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:58:00</th>\n      <td>135.652550</td>\n      <td>16823.593779</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 05:59:00</th>\n      <td>106.761210</td>\n      <td>16823.667239</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:00:00</th>\n      <td>160.929330</td>\n      <td>16820.593849</td>\n    </tr>\n    <tr>\n      <th>2022-12-08 06:01:00</th>\n      <td>311.577950</td>\n      <td>16812.328981</td>\n    </tr>\n  </tbody>\n</table>\n<p>2760153 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_df.index = pd.to_datetime(prices_df.index * 1e9)\n",
    "prices_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "hourly_prices = prices_df.groupby(pd.Grouper(freq='H')).agg({'amount': 'sum', 'price': 'last'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "hourly_prices['price'] = hourly_prices['price'].ffill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "            #time.sleep(0.01)\n",
    "\n",
    "env = StockExchangeEnv(hourly_prices['price'].to_numpy(), hourly_prices['amount'].to_numpy(), 10_000)\n",
    "\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    env.render()\n",
    "    current_step = env.current_step\n",
    "    current_price = env.price_data[current_step]\n",
    "    next_price = env.price_data[current_step + 1]\n",
    "    if next_price > current_price:\n",
    "        env.step(1)\n",
    "    elif next_price < current_price:\n",
    "        env.step(2)\n",
    "    else:\n",
    "        env.step(0)\n",
    "\n",
    "# for i in range(100):\n",
    "#     env.render()\n",
    "#     current_step = env.current_step\n",
    "#     current_price = env.price_data[current_step]\n",
    "#     next_price = env.price_data[current_step + 1]\n",
    "#     try:\n",
    "#         next_next_price = env.price_data[current_step + 2]\n",
    "#     except IndexError:\n",
    "#         next_next_price = 0\n",
    "#     print(f'{current_price=:.2f}\\t{next_price=:.2f}\\t{next_next_price=:.2f}')\n",
    "#     print('Enter next action: 0 HOLD, 1 BUY, 2 SELL\\n')\n",
    "#     time.sleep(0.1)\n",
    "#     action = int(input())\n",
    "#     env.step(action)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 16:36:43,057\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hourly_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 11\u001B[0m\n\u001B[1;32m      4\u001B[0m ray\u001B[38;5;241m.\u001B[39mshutdown()\n\u001B[1;32m      5\u001B[0m ray\u001B[38;5;241m.\u001B[39minit()\n\u001B[1;32m      7\u001B[0m dqn \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m      8\u001B[0m     PPOConfig()\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;241m.\u001B[39mrollouts(num_rollout_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;241m.\u001B[39mresources(num_gpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;241m.\u001B[39menvironment(env\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStockExchangeEnv-v0\u001B[39m\u001B[38;5;124m'\u001B[39m, env_config\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice_data\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[43mhourly_prices\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprice\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume_data\u001B[39m\u001B[38;5;124m'\u001B[39m: hourly_prices[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitial_cash\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m10_000\u001B[39m})\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m.\u001B[39mbuild()\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m500\u001B[39m):\n\u001B[1;32m     16\u001B[0m     result \u001B[38;5;241m=\u001B[39m dqn\u001B[38;5;241m.\u001B[39mtrain()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'hourly_prices' is not defined"
     ]
    }
   ],
   "source": [
    "from rl_trading."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 23:20:54,623\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 23:20:56,043\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\tMean return: -42.865930799546184\n",
      "Step: 2\tMean return: -185.89766800128746\n",
      "Step: 3\tMean return: 169.17498209446853\n",
      "Step: 4\tMean return: -88.3142230583735\n",
      "Step: 5\tMean return: 19.19788326543157\n",
      "Step: 6\tMean return: -16.45068610735584\n",
      "Step: 7\tMean return: 7.063555817371994\n",
      "Step: 8\tMean return: -38.02530962088903\n",
      "Step: 9\tMean return: -41.522897312310235\n",
      "Step: 10\tMean return: -17.97407142151989\n",
      "Step: 11\tMean return: -19.678367718046115\n",
      "Step: 12\tMean return: 11.896916841168824\n",
      "Step: 13\tMean return: -2.235516732331765\n",
      "Step: 14\tMean return: 12.66614309286765\n",
      "Step: 15\tMean return: -4.661710404750021\n",
      "Step: 16\tMean return: -16.956172854057762\n",
      "Step: 17\tMean return: -11.008859576698496\n",
      "Step: 18\tMean return: 2.480511230930242\n",
      "Step: 19\tMean return: -0.4883398345264868\n",
      "Step: 20\tMean return: 26.459753117181773\n",
      "Step: 21\tMean return: -44.16181603506087\n",
      "Step: 22\tMean return: 20.183706555358384\n",
      "Step: 23\tMean return: -3.228635785139504\n",
      "Step: 24\tMean return: 24.918146317321316\n",
      "Step: 25\tMean return: 8.069768562017744\n",
      "Step: 26\tMean return: 21.183064981363295\n",
      "Step: 27\tMean return: 21.986740159274323\n",
      "Step: 28\tMean return: 18.439004376829672\n",
      "Step: 29\tMean return: 11.235094199674695\n",
      "Step: 30\tMean return: -18.454389558274144\n",
      "Step: 31\tMean return: 0.4779703119930309\n",
      "Step: 32\tMean return: -13.879348664528479\n",
      "Step: 33\tMean return: -4.414854881549072\n",
      "Step: 34\tMean return: 25.30627695867275\n",
      "Step: 35\tMean return: 11.386543775751761\n",
      "Step: 36\tMean return: -0.1694824840252113\n",
      "Step: 37\tMean return: 5.89722545505414\n",
      "Step: 38\tMean return: -4.4858072601322965\n",
      "Step: 39\tMean return: 16.594622618559733\n",
      "Step: 40\tMean return: 1.5351458495108272\n",
      "Step: 41\tMean return: -0.5398200925658057\n",
      "Step: 42\tMean return: -24.769327379975476\n",
      "Step: 43\tMean return: -12.216331839527047\n",
      "Step: 44\tMean return: -5.6329169383652875\n",
      "Step: 45\tMean return: 2.9569144049329954\n",
      "Step: 46\tMean return: -6.85947251076328\n",
      "Step: 47\tMean return: -10.889216984027753\n",
      "Step: 48\tMean return: 23.114663099628014\n",
      "Step: 49\tMean return: -0.5502420291690759\n",
      "Step: 50\tMean return: -0.03243519025008936\n",
      "Step: 51\tMean return: 8.155265680051926\n",
      "Step: 52\tMean return: -12.364523852286984\n",
      "Step: 53\tMean return: 1.7423275592588652\n",
      "Step: 54\tMean return: -2.9104647257931537\n",
      "Step: 55\tMean return: -1.274624985697901\n",
      "Step: 56\tMean return: -5.948164801591283\n",
      "Step: 57\tMean return: -4.296843552254159\n",
      "Step: 58\tMean return: 0.7535884564825028\n",
      "Step: 59\tMean return: 1.7556978045066716\n",
      "Step: 60\tMean return: -1.853147364183351\n",
      "Step: 61\tMean return: -3.563379185676786\n",
      "Step: 62\tMean return: -8.15441640664445\n",
      "Step: 63\tMean return: 8.857036566502702\n",
      "Step: 64\tMean return: -5.640472012687715\n",
      "Step: 65\tMean return: 17.890299769167214\n",
      "Step: 66\tMean return: -6.227366412796091\n",
      "Step: 67\tMean return: 6.002241123134899\n",
      "Step: 68\tMean return: -0.6503603378614571\n",
      "Step: 69\tMean return: 14.26222541596473\n",
      "Step: 70\tMean return: -7.96471444914192\n",
      "Step: 71\tMean return: -3.3576494925343106\n",
      "Step: 72\tMean return: 5.9238466558805705\n",
      "Step: 73\tMean return: 2.278869688476243\n",
      "Step: 74\tMean return: 2.1951016048972813\n",
      "Step: 75\tMean return: 5.831000258159238\n",
      "Step: 76\tMean return: 19.954976040613456\n",
      "Step: 77\tMean return: -3.1514098006923086\n",
      "Step: 78\tMean return: 18.18126420690378\n",
      "Step: 79\tMean return: 12.359239818530005\n",
      "Step: 80\tMean return: 7.520029179113571\n",
      "Step: 81\tMean return: 33.06959100589\n",
      "Step: 82\tMean return: -10.78834427043903\n",
      "Step: 83\tMean return: 2.19704148589266\n",
      "Step: 84\tMean return: -11.169366058550713\n",
      "Step: 85\tMean return: -20.55052874727224\n",
      "Step: 86\tMean return: 4.889533920467129\n",
      "Step: 87\tMean return: 9.552917395456152\n",
      "Step: 88\tMean return: 6.827010386960464\n",
      "Step: 89\tMean return: -4.283908869425541\n",
      "Step: 90\tMean return: -5.920463695723538\n",
      "Step: 91\tMean return: -7.696401481802223\n",
      "Step: 92\tMean return: -1.274082156118384\n",
      "Step: 93\tMean return: -0.9966833829155439\n",
      "Step: 94\tMean return: -29.416883048938743\n",
      "Step: 95\tMean return: 1.9115194717049961\n",
      "Step: 96\tMean return: -8.559848147787397\n",
      "Step: 97\tMean return: -12.002049473328151\n",
      "Step: 98\tMean return: 11.763158872308304\n",
      "Step: 99\tMean return: -55.70089418048187\n",
      "Step: 100\tMean return: 8.303099539169597\n",
      "Step: 101\tMean return: -5.387173962683409\n",
      "Step: 102\tMean return: 0.15743374015153677\n",
      "Step: 103\tMean return: 21.253463931579645\n",
      "Step: 104\tMean return: -7.414427446858481\n",
      "Step: 105\tMean return: -20.44106971161342\n",
      "Step: 106\tMean return: 9.22417627098861\n",
      "Step: 107\tMean return: 12.266956697121405\n",
      "Step: 108\tMean return: 15.951100480172444\n",
      "Step: 109\tMean return: -2.1214888447824523\n",
      "Step: 110\tMean return: 2.4203046201045617\n",
      "Step: 111\tMean return: -20.64621630237246\n",
      "Step: 112\tMean return: 1.7186271443492023\n",
      "Step: 113\tMean return: -5.98968408916191\n",
      "Step: 114\tMean return: -3.1010985089665155\n",
      "Step: 115\tMean return: 6.993591601105536\n",
      "Step: 116\tMean return: -8.45396645010389\n",
      "Step: 117\tMean return: 4.443400243291808\n",
      "Step: 118\tMean return: 3.689592120996431\n",
      "Step: 119\tMean return: -0.3308846379082206\n",
      "Step: 120\tMean return: 9.476881326801685\n",
      "Step: 121\tMean return: -2.7493903070168018\n",
      "Step: 122\tMean return: 12.744914064714877\n",
      "Step: 123\tMean return: -27.061213605054583\n",
      "Step: 124\tMean return: 26.032787864073907\n",
      "Step: 125\tMean return: -7.572462710037326\n",
      "Step: 126\tMean return: -14.998715153064985\n",
      "Step: 127\tMean return: 3.944270100024314\n",
      "Step: 128\tMean return: 6.965684618648993\n",
      "Step: 129\tMean return: 28.794405661250575\n",
      "Step: 130\tMean return: -0.09916588066706027\n",
      "Step: 131\tMean return: -12.322697325607097\n",
      "Step: 132\tMean return: -14.614550331935934\n",
      "Step: 133\tMean return: 84.76851835027965\n",
      "Step: 134\tMean return: -6.868187132219736\n",
      "Step: 135\tMean return: 40.19000268373826\n",
      "Step: 136\tMean return: 4.207196198127567\n",
      "Step: 137\tMean return: -6.432826894016298\n",
      "Step: 138\tMean return: -5.636168948553668\n",
      "Step: 139\tMean return: -20.40009909217013\n",
      "Step: 140\tMean return: -12.170406101052741\n",
      "Step: 141\tMean return: 19.217313118841293\n",
      "Step: 142\tMean return: -34.97545079781148\n",
      "Step: 143\tMean return: -0.16706326786783393\n",
      "Step: 144\tMean return: 3.3568042326129763\n",
      "Step: 145\tMean return: 1.3682514977420215\n",
      "Step: 146\tMean return: -16.722597556131277\n",
      "Step: 147\tMean return: 13.484305100075016\n",
      "Step: 148\tMean return: 9.75127413559294\n",
      "Step: 149\tMean return: 13.794498614061768\n",
      "Step: 150\tMean return: 9.268090216662868\n",
      "Step: 151\tMean return: -94.62656722204203\n",
      "Step: 152\tMean return: 3.628508481198314\n",
      "Step: 153\tMean return: -36.984558655835514\n",
      "Step: 154\tMean return: 5.783475479087319\n",
      "Step: 155\tMean return: -16.578770794790643\n",
      "Step: 156\tMean return: 15.539506604347753\n",
      "Step: 157\tMean return: 19.406608537477222\n",
      "Step: 158\tMean return: -0.5668498523283961\n",
      "Step: 159\tMean return: 28.305688278457275\n",
      "Step: 160\tMean return: 1.986488779114261\n",
      "Step: 161\tMean return: 19.821032106878594\n",
      "Step: 162\tMean return: 0.10210554372612023\n",
      "Step: 163\tMean return: 0.07133902890509489\n",
      "Step: 164\tMean return: 4.534802986544073\n",
      "Step: 165\tMean return: -27.914116224533274\n",
      "Step: 166\tMean return: -6.6545316532119525\n",
      "Step: 167\tMean return: -6.508520830540911\n",
      "Step: 168\tMean return: -1.9184358229138343\n",
      "Step: 169\tMean return: 17.747619968080897\n",
      "Step: 170\tMean return: -10.465071247581491\n",
      "Step: 171\tMean return: 5.371390081361169\n",
      "Step: 172\tMean return: -17.177851310903943\n",
      "Step: 173\tMean return: 46.80327538268074\n",
      "Step: 174\tMean return: -10.800183772193023\n",
      "Step: 175\tMean return: 1.1182332198999212\n",
      "Step: 176\tMean return: -0.008003227887156754\n",
      "Step: 177\tMean return: -26.496197278962544\n",
      "Step: 178\tMean return: 47.41159991882909\n",
      "Step: 179\tMean return: -11.288149776480005\n",
      "Step: 180\tMean return: -12.230596457795873\n",
      "Step: 181\tMean return: 21.124654581577616\n",
      "Step: 182\tMean return: 7.931212433246128\n",
      "Step: 183\tMean return: 3.9017469733571306\n",
      "Step: 184\tMean return: -5.004386519557138\n",
      "Step: 185\tMean return: 12.246911855550225\n",
      "Step: 186\tMean return: -2.048084237550893\n",
      "Step: 187\tMean return: 2.848393428627278\n",
      "Step: 188\tMean return: 16.709036106753246\n",
      "Step: 189\tMean return: -8.513016095252588\n",
      "Step: 190\tMean return: 7.938802065297896\n",
      "Step: 191\tMean return: -25.957305509079198\n",
      "Step: 192\tMean return: -12.386892429706204\n",
      "Step: 193\tMean return: -22.274633603826278\n",
      "Step: 194\tMean return: 32.67585524107888\n",
      "Step: 195\tMean return: -0.8759948567091306\n",
      "Step: 196\tMean return: -30.45093463065359\n",
      "Step: 197\tMean return: -8.19929802056904\n",
      "Step: 198\tMean return: 8.353906861480846\n",
      "Step: 199\tMean return: -21.607848427304308\n",
      "Step: 200\tMean return: -14.990751107844552\n",
      "Step: 201\tMean return: 9.970883837191813\n",
      "Step: 202\tMean return: 6.70677799330977\n",
      "Step: 203\tMean return: 1.4004184189770057\n",
      "Step: 204\tMean return: 10.156304615174976\n",
      "Step: 205\tMean return: -14.469463774409105\n",
      "Step: 206\tMean return: -1.2678488104188363\n",
      "Step: 207\tMean return: 4.191845258029807\n",
      "Step: 208\tMean return: 17.7868090551354\n",
      "Step: 209\tMean return: -2.7947625693604823\n",
      "Step: 210\tMean return: 8.599413677847515\n",
      "Step: 211\tMean return: 20.891424103761075\n",
      "Step: 212\tMean return: -24.136229297273967\n",
      "Step: 213\tMean return: 5.664956611129983\n",
      "Step: 214\tMean return: -8.536017861234068\n",
      "Step: 215\tMean return: 1.0402244425585194\n",
      "Step: 216\tMean return: 37.877588601040515\n",
      "Step: 217\tMean return: 19.855785189667586\n",
      "Step: 218\tMean return: 14.711314805616293\n",
      "Step: 219\tMean return: -16.554026220906437\n",
      "Step: 220\tMean return: 0.024757625755337357\n",
      "Step: 221\tMean return: -3.860780498335953\n",
      "Step: 222\tMean return: -2.185691570780218\n",
      "Step: 223\tMean return: -3.7022407038686653\n",
      "Step: 224\tMean return: -5.61107101910151\n",
      "Step: 225\tMean return: 3.567599740838832\n",
      "Step: 226\tMean return: -10.382514400023847\n",
      "Step: 227\tMean return: 23.94794996268889\n",
      "Step: 228\tMean return: 5.435634504529153\n",
      "Step: 229\tMean return: -2.327127636080877\n",
      "Step: 230\tMean return: 1.2317241895134612\n",
      "Step: 231\tMean return: 15.459732007914663\n",
      "Step: 232\tMean return: -11.465084266192735\n",
      "Step: 233\tMean return: -1.3392922420722244\n",
      "Step: 234\tMean return: -38.210664539909956\n",
      "Step: 235\tMean return: -9.183176434055476\n",
      "Step: 236\tMean return: 18.77284998986088\n",
      "Step: 237\tMean return: 13.71348418507805\n",
      "Step: 238\tMean return: 7.8673109802244285\n",
      "Step: 239\tMean return: 2.326054011840788\n",
      "Step: 240\tMean return: 1.5955161114351721\n",
      "Step: 241\tMean return: 8.936768147239963\n",
      "Step: 242\tMean return: 2.9295661368977743\n",
      "Step: 243\tMean return: -10.04214141145756\n",
      "Step: 244\tMean return: -11.30894279311231\n",
      "Step: 245\tMean return: -1.4420483065490226\n",
      "Step: 246\tMean return: -7.461654969497704\n",
      "Step: 247\tMean return: 8.448507296955322\n",
      "Step: 248\tMean return: 3.53372418710077\n",
      "Step: 249\tMean return: 1.2456481817987697\n",
      "Step: 250\tMean return: 15.918581229855063\n",
      "Step: 251\tMean return: 9.557548822081099\n",
      "Step: 252\tMean return: 16.636316825207906\n",
      "Step: 253\tMean return: -10.66424997667189\n",
      "Step: 254\tMean return: -13.320985698361055\n",
      "Step: 255\tMean return: -4.978179059921185\n",
      "Step: 256\tMean return: 13.381738402840602\n",
      "Step: 257\tMean return: -32.75174839801066\n",
      "Step: 258\tMean return: 3.4867083657364857\n",
      "Step: 259\tMean return: -7.540393800660622\n",
      "Step: 260\tMean return: -0.7337180282369808\n",
      "Step: 261\tMean return: 17.889303370262986\n",
      "Step: 262\tMean return: 23.779918826778996\n",
      "Step: 263\tMean return: -16.452459394955476\n",
      "Step: 264\tMean return: -7.638310405343054\n",
      "Step: 265\tMean return: 7.731492529040315\n",
      "Step: 266\tMean return: -9.790426967274616\n",
      "Step: 267\tMean return: -14.560939305861902\n",
      "Step: 268\tMean return: -10.081794670051694\n",
      "Step: 269\tMean return: -19.648489869824715\n",
      "Step: 270\tMean return: -28.598938715287385\n",
      "Step: 271\tMean return: 7.928113005539235\n",
      "Step: 272\tMean return: 2.1607806750454803\n",
      "Step: 273\tMean return: 0.6572535915716071\n",
      "Step: 274\tMean return: -12.763984350489228\n",
      "Step: 275\tMean return: 30.239809576654405\n",
      "Step: 276\tMean return: -5.441746892034371\n",
      "Step: 277\tMean return: 6.416191125782043\n",
      "Step: 278\tMean return: 1.913251398305929\n",
      "Step: 279\tMean return: -5.3856202195034895\n",
      "Step: 280\tMean return: -4.42582702181031\n",
      "Step: 281\tMean return: 8.042259037418408\n",
      "Step: 282\tMean return: 9.40988077072645\n",
      "Step: 283\tMean return: -16.71683206565578\n",
      "Step: 284\tMean return: 8.63266000691965\n",
      "Step: 285\tMean return: -1.6796757680009613\n",
      "Step: 286\tMean return: -2.178852481181184\n",
      "Step: 287\tMean return: 7.4247521627214885\n",
      "Step: 288\tMean return: 14.78014651139545\n",
      "Step: 289\tMean return: -6.243190798692922\n",
      "Step: 290\tMean return: -10.226214503630162\n",
      "Step: 291\tMean return: -2.8740326305251074\n",
      "Step: 292\tMean return: -20.128810033839056\n",
      "Step: 293\tMean return: -6.9940024290211475\n",
      "Step: 294\tMean return: 4.286222023743084\n",
      "Step: 295\tMean return: -5.838022098674337\n",
      "Step: 296\tMean return: -0.9549796727509602\n",
      "Step: 297\tMean return: -1.7022213914870372\n",
      "Step: 298\tMean return: -10.979350587980006\n",
      "Step: 299\tMean return: -21.1306816172284\n",
      "Step: 300\tMean return: -5.867546002535601\n",
      "Step: 301\tMean return: 31.825186342157814\n",
      "Step: 302\tMean return: -9.974205308846594\n",
      "Step: 303\tMean return: -2.6108073307849007\n",
      "Step: 304\tMean return: 3.025126873488771\n",
      "Step: 305\tMean return: -3.2515264162359925\n",
      "Step: 306\tMean return: -3.834668549770904\n",
      "Step: 307\tMean return: -6.51349813320745\n",
      "Step: 308\tMean return: -3.7055032716491043\n",
      "Step: 309\tMean return: -3.4119544571907863\n",
      "Step: 310\tMean return: 17.039125378110967\n",
      "Step: 311\tMean return: 6.611379191602627\n",
      "Step: 312\tMean return: -0.26502215887374403\n",
      "Step: 313\tMean return: 11.244956968124898\n",
      "Step: 314\tMean return: -5.69016861289444\n",
      "Step: 315\tMean return: -7.423286118040223\n",
      "Step: 316\tMean return: -5.3059080520153294\n",
      "Step: 317\tMean return: 12.430579994237505\n",
      "Step: 318\tMean return: 6.2259878681049665\n",
      "Step: 319\tMean return: -26.71954572644833\n",
      "Step: 320\tMean return: 29.73451934957593\n",
      "Step: 321\tMean return: -9.696332053707774\n",
      "Step: 322\tMean return: -1.4627280362101192\n",
      "Step: 323\tMean return: 5.634286672738289\n",
      "Step: 324\tMean return: 0.4483601891393664\n",
      "Step: 325\tMean return: 3.33191341084399\n",
      "Step: 326\tMean return: 6.095973006466174\n",
      "Step: 327\tMean return: -9.265988237379696\n",
      "Step: 328\tMean return: 9.66693949983659\n",
      "Step: 329\tMean return: 0.08543590425835645\n",
      "Step: 330\tMean return: -1.4021600068884073\n",
      "Step: 331\tMean return: -9.117662087812223\n",
      "Step: 332\tMean return: 10.195390978911728\n",
      "Step: 333\tMean return: 5.4423740268138685\n",
      "Step: 334\tMean return: 6.465066357766464\n",
      "Step: 335\tMean return: -3.448029134408498\n",
      "Step: 336\tMean return: 8.912470994930136\n",
      "Step: 337\tMean return: -3.2571561410808316\n",
      "Step: 338\tMean return: -25.926324899775153\n",
      "Step: 339\tMean return: 9.739658305705706\n",
      "Step: 340\tMean return: -4.565040016879757\n",
      "Step: 341\tMean return: 0.5011590789830188\n",
      "Step: 342\tMean return: 2.103618016312175\n",
      "Step: 343\tMean return: 3.0191295903499302\n",
      "Step: 344\tMean return: -13.461298019718123\n",
      "Step: 345\tMean return: 15.251284609395988\n",
      "Step: 346\tMean return: -16.822465195538626\n",
      "Step: 347\tMean return: 28.99749035368608\n",
      "Step: 348\tMean return: 0.47972370907995354\n",
      "Step: 349\tMean return: 2.6535283354252535\n",
      "Step: 350\tMean return: -4.779613567909219\n",
      "Step: 351\tMean return: -0.7001050772949384\n",
      "Step: 352\tMean return: -3.5124091165382016\n",
      "Step: 353\tMean return: 1.88143330970428\n",
      "Step: 354\tMean return: -10.662999526943587\n",
      "Step: 355\tMean return: 2.8134836856560286\n",
      "Step: 356\tMean return: -17.089744164946932\n",
      "Step: 357\tMean return: -2.9631099694805743\n",
      "Step: 358\tMean return: 2.131913174290403\n",
      "Step: 359\tMean return: -2.1044098054170353\n",
      "Step: 360\tMean return: -2.7656132859208267\n",
      "Step: 361\tMean return: 10.56654519423977\n",
      "Step: 362\tMean return: 14.122076063497898\n",
      "Step: 363\tMean return: -3.485549510653818\n",
      "Step: 364\tMean return: 5.933486716524421\n",
      "Step: 365\tMean return: -23.2422217858142\n",
      "Step: 366\tMean return: -0.5918292451790512\n",
      "Step: 367\tMean return: -5.162302189443563\n",
      "Step: 368\tMean return: 2.4508333296966884\n",
      "Step: 369\tMean return: 1.320629078139591\n",
      "Step: 370\tMean return: -0.5190729197737528\n",
      "Step: 371\tMean return: -1.9512485929420655\n",
      "Step: 372\tMean return: 4.127736721050933\n",
      "Step: 373\tMean return: 42.63593597088064\n",
      "Step: 374\tMean return: 90.07926789495865\n",
      "Step: 375\tMean return: -6.429574176640163\n",
      "Step: 376\tMean return: 18.532244315944517\n",
      "Step: 377\tMean return: 4.640227302952662\n",
      "Step: 378\tMean return: 22.347030203423436\n",
      "Step: 379\tMean return: 0.21304620801611235\n",
      "Step: 380\tMean return: -5.049777759798071\n",
      "Step: 381\tMean return: 14.342778426548593\n",
      "Step: 382\tMean return: 13.265493867331697\n",
      "Step: 383\tMean return: -23.09376903223405\n",
      "Step: 384\tMean return: 4.984174109183587\n",
      "Step: 385\tMean return: 4.883107456446068\n",
      "Step: 386\tMean return: 0.03107794740375539\n",
      "Step: 387\tMean return: -27.22454945419374\n",
      "Step: 388\tMean return: -10.88837476753919\n",
      "Step: 389\tMean return: 22.203855262235738\n",
      "Step: 390\tMean return: -1.2504945733810382\n",
      "Step: 391\tMean return: -43.74257142433212\n",
      "Step: 392\tMean return: -84.01242373372907\n",
      "Step: 393\tMean return: 19.991409235581706\n",
      "Step: 394\tMean return: -13.325993491128393\n",
      "Step: 395\tMean return: -4.108140296512956\n",
      "Step: 396\tMean return: -12.36234721437202\n",
      "Step: 397\tMean return: -6.419573134171351\n",
      "Step: 398\tMean return: 7.034328336383287\n",
      "Step: 399\tMean return: 2.235770136344172\n",
      "Step: 400\tMean return: -4.082075675759424\n",
      "Step: 401\tMean return: 26.57879481174705\n",
      "Step: 402\tMean return: -0.2060312505396905\n",
      "Step: 403\tMean return: 5.48216084546144\n",
      "Step: 404\tMean return: 8.541907591422133\n",
      "Step: 405\tMean return: 23.884000289804508\n",
      "Step: 406\tMean return: 45.591658068062955\n",
      "Step: 407\tMean return: -17.121275985670856\n",
      "Step: 408\tMean return: 7.037083430579951\n",
      "Step: 409\tMean return: 2.4544959243391897\n",
      "Step: 410\tMean return: 13.00162306308759\n",
      "Step: 411\tMean return: -7.350266692025852\n",
      "Step: 412\tMean return: -12.249568577866867\n",
      "Step: 413\tMean return: 5.391086774630494\n",
      "Step: 414\tMean return: -5.661202615023686\n",
      "Step: 415\tMean return: -4.0285555080084485\n",
      "Step: 416\tMean return: -18.376261369484382\n",
      "Step: 417\tMean return: -13.409970525145235\n",
      "Step: 418\tMean return: -5.34961768843521\n",
      "Step: 419\tMean return: -9.315886909977234\n",
      "Step: 420\tMean return: 1.5213005296007942\n",
      "Step: 421\tMean return: -5.108154189620691\n",
      "Step: 422\tMean return: -20.64260357121124\n",
      "Step: 423\tMean return: 10.628404268659743\n",
      "Step: 424\tMean return: -16.046503029856993\n",
      "Step: 425\tMean return: -4.041848225632529\n",
      "Step: 426\tMean return: -6.183551517115547\n",
      "Step: 427\tMean return: 0.596860975653235\n",
      "Step: 428\tMean return: 5.779731016444185\n",
      "Step: 429\tMean return: -7.415401102039059\n",
      "Step: 430\tMean return: 2.513105618812706\n",
      "Step: 431\tMean return: 19.201625254973006\n",
      "Step: 432\tMean return: 7.788295438674458\n",
      "Step: 433\tMean return: -2.8448292363139807\n",
      "Step: 434\tMean return: 13.099612445562725\n",
      "Step: 435\tMean return: 0.2143083000865954\n",
      "Step: 436\tMean return: -9.700201141963461\n",
      "Step: 437\tMean return: -10.157945951527909\n",
      "Step: 438\tMean return: -10.905595807313276\n",
      "Step: 439\tMean return: 0.9829880987034084\n",
      "Step: 440\tMean return: 3.4099944013779715\n",
      "Step: 441\tMean return: -19.725853359133236\n",
      "Step: 442\tMean return: -30.559905201402472\n",
      "Step: 443\tMean return: 10.121793811539291\n",
      "Step: 444\tMean return: 56.079290483176464\n",
      "Step: 445\tMean return: -6.825755540906675\n",
      "Step: 446\tMean return: 15.423570391222102\n",
      "Step: 447\tMean return: 51.22437227082017\n",
      "Step: 448\tMean return: -1.197092445493081\n",
      "Step: 449\tMean return: -14.936188273428488\n",
      "Step: 450\tMean return: -2.1266749410131522\n",
      "Step: 451\tMean return: 11.817634708938312\n",
      "Step: 452\tMean return: 12.987840779102116\n",
      "Step: 453\tMean return: -3.804692889823\n",
      "Step: 454\tMean return: 2.9997262016864896\n",
      "Step: 455\tMean return: 9.492914047502245\n",
      "Step: 456\tMean return: -24.83304906376298\n",
      "Step: 457\tMean return: 0.09830808803613764\n",
      "Step: 458\tMean return: 3.84669680954863\n",
      "Step: 459\tMean return: 12.346039707938889\n",
      "Step: 460\tMean return: 12.381818974587278\n",
      "Step: 461\tMean return: -11.2347820234957\n",
      "Step: 462\tMean return: -53.755664845907276\n",
      "Step: 463\tMean return: -0.5007252714354581\n",
      "Step: 464\tMean return: -53.64954195346172\n",
      "Step: 465\tMean return: -39.96898059648234\n",
      "Step: 466\tMean return: 25.590892403761664\n",
      "Step: 467\tMean return: -5.796781008821563\n",
      "Step: 468\tMean return: -20.365474407754647\n",
      "Step: 469\tMean return: -10.795959049013636\n",
      "Step: 470\tMean return: -12.879461482553907\n",
      "Step: 471\tMean return: -6.1487347299463\n",
      "Step: 472\tMean return: 16.774777220297064\n",
      "Step: 473\tMean return: 21.84092300294652\n",
      "Step: 474\tMean return: 59.67304175073193\n",
      "Step: 475\tMean return: 2.2219553863469446\n",
      "Step: 476\tMean return: 14.222086452072636\n",
      "Step: 477\tMean return: 0.3016115607075699\n",
      "Step: 478\tMean return: 2.9780930854363032\n",
      "Step: 479\tMean return: -0.0646601696376274\n",
      "Step: 480\tMean return: -3.3673505695971473\n",
      "Step: 481\tMean return: -1.612258535722667\n",
      "Step: 482\tMean return: 26.46265234902239\n",
      "Step: 483\tMean return: 4.31149862002776\n",
      "Step: 484\tMean return: -26.953274721944563\n",
      "Step: 485\tMean return: 1.470020370650782\n",
      "Step: 486\tMean return: 1.458664356048048\n",
      "Step: 487\tMean return: 5.354697385401396\n",
      "Step: 488\tMean return: -4.865690651934565\n",
      "Step: 489\tMean return: -2.674857239770317\n",
      "Step: 490\tMean return: -18.808134044795096\n",
      "Step: 491\tMean return: -19.502621199511378\n",
      "Step: 492\tMean return: -37.393879560223795\n",
      "Step: 493\tMean return: -43.503727934945324\n",
      "Step: 494\tMean return: -12.815342776802446\n",
      "Step: 495\tMean return: 9.122623034900034\n",
      "Step: 496\tMean return: -8.691910038315346\n",
      "Step: 497\tMean return: 11.065681917033835\n",
      "Step: 498\tMean return: -3.2849380903689234\n",
      "Step: 499\tMean return: -8.57105499430685\n",
      "Step: 500\tMean return: 6.42363866122847\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Variable.__del__ at 0x7f17eafc2950>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/tkinter/__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[all] in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (0.26.3)\r\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (0.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (1.24.3)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.2.1)\r\n",
      "Collecting mujoco-py<2.2,>=2.1\r\n",
      "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m12.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting mujoco==2.2\r\n",
      "  Downloading mujoco-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: imageio>=2.14.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.28.1)\r\n",
      "Collecting gym==0.26.2\r\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting box2d-py==2.3.5\r\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m374.4/374.4 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting opencv-python>=3.0\r\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.8/61.8 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m�\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m61.8/61.8 MB\u001B[0m \u001B[31m115.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting swig==4.*\r\n",
      "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m24.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting ale-py~=0.8.0\r\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: matplotlib>=3.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (3.7.1)\r\n",
      "Requirement already satisfied: pygame==2.1.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (2.1.0)\r\n",
      "Collecting moviepy>=1.0.0\r\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m388.3/388.3 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting pytest==7.0.1\r\n",
      "  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m297.0/297.0 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: lz4>=3.1.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from gymnasium[all]) (4.3.2)\r\n",
      "Collecting gym-notices>=0.0.4\r\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\r\n",
      "Collecting glfw\r\n",
      "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.8/207.8 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco==2.2->gymnasium[all]) (1.4.0)\r\n",
      "Collecting pyopengl\r\n",
      "  Using cached PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\r\n",
      "Collecting tomli>=1.0.0\r\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: packaging in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from pytest==7.0.1->gymnasium[all]) (23.1)\r\n",
      "Collecting pluggy<2.0,>=0.12\r\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting py>=1.8.2\r\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from pytest==7.0.1->gymnasium[all]) (23.1.0)\r\n",
      "Collecting iniconfig\r\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\r\n",
      "Collecting importlib-resources\r\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from ale-py~=0.8.0->gymnasium[all]) (4.5.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from imageio>=2.14.1->gymnasium[all]) (9.5.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (4.39.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (1.0.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[all]) (0.11.0)\r\n",
      "Collecting decorator<5.0,>=4.0.2\r\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[all]) (4.65.0)\r\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[all]) (2.28.1)\r\n",
      "Collecting proglog<=1.0.0\r\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\r\n",
      "Collecting imageio_ffmpeg>=0.2.0\r\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.9/26.9 MB\u001B[0m \u001B[31m23.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting fasteners~=0.15\r\n",
      "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: Cython>=0.27.2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco-py<2.2,>=2.1->gymnasium[all]) (0.29.34)\r\n",
      "Requirement already satisfied: cffi>=1.10 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from mujoco-py<2.2,>=2.1->gymnasium[all]) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1->gymnasium[all]) (2.21)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->gymnasium[all]) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/fassty/anaconda3/envs/diploma_thesis/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (1.26.13)\r\n",
      "Building wheels for collected packages: box2d-py, gym, moviepy\r\n",
      "  Building wheel for box2d-py (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[16 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m Using setuptools (version 66.0.0).\r\n",
      "  \u001B[31m   \u001B[0m running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m running build\r\n",
      "  \u001B[31m   \u001B[0m running build_py\r\n",
      "  \u001B[31m   \u001B[0m creating build\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/Box2D.py -> build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/__init__.py -> build/lib.linux-x86_64-cpython-310/Box2D\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-310/Box2D/b2\r\n",
      "  \u001B[31m   \u001B[0m copying library/Box2D/b2/__init__.py -> build/lib.linux-x86_64-cpython-310/Box2D/b2\r\n",
      "  \u001B[31m   \u001B[0m running build_ext\r\n",
      "  \u001B[31m   \u001B[0m building 'Box2D._Box2D' extension\r\n",
      "  \u001B[31m   \u001B[0m swigging Box2D/Box2D.i to Box2D/Box2D_wrap.cpp\r\n",
      "  \u001B[31m   \u001B[0m swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D/Box2D_wrap.cpp Box2D/Box2D.i\r\n",
      "  \u001B[31m   \u001B[0m error: command 'swig' failed: No such file or directory\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for box2d-py\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25h  Running setup.py clean for box2d-py\r\n",
      "  Building wheel for gym (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827631 sha256=ff39f2ad30a47272e9a22a0df7811f42e7192b341213693e30d3603b76f80b9f\r\n",
      "  Stored in directory: /home/fassty/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\r\n",
      "  Building wheel for moviepy (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110727 sha256=bb5f77d5cc61fe09a780676646e407509e4b67906f2a891d8f78e00b97f30dda\r\n",
      "  Stored in directory: /home/fassty/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\r\n",
      "Successfully built gym moviepy\r\n",
      "Failed to build box2d-py\r\n",
      "Installing collected packages: swig, pyopengl, gym-notices, glfw, box2d-py, tomli, py, proglog, pluggy, opencv-python, mujoco, iniconfig, importlib-resources, imageio_ffmpeg, gym, fasteners, decorator, pytest, mujoco-py, moviepy, ale-py\r\n",
      "  Running setup.py install for box2d-py ... \u001B[?25l-\u001B[2m\u001B[1m\u001B[33m(autoscaler +24h56m9s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "done\r\n",
      "\u001B[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[?25h  Attempting uninstall: decorator\r\n",
      "    Found existing installation: decorator 5.1.1\r\n",
      "    Uninstalling decorator-5.1.1:\r\n",
      "      Successfully uninstalled decorator-5.1.1\r\n",
      "Successfully installed ale-py-0.8.1 box2d-py-2.3.5 decorator-4.4.2 fasteners-0.18 glfw-2.5.9 gym-0.26.2 gym-notices-0.0.8 imageio_ffmpeg-0.4.8 importlib-resources-5.12.0 iniconfig-2.0.0 moviepy-1.0.3 mujoco-2.2.0 mujoco-py-2.1.2.14 opencv-python-4.7.0.72 pluggy-1.0.0 proglog-0.1.10 py-1.11.0 pyopengl-3.1.6 pytest-7.0.1 swig-4.1.1 tomli-2.0.1\r\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_prices['price'].isna().any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
